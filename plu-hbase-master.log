Mon Dec 29 14:32:10 UTC 2014 Starting master on sandbox.hortonworks.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30509
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-12-29 14:32:12,669 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2014-12-29 14:32:12,670 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2014-12-29 14:32:12,670 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2014-12-29 14:32:13,415 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2014-12-29 14:32:13,417 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64
2014-12-29 14:32:13,417 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/hdp/current/hbase-client/bin/..
2014-12-29 14:32:13,418 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-12-29 14:32:13,418 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hbase
2014-12-29 14:32:13,418 INFO  [main] util.ServerCommandLine: env:HOSTNAME=sandbox.hortonworks.com
2014-12-29 14:32:13,418 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase
2014-12-29 14:32:13,418 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-master.znode
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xmx1024m
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-12-29 14:32:13,419 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:ZOOKEEPER_HOME=/usr/hdp/2.2.0.0-2041/zookeeper
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xmn200m -XX:CMSInitiatingOccupancyFraction=70  -Xms1024m -Xmx1024m
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/hbase/bin
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF=/usr/hdp/2.2.0.0-2041/hadoop/conf
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HDP_VERSION=2.2.0.0-2041
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2014-12-29 14:32:13,420 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVERS=/etc/hbase/conf/regionservers
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-master.autorestart
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:SERVER_GC_OPTS=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291432
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-master-sandbox.hortonworks.com.log
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-Dhdp.version=2.2.0.0-2041  -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291432  -Xmx1024m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2014-12-29 14:32:13,421 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/etc/hbase/conf
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/hdp/2.2.0.0-2041/hadoop
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=::/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-12-29 14:32:13,422 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/hadoop/.//*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//*::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/*:/usr/hdp/current/tez-client/*:/usr/hdp/current/tez-client/lib/*:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/*:/usr/hdp/2.2.0.0-2041/tez/lib/*:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 14:32:13,431 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-12-29 14:32:13,431 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2014-12-29 14:32:13,431 INFO  [main] util.ServerCommandLine: env:USER=hbase
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:HOME=/home/hbase
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-master-sandbox.hortonworks.com
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-12-29 14:32:13,432 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2014-12-29 14:32:13,434 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.65-b04
2014-12-29 14:32:13,434 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -Dhdp.version=2.2.0.0-2041, -XX:+UseConcMarkSweepGC, -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log, -verbose:gc, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -Xloggc:/var/log/hbase/gc.log-201412291432, -Xmx1024m, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log, -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.., -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2014-12-29 14:32:13,533 DEBUG [main] master.HMaster: master/sandbox.hortonworks.com/172.16.144.128:60000 HConnection server-to-server retries=350
2014-12-29 14:32:13,805 INFO  [main] ipc.RpcServer: master/sandbox.hortonworks.com/172.16.144.128:60000: started 10 reader(s).
2014-12-29 14:32:14,017 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-12-29 14:32:14,329 INFO  [main] impl.MetricsSinkAdapter: Sink ganglia started
2014-12-29 14:32:14,598 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-12-29 14:32:14,598 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-12-29 14:32:17,717 INFO  [main] master.HMaster: hbase.rootdir=hdfs://sandbox.hortonworks.com:8020/apps/hbase/data, hbase.cluster.distributed=true
2014-12-29 14:32:17,724 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-12-29 14:32:17,893 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2014-12-29 14:32:17,893 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2014-12-29 14:32:17,893 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2014-12-29 14:32:17,893 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2014-12-29 14:32:17,894 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2014-12-29 14:32:17,895 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2014-12-29 14:32:17,896 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=master:60000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 14:32:17,937 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 14:32:17,944 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 14:32:17,959 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 14:32:18,021 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0000, negotiated timeout = 30000
2014-12-29 14:32:18,097 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-12-29 14:32:18,100 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2014-12-29 14:32:18,218 INFO  [master:sandbox:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-12-29 14:32:18,291 INFO  [master:sandbox:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-12-29 14:32:18,298 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-12-29 14:32:18,298 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-12-29 14:32:18,317 INFO  [master:sandbox:60000] http.HttpServer: Jetty bound to port 60010
2014-12-29 14:32:18,317 INFO  [master:sandbox:60000] mortbay.log: jetty-6.1.26
2014-12-29 14:32:19,279 INFO  [master:sandbox:60000] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60010
2014-12-29 14:32:19,572 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-12-29 14:32:19,574 INFO  [master:sandbox:60000] master.ActiveMasterManager: Registered Active Master=sandbox.hortonworks.com,60000,1419863535137
2014-12-29 14:32:19,586 INFO  [master:sandbox:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 14:32:19,997 DEBUG [master:sandbox:60000] hbase.HRegionInfo: 1588230740
2014-12-29 14:32:21,251 DEBUG [master:sandbox:60000] util.FSUtils: Created version file at hdfs://sandbox.hortonworks.com:8020/apps/hbase/data with version=8
2014-12-29 14:32:21,297 DEBUG [master:sandbox:60000] util.FSUtils: Created cluster ID file at hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/hbase.id with ID: db2ed425-2c89-4878-9a96-eb9f3133579d
2014-12-29 14:32:21,494 INFO  [master:sandbox:60000] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
2014-12-29 14:32:21,557 INFO  [master:sandbox:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2014-12-29 14:32:21,842 INFO  [master:sandbox:60000] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'false', BLOCKCACHE => 'false'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data Table name == hbase:meta
2014-12-29 14:32:21,950 DEBUG [master:sandbox:60000] regionserver.HRegion: Instantiated hbase:meta,,1.1588230740
2014-12-29 14:32:22,166 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000
2014-12-29 14:32:22,187 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
2014-12-29 14:32:22,187 INFO  [StoreOpener-1588230740-1] util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
2014-12-29 14:32:22,195 DEBUG [master:sandbox:60000] regionserver.HRegion: Found 0 recovered edits file(s) under hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/1588230740
2014-12-29 14:32:22,243 DEBUG [master:sandbox:60000] wal.HLogUtil: Written region seqId to file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/1588230740/recovered.edits/2_seqid ,newSeqId=2 ,maxSeqId=0
2014-12-29 14:32:22,243 INFO  [master:sandbox:60000] regionserver.HRegion: Onlined 1588230740; next sequenceid=2
2014-12-29 14:32:22,243 DEBUG [master:sandbox:60000] regionserver.HRegion: Closing hbase:meta,,1.1588230740: disabling compactions & flushes
2014-12-29 14:32:22,243 DEBUG [master:sandbox:60000] regionserver.HRegion: Updates disabled for region hbase:meta,,1.1588230740
2014-12-29 14:32:22,250 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
2014-12-29 14:32:22,250 INFO  [master:sandbox:60000] regionserver.HRegion: Closed hbase:meta,,1.1588230740
2014-12-29 14:32:22,397 DEBUG [master:sandbox:60000] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-12-29 14:32:22,474 INFO  [master:sandbox:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-12-29 14:32:22,498 DEBUG [master:sandbox:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2014-12-29 14:32:22,510 INFO  [master:sandbox:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-12-29 14:32:22,519 INFO  [master:sandbox:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-12-29 14:32:22,763 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=hconnection-0x369b0b39, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 14:32:22,770 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 14:32:22,777 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 14:32:22,773 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x369b0b39 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 14:32:22,783 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0001, negotiated timeout = 30000
2014-12-29 14:32:22,799 DEBUG [master:sandbox:60000] ipc.RpcClient: Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@7404b78b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2014-12-29 14:32:22,818 DEBUG [master:sandbox:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@6f21fc12
2014-12-29 14:32:22,979 INFO  [master:sandbox:60000] master.HMaster: Server active/primary master=sandbox.hortonworks.com,60000,1419863535137, sessionid=0x14a9675840d0000, setting cluster-up flag (Was=false)
2014-12-29 14:32:23,066 INFO  [master:sandbox:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase-unsecure/online-snapshot/acquired /hbase-unsecure/online-snapshot/reached /hbase-unsecure/online-snapshot/abort
2014-12-29 14:32:23,069 DEBUG [master:sandbox:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sandbox.hortonworks.com,60000,1419863535137
2014-12-29 14:32:23,091 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 14:32:23,092 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 14:32:23,093 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 14:32:23,093 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 14:32:23,094 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sandbox:60000, corePoolSize=10, maxPoolSize=10
2014-12-29 14:32:23,094 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sandbox:60000, corePoolSize=1, maxPoolSize=1
2014-12-29 14:32:23,099 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-12-29 14:32:23,117 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=replicationLogCleaner, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 14:32:23,123 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 14:32:23,125 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 14:32:23,127 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 14:32:23,129 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0002, negotiated timeout = 30000
2014-12-29 14:32:23,149 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-12-29 14:32:23,154 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-12-29 14:32:23,160 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-12-29 14:32:23,164 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-12-29 14:32:23,164 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-12-29 14:32:23,168 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:24,676 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1508 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:26,183 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 3015 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:27,692 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 4524 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:29,203 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 6035 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:30,714 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 7546 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:32,224 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 9056 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:33,737 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 10568 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:35,246 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 12078 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:36,758 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 13589 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:38,270 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 15102 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:39,776 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 16608 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:41,284 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 18115 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:42,791 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 19623 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:44,300 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 21132 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:45,812 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 22644 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:47,320 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 24152 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:48,829 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 25661 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:50,338 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 27170 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:51,846 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 28677 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:53,355 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 30187 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:54,864 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 31696 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:56,372 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 33204 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:57,880 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 34712 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:32:59,387 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 36219 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:00,894 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 37726 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:02,401 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 39233 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:03,907 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 40739 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:05,419 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 42251 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:06,926 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 43758 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:08,434 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 45266 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:09,941 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 46773 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:11,448 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 48280 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:12,958 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 49790 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:14,467 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 51298 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:15,974 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 52806 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:17,483 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 54315 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:18,992 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 55824 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:20,498 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 57330 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:22,006 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 58838 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:23,517 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 60349 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:25,027 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 61859 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:26,537 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 63369 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:28,044 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 64876 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:29,558 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 66390 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:31,066 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 67898 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:32,572 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 69404 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:34,080 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 70911 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:35,586 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 72418 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:37,093 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 73925 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:38,600 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 75431 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:40,107 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 76939 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:41,614 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 78446 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:43,121 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 79953 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:44,631 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 81462 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:46,141 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 82972 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:47,653 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 84485 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:49,166 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 85998 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:50,677 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 87509 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:52,185 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 89017 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:53,693 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 90525 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:55,200 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 92032 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:56,709 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 93541 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:58,223 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 95055 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:33:59,730 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 96562 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:01,240 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 98072 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:02,748 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 99580 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:04,256 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 101088 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:05,763 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 102595 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:07,269 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 104101 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:08,780 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 105612 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:10,291 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 107123 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:11,800 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 108631 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:13,317 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 110149 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:14,828 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 111660 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:16,338 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 113170 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:17,846 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 114678 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:19,356 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 116188 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:20,863 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 117695 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:22,370 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 119202 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:23,880 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 120712 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:25,386 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 122218 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:26,894 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 123726 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:28,400 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 125232 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:29,910 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 126742 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:31,417 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 128249 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:32,923 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 129755 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:34,431 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 131263 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:35,939 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 132771 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:37,447 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 134279 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:38,954 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 135786 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:40,459 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 137291 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:41,969 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 138801 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:43,477 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 140309 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:44,984 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 141816 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:46,492 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 143323 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:48,002 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 144834 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:49,510 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 146342 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:51,019 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 147851 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:52,528 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 149359 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:54,036 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 150868 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:55,556 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 152388 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:57,068 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 153900 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:34:58,575 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 155407 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:00,085 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 156916 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:01,597 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 158429 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:03,109 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 159940 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:04,620 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 161452 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:06,129 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 162961 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:07,639 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 164471 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:09,149 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 165981 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:10,659 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 167490 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:12,169 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 169001 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:13,680 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 170512 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:15,189 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 172021 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:16,698 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 173530 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:18,206 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 175038 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:19,715 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 176547 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:21,223 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 178055 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:22,732 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 179564 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:24,238 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 181070 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:25,745 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 182577 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:26,955 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44087; # active connections: 1
2014-12-29 14:35:27,255 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 184087 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:27,263 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:27,269 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 14:35:27,304 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase-unsecure/rs/sandbox.hortonworks.com,60020,1419863721426 data: PBUF
2014-12-29 14:35:27,306 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 184138 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 14:35:28,817 INFO  [master:sandbox:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 185649 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-12-29 14:35:28,824 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419863721426 belongs to an existing region server
2014-12-29 14:35:29,875 INFO  [master:sandbox:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-12-29 14:35:29,879 WARN  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/meta-region-server already deleted, retry=false
2014-12-29 14:35:29,917 DEBUG [master:sandbox:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sandbox.hortonworks.com,60020,1419863721426; 1 (online=1, available=1) available servers, forceNewPlan=false
2014-12-29 14:35:29,917 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-12-29 14:35:29,947 DEBUG [master:sandbox:60000] master.AssignmentManager: Setting table hbase:meta to ENABLED state.
2014-12-29 14:35:29,975 INFO  [master:sandbox:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:29,975 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1419863729917, server=null} to {1588230740 state=PENDING_OPEN, ts=1419863729975, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:29,975 DEBUG [master:sandbox:60000] master.ServerManager: New admin connection to sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:30,055 DEBUG [master:sandbox:60000] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2014-12-29 14:35:30,059 DEBUG [master:sandbox:60000] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:35:30,529 INFO  [master:sandbox:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-12-29 14:35:30,585 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419863721426, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1419863729975, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:30,590 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1419863729975, server=sandbox.hortonworks.com,60020,1419863721426} to {1588230740 state=OPENING, ts=1419863730590, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:30,986 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419863721426, region=1588230740, current_state={1588230740 state=OPENING, ts=1419863730590, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:30,986 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1419863730590, server=sandbox.hortonworks.com,60020,1419863721426} to {1588230740 state=OPEN, ts=1419863730986, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:30,990 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sandbox.hortonworks.com,60020,1419863721426; deleting unassigned node
2014-12-29 14:35:30,995 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x14a9675840d0000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-12-29 14:35:30,997 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1419863730986, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:30,997 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sandbox.hortonworks.com,60020,1419863721426 {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-12-29 14:35:30,998 INFO  [master:sandbox:60000] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:31,053 DEBUG [htable-pool3-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 14:35:31,054 DEBUG [htable-pool3-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:35:31,106 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
2014-12-29 14:35:31,106 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-12-29 14:35:31,146 INFO  [master:sandbox:60000] master.AssignmentManager: Clean cluster startup. Assigning userregions
2014-12-29 14:35:31,146 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleting any existing unassigned nodes
2014-12-29 14:35:31,158 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2014-12-29 14:35:31,168 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2014-12-29 14:35:31,224 INFO  [master:sandbox:60000] master.TableNamespaceManager: Namespace table not found. Creating...
2014-12-29 14:35:31,290 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/hbase:namespace/write-master:600000000000000
2014-12-29 14:35:31,306 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table hbase:namespace
2014-12-29 14:35:31,377 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
2014-12-29 14:35:31,387 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == hbase:namespace
2014-12-29 14:35:31,447 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Instantiated hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.
2014-12-29 14:35:31,447 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closing hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.: disabling compactions & flushes
2014-12-29 14:35:31,447 DEBUG [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Updates disabled for region hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.
2014-12-29 14:35:31,447 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.
2014-12-29 14:35:31,578 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2014-12-29 14:35:31,604 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:31,607 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x14a9675840d0000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node db8d9fe8d0471c86ef90518de99b1581 with OFFLINE state
2014-12-29 14:35:31,625 DEBUG [main-EventThread] master.OfflineCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419863731578, server=null}, server=sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:31,628 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419863731578, server=null}, server=sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:31,630 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1419863721426 unassigned znodes=1 of total=1
2014-12-29 14:35:31,630 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419863731607, server=null} to {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419863731630, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:31,846 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1419863721426
2014-12-29 14:35:31,853 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/hbase:namespace/write-master:600000000000000
2014-12-29 14:35:31,853 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, hbase:namespace, creation successful
2014-12-29 14:35:31,875 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419863721426, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419863731630, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:31,875 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419863731630, server=sandbox.hortonworks.com,60020,1419863721426} to {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419863731875, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:32,078 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419863721426, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419863731875, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:32,079 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419863731875, server=sandbox.hortonworks.com,60020,1419863721426} to {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419863732079, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:32,079 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of db8d9fe8d0471c86ef90518de99b1581 from sandbox.hortonworks.com,60020,1419863721426; deleting unassigned node
2014-12-29 14:35:32,087 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x14a9675840d0000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node db8d9fe8d0471c86ef90518de99b1581 in expected state RS_ZK_REGION_OPENED
2014-12-29 14:35:32,099 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581. deleted, state: {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419863732079, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 14:35:32,100 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined db8d9fe8d0471c86ef90518de99b1581 on sandbox.hortonworks.com,60020,1419863721426 {ENCODED => db8d9fe8d0471c86ef90518de99b1581, NAME => 'hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.', STARTKEY => '', ENDKEY => ''}
2014-12-29 14:35:32,236 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-12-29 14:35:32,259 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-12-29 14:35:32,259 DEBUG [main-EventThread] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-12-29 14:35:32,269 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/default already exists and this is not a retry
2014-12-29 14:35:32,274 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/hbase already exists and this is not a retry
2014-12-29 14:35:32,277 INFO  [master:sandbox:60000] master.HMaster: Master has completed initialization
2014-12-29 14:40:31,204 DEBUG [htable-pool12-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 14:40:31,205 DEBUG [htable-pool12-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:40:31,331 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 14:45:31,183 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 14:45:31,193 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40237; # active connections: 2
2014-12-29 14:45:31,194 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40237 because read count=-1. Number of active connections: 2
2014-12-29 14:45:31,195 DEBUG [htable-pool13-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 14:45:31,195 DEBUG [htable-pool13-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:46:01,101 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40300; # active connections: 2
2014-12-29 14:46:01,108 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40300 because read count=-1. Number of active connections: 2
2014-12-29 14:46:31,167 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40369; # active connections: 2
2014-12-29 14:46:31,168 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40369 because read count=-1. Number of active connections: 2
2014-12-29 14:47:01,284 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40504; # active connections: 2
2014-12-29 14:47:01,297 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40504 because read count=-1. Number of active connections: 2
2014-12-29 14:47:31,195 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40795; # active connections: 2
2014-12-29 14:47:31,203 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40795 because read count=-1. Number of active connections: 2
2014-12-29 14:48:01,274 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:40945; # active connections: 2
2014-12-29 14:48:01,275 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:40945 because read count=-1. Number of active connections: 2
2014-12-29 14:48:31,200 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41101; # active connections: 2
2014-12-29 14:48:31,202 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41101 because read count=-1. Number of active connections: 2
2014-12-29 14:49:01,273 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41159; # active connections: 2
2014-12-29 14:49:01,274 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41159 because read count=-1. Number of active connections: 2
2014-12-29 14:49:31,221 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41226; # active connections: 2
2014-12-29 14:49:31,223 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41226 because read count=-1. Number of active connections: 2
2014-12-29 14:50:01,084 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41287; # active connections: 2
2014-12-29 14:50:01,085 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41287 because read count=-1. Number of active connections: 2
2014-12-29 14:50:31,204 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 14:50:31,212 DEBUG [htable-pool14-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 14:50:31,213 DEBUG [htable-pool14-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:50:31,259 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41355; # active connections: 2
2014-12-29 14:50:31,267 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41355 because read count=-1. Number of active connections: 2
2014-12-29 14:51:01,126 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41418; # active connections: 2
2014-12-29 14:51:01,126 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41418 because read count=-1. Number of active connections: 2
2014-12-29 14:51:31,094 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41486; # active connections: 2
2014-12-29 14:51:31,096 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41486 because read count=-1. Number of active connections: 2
2014-12-29 14:52:01,270 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41544; # active connections: 2
2014-12-29 14:52:01,270 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41544 because read count=-1. Number of active connections: 2
2014-12-29 14:52:31,143 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41611; # active connections: 2
2014-12-29 14:52:31,146 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41611 because read count=-1. Number of active connections: 2
2014-12-29 14:53:01,275 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41668; # active connections: 2
2014-12-29 14:53:01,279 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41668 because read count=-1. Number of active connections: 2
2014-12-29 14:53:31,194 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41735; # active connections: 2
2014-12-29 14:53:31,195 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41735 because read count=-1. Number of active connections: 2
2014-12-29 14:54:01,283 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41794; # active connections: 2
2014-12-29 14:54:01,283 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41794 because read count=-1. Number of active connections: 2
2014-12-29 14:54:31,165 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41859; # active connections: 2
2014-12-29 14:54:31,168 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41859 because read count=-1. Number of active connections: 2
2014-12-29 14:55:01,300 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41917; # active connections: 2
2014-12-29 14:55:01,300 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41917 because read count=-1. Number of active connections: 2
2014-12-29 14:55:31,181 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:41986; # active connections: 2
2014-12-29 14:55:31,190 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:41986 because read count=-1. Number of active connections: 2
2014-12-29 14:55:31,194 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 14:55:31,196 DEBUG [htable-pool15-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 14:55:31,196 DEBUG [htable-pool15-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 14:56:01,048 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42050; # active connections: 2
2014-12-29 14:56:01,048 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42050 because read count=-1. Number of active connections: 2
2014-12-29 14:56:31,183 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42119; # active connections: 2
2014-12-29 14:56:31,184 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42119 because read count=-1. Number of active connections: 2
2014-12-29 14:57:01,074 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42175; # active connections: 2
2014-12-29 14:57:01,075 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42175 because read count=-1. Number of active connections: 2
2014-12-29 14:57:31,216 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42242; # active connections: 2
2014-12-29 14:57:31,219 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42242 because read count=-1. Number of active connections: 2
2014-12-29 14:58:01,092 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42299; # active connections: 2
2014-12-29 14:58:01,094 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42299 because read count=-1. Number of active connections: 2
2014-12-29 14:58:31,253 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42369; # active connections: 2
2014-12-29 14:58:31,254 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42369 because read count=-1. Number of active connections: 2
2014-12-29 14:59:01,127 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42423; # active connections: 2
2014-12-29 14:59:01,127 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42423 because read count=-1. Number of active connections: 2
2014-12-29 14:59:31,272 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42494; # active connections: 2
2014-12-29 14:59:31,272 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42494 because read count=-1. Number of active connections: 2
2014-12-29 15:00:01,162 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42550; # active connections: 2
2014-12-29 15:00:01,162 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42550 because read count=-1. Number of active connections: 2
2014-12-29 15:00:31,086 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42619; # active connections: 2
2014-12-29 15:00:31,090 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42619 because read count=-1. Number of active connections: 2
2014-12-29 15:00:31,191 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:00:31,194 DEBUG [htable-pool16-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:00:31,195 DEBUG [htable-pool16-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:01:01,196 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42832; # active connections: 2
2014-12-29 15:01:01,197 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42832 because read count=-1. Number of active connections: 2
2014-12-29 15:01:31,115 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42903; # active connections: 2
2014-12-29 15:01:31,116 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42903 because read count=-1. Number of active connections: 2
2014-12-29 15:02:01,279 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:42961; # active connections: 2
2014-12-29 15:02:01,284 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:42961 because read count=-1. Number of active connections: 2
2014-12-29 15:02:31,180 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:43035; # active connections: 2
2014-12-29 15:02:31,181 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:43035 because read count=-1. Number of active connections: 2
2014-12-29 15:03:01,226 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:43225; # active connections: 2
2014-12-29 15:03:01,228 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:43225 because read count=-1. Number of active connections: 2
2014-12-29 15:03:31,146 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:43611; # active connections: 2
2014-12-29 15:03:31,147 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:43611 because read count=-1. Number of active connections: 2
2014-12-29 15:04:01,269 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44042; # active connections: 2
2014-12-29 15:04:01,270 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44042 because read count=-1. Number of active connections: 2
2014-12-29 15:04:31,144 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44264; # active connections: 2
2014-12-29 15:04:31,147 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44264 because read count=-1. Number of active connections: 2
2014-12-29 15:05:01,272 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44334; # active connections: 2
2014-12-29 15:05:01,273 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44334 because read count=-1. Number of active connections: 2
2014-12-29 15:05:31,197 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:05:31,216 DEBUG [htable-pool17-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:05:31,218 DEBUG [htable-pool17-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:05:31,276 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44451; # active connections: 2
2014-12-29 15:05:31,276 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44451 because read count=-1. Number of active connections: 2
2014-12-29 15:06:01,061 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44526; # active connections: 2
2014-12-29 15:06:01,063 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44526 because read count=-1. Number of active connections: 2
2014-12-29 15:06:31,268 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44889; # active connections: 2
2014-12-29 15:06:31,272 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44889 because read count=-1. Number of active connections: 2
2014-12-29 15:07:01,103 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44945; # active connections: 2
2014-12-29 15:07:01,103 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44945 because read count=-1. Number of active connections: 2
2014-12-29 15:07:31,257 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45015; # active connections: 2
2014-12-29 15:07:31,258 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45015 because read count=-1. Number of active connections: 2
2014-12-29 15:08:01,151 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45070; # active connections: 2
2014-12-29 15:08:01,151 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45070 because read count=-1. Number of active connections: 2
2014-12-29 15:08:31,063 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45138; # active connections: 2
2014-12-29 15:08:31,063 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45138 because read count=-1. Number of active connections: 2
2014-12-29 15:09:01,164 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45345; # active connections: 2
2014-12-29 15:09:01,165 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45345 because read count=-1. Number of active connections: 2
2014-12-29 15:09:31,065 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45412; # active connections: 2
2014-12-29 15:09:31,066 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45412 because read count=-1. Number of active connections: 2
2014-12-29 15:10:01,206 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45471; # active connections: 2
2014-12-29 15:10:01,206 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45471 because read count=-1. Number of active connections: 2
2014-12-29 15:10:31,116 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45538; # active connections: 2
2014-12-29 15:10:31,116 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45538 because read count=-1. Number of active connections: 2
2014-12-29 15:10:31,192 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:10:31,201 DEBUG [htable-pool18-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:10:31,202 DEBUG [htable-pool18-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:11:01,261 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45596; # active connections: 2
2014-12-29 15:11:01,261 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45596 because read count=-1. Number of active connections: 2
2014-12-29 15:11:31,130 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45665; # active connections: 2
2014-12-29 15:11:31,130 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45665 because read count=-1. Number of active connections: 2
2014-12-29 15:12:01,297 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45722; # active connections: 2
2014-12-29 15:12:01,300 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45722 because read count=-1. Number of active connections: 2
2014-12-29 15:12:31,226 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45788; # active connections: 2
2014-12-29 15:12:31,226 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45788 because read count=-1. Number of active connections: 2
2014-12-29 15:13:01,280 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45846; # active connections: 2
2014-12-29 15:13:01,283 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45846 because read count=-1. Number of active connections: 2
2014-12-29 15:13:31,174 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45913; # active connections: 2
2014-12-29 15:13:31,174 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45913 because read count=-1. Number of active connections: 2
2014-12-29 15:14:01,263 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:45976; # active connections: 2
2014-12-29 15:14:01,269 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:45976 because read count=-1. Number of active connections: 2
2014-12-29 15:14:31,138 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46044; # active connections: 2
2014-12-29 15:14:31,139 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46044 because read count=-1. Number of active connections: 2
2014-12-29 15:15:01,242 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46115; # active connections: 2
2014-12-29 15:15:01,259 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46115 because read count=-1. Number of active connections: 2
2014-12-29 15:15:31,193 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:15:31,205 DEBUG [htable-pool19-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:15:31,206 DEBUG [htable-pool19-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:15:31,308 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46193; # active connections: 2
2014-12-29 15:15:31,311 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46193 because read count=-1. Number of active connections: 2
2014-12-29 15:16:01,360 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46262; # active connections: 2
2014-12-29 15:16:01,360 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46262 because read count=-1. Number of active connections: 2
2014-12-29 15:16:31,134 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46336; # active connections: 2
2014-12-29 15:16:31,134 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46336 because read count=-1. Number of active connections: 2
2014-12-29 15:17:01,199 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46398; # active connections: 2
2014-12-29 15:17:01,200 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46398 because read count=-1. Number of active connections: 2
2014-12-29 15:17:31,307 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46477; # active connections: 2
2014-12-29 15:17:31,307 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46477 because read count=-1. Number of active connections: 2
2014-12-29 15:18:01,196 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46558; # active connections: 2
2014-12-29 15:18:01,198 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46558 because read count=-1. Number of active connections: 2
2014-12-29 15:18:31,180 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46642; # active connections: 2
2014-12-29 15:18:31,180 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46642 because read count=-1. Number of active connections: 2
2014-12-29 15:19:01,279 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46715; # active connections: 2
2014-12-29 15:19:01,280 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46715 because read count=-1. Number of active connections: 2
2014-12-29 15:19:31,200 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46795; # active connections: 2
2014-12-29 15:19:31,201 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46795 because read count=-1. Number of active connections: 2
2014-12-29 15:20:01,115 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:46915; # active connections: 2
2014-12-29 15:20:01,115 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:46915 because read count=-1. Number of active connections: 2
2014-12-29 15:20:23,378 WARN  [master:sandbox:60000.archivedHFileCleaner] cleaner.CleanerChore: Error while cleaning the logs
java.net.ConnectException: Call From sandbox.hortonworks.com/172.16.144.128 to sandbox.hortonworks.com:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:554)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1969)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1952)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:693)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:105)
	at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:755)
	at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:751)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:751)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1597)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1617)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.Chore.run(Chore.java:80)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 28 more
2014-12-29 15:20:23,378 WARN  [master:sandbox:60000.oldLogCleaner] cleaner.CleanerChore: Error while cleaning the logs
java.net.ConnectException: Call From sandbox.hortonworks.com/172.16.144.128 to sandbox.hortonworks.com:8020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getListing(ClientNamenodeProtocolTranslatorPB.java:554)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getListing(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor4.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.getListing(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1969)
	at org.apache.hadoop.hdfs.DFSClient.listPaths(DFSClient.java:1952)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatusInternal(DistributedFileSystem.java:693)
	at org.apache.hadoop.hdfs.DistributedFileSystem.access$600(DistributedFileSystem.java:105)
	at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:755)
	at org.apache.hadoop.hdfs.DistributedFileSystem$15.doCall(DistributedFileSystem.java:751)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.listStatus(DistributedFileSystem.java:751)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1597)
	at org.apache.hadoop.hbase.util.FSUtils.listStatus(FSUtils.java:1617)
	at org.apache.hadoop.hbase.master.cleaner.CleanerChore.chore(CleanerChore.java:123)
	at org.apache.hadoop.hbase.Chore.run(Chore.java:80)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 28 more
2014-12-29 15:20:31,155 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47061; # active connections: 2
2014-12-29 15:20:31,155 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47061 because read count=-1. Number of active connections: 2
2014-12-29 15:20:31,211 DEBUG [sandbox.hortonworks.com,60000,1419863535137-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:20:31,215 DEBUG [htable-pool20-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:20:31,216 DEBUG [htable-pool20-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:21:01,211 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47128; # active connections: 2
2014-12-29 15:21:01,212 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47128 because read count=-1. Number of active connections: 2
2014-12-29 15:21:31,136 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47204; # active connections: 2
2014-12-29 15:21:31,137 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47204 because read count=-1. Number of active connections: 2
2014-12-29 15:22:01,102 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47265; # active connections: 2
2014-12-29 15:22:01,103 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47265 because read count=-1. Number of active connections: 2
2014-12-29 15:22:31,248 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47335; # active connections: 2
2014-12-29 15:22:31,251 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47335 because read count=-1. Number of active connections: 2
2014-12-29 15:23:01,225 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47426; # active connections: 2
2014-12-29 15:23:01,226 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47426 because read count=-1. Number of active connections: 2
2014-12-29 15:23:20,123 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:44087 because read count=-1. Number of active connections: 1
2014-12-29 15:23:20,266 INFO  [main-EventThread] zookeeper.RegionServerTracker: RegionServer ephemeral node deleted, processing expiration [sandbox.hortonworks.com,60020,1419863721426]
2014-12-29 15:23:20,274 DEBUG [main-EventThread] master.AssignmentManager: based on AM, current region=hbase:meta,,1.1588230740 is on server=sandbox.hortonworks.com,60020,1419863721426 server being checked: sandbox.hortonworks.com,60020,1419863721426
2014-12-29 15:23:20,309 DEBUG [main-EventThread] master.ServerManager: Added=sandbox.hortonworks.com,60020,1419863721426 to dead servers, submitted shutdown handler to be executed meta=true
2014-12-29 15:23:20,313 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] handler.MetaServerShutdownHandler: Splitting hbase:meta logs for sandbox.hortonworks.com,60020,1419863721426
2014-12-29 15:23:20,323 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.MasterFileSystem: Log dir for server sandbox.hortonworks.com,60020,1419863721426 does not exist
2014-12-29 15:23:20,324 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1419863721426]
2014-12-29 15:23:20,335 DEBUG [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2014-12-29 15:23:20,360 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: started splitting 0 logs in []
2014-12-29 15:23:20,366 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 5ms
2014-12-29 15:23:20,373 DEBUG [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: based on AM, current region=hbase:meta,,1.1588230740 is on server=sandbox.hortonworks.com,60020,1419863721426 server being checked: sandbox.hortonworks.com,60020,1419863721426
2014-12-29 15:23:20,374 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] handler.MetaServerShutdownHandler: Server sandbox.hortonworks.com,60020,1419863721426 was carrying META. Trying to assign.
2014-12-29 15:23:20,376 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {1588230740 state=OPEN, ts=1419863730997, server=sandbox.hortonworks.com,60020,1419863721426} to {1588230740 state=OFFLINE, ts=1419866600376, server=sandbox.hortonworks.com,60020,1419863721426}
2014-12-29 15:23:20,376 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Offlined 1588230740 from sandbox.hortonworks.com,60020,1419863721426
2014-12-29 15:23:20,506 DEBUG [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2014-12-29 15:23:20,507 DEBUG [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:23:20,521 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] catalog.CatalogTracker: Failed verification of hbase:meta,,1 at address=sandbox.hortonworks.com,60020,1419863721426, exception=java.net.ConnectException: Connection refused
2014-12-29 15:23:20,522 INFO  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-12-29 15:23:20,531 WARN  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Can't move 1588230740, there is no destination server available.
2014-12-29 15:23:20,532 WARN  [MASTER_META_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Unable to determine a plan to assign {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
Mon Dec 29 15:23:21 UTC 2014 Terminating master
Mon Dec 29 15:23:22 UTC 2014 Starting master on sandbox.hortonworks.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30509
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-12-29 15:23:26,778 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2014-12-29 15:23:26,783 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2014-12-29 15:23:26,783 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2014-12-29 15:23:27,479 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2014-12-29 15:23:27,492 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2014-12-29 15:23:27,493 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2014-12-29 15:23:29,365 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2014-12-29 15:23:29,365 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2014-12-29 15:23:29,366 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2014-12-29 15:23:29,366 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-12-29 15:23:29,366 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2014-12-29 15:23:29,366 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2014-12-29 15:23:29,379 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2014-12-29 15:23:29,380 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2014-12-29 15:23:29,391 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=clean znode for master, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:23:29,506 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2014-12-29 15:23:29,506 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64
2014-12-29 15:23:29,506 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/hdp/current/hbase-master/bin/..
2014-12-29 15:23:29,507 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-12-29 15:23:29,507 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hbase
2014-12-29 15:23:29,507 INFO  [main] util.ServerCommandLine: env:HOSTNAME=sandbox.hortonworks.com
2014-12-29 15:23:29,507 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-master.znode
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xmx1024m
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-12-29 15:23:29,508 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:ZOOKEEPER_HOME=/usr/hdp/2.2.0.0-2041/zookeeper
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xmn200m -XX:CMSInitiatingOccupancyFraction=70  -Xms1024m -Xmx1024m
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin:/home/hbase/bin
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF=/usr/hdp/2.2.0.0-2041/hadoop/conf
2014-12-29 15:23:29,509 INFO  [main] util.ServerCommandLine: env:HDP_VERSION=2.2.0.0-2041
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVERS=/etc/hbase/conf/regionservers
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-master.autorestart
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:SERVER_GC_OPTS=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291523
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-master-sandbox.hortonworks.com.log
2014-12-29 15:23:29,510 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-Dhdp.version=2.2.0.0-2041  -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291523  -Xmx1024m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log -Dhbase.home.dir=/usr/hdp/current/hbase-master/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/etc/hbase/conf
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2014-12-29 15:23:29,511 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/hdp/2.2.0.0-2041/hadoop
2014-12-29 15:23:29,515 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-12-29 15:23:29,515 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=::/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:23:29,516 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-12-29 15:23:29,516 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-12-29 15:23:29,516 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-master/bin/..:/usr/hdp/current/hbase-master/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-master/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-master/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-master/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-master/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-master/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-master/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-master/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-master/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-master/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-master/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-master/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-master/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-master/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-master/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/hadoop/.//*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//*::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/*:/usr/hdp/current/tez-client/*:/usr/hdp/current/tez-client/lib/*:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/*:/usr/hdp/2.2.0.0-2041/tez/lib/*:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:USER=hbase
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:HOME=/home/hbase
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-master-sandbox.hortonworks.com
2014-12-29 15:23:29,525 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-12-29 15:23:29,526 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2014-12-29 15:23:29,536 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.65-b04
2014-12-29 15:23:29,536 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -Dhdp.version=2.2.0.0-2041, -XX:+UseConcMarkSweepGC, -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log, -verbose:gc, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -Xloggc:/var/log/hbase/gc.log-201412291523, -Xmx1024m, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log, -Dhbase.home.dir=/usr/hdp/current/hbase-master/bin/.., -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2014-12-29 15:23:29,542 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=clean znode for master connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:23:29,551 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:23:29,564 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:23:29,589 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0010, negotiated timeout = 30000
2014-12-29 15:23:29,793 DEBUG [main] master.HMaster: master/sandbox.hortonworks.com/172.16.144.128:60000 HConnection server-to-server retries=350
2014-12-29 15:23:30,895 INFO  [main] ipc.RpcServer: master/sandbox.hortonworks.com/172.16.144.128:60000: started 10 reader(s).
2014-12-29 15:23:31,569 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-12-29 15:23:32,264 INFO  [main] impl.MetricsSinkAdapter: Sink ganglia started
2014-12-29 15:23:33,189 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-12-29 15:23:33,189 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-12-29 15:23:37,067 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-12-29 15:23:37,068 INFO  [main] zookeeper.ZooKeeper: Session: 0x14a9675840d0010 closed
2014-12-29 15:23:38,665 INFO  [main] master.HMaster: hbase.rootdir=hdfs://sandbox.hortonworks.com:8020/apps/hbase/data, hbase.cluster.distributed=true
2014-12-29 15:23:38,682 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-12-29 15:23:38,866 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2014-12-29 15:23:38,866 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2014-12-29 15:23:38,866 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-master/bin/..:/usr/hdp/current/hbase-master/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-master/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-master/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-master/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-master/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-master/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-master/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-master/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-master/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-master/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-master/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-master/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-master/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-master/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-master/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-12-29 15:23:38,867 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2014-12-29 15:23:38,868 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2014-12-29 15:23:38,868 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2014-12-29 15:23:38,868 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2014-12-29 15:23:38,869 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=master:60000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:23:38,941 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:23:38,951 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:23:38,970 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:23:38,994 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0011, negotiated timeout = 30000
2014-12-29 15:23:39,023 INFO  [main] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure already exists and this is not a retry
2014-12-29 15:23:39,073 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-12-29 15:23:39,089 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2014-12-29 15:23:39,129 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47508; # active connections: 1
2014-12-29 15:23:39,133 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47508 because read count=-1. Number of active connections: 1
2014-12-29 15:23:39,279 INFO  [master:sandbox:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-12-29 15:23:39,359 INFO  [master:sandbox:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-12-29 15:23:39,370 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-12-29 15:23:39,370 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-12-29 15:23:39,399 INFO  [master:sandbox:60000] http.HttpServer: Jetty bound to port 60010
2014-12-29 15:23:39,399 INFO  [master:sandbox:60000] mortbay.log: jetty-6.1.26
2014-12-29 15:23:41,299 INFO  [master:sandbox:60000] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60010
2014-12-29 15:23:41,774 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-12-29 15:23:41,788 INFO  [master:sandbox:60000] master.ActiveMasterManager: Registered Active Master=sandbox.hortonworks.com,60000,1419866614925
2014-12-29 15:23:41,842 INFO  [master:sandbox:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 15:23:43,338 DEBUG [master:sandbox:60000] hbase.HRegionInfo: 1588230740
2014-12-29 15:23:43,553 INFO  [master:sandbox:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2014-12-29 15:23:44,061 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:44246; # active connections: 1
2014-12-29 15:23:44,069 DEBUG [master:sandbox:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-12-29 15:23:44,120 DEBUG [master:sandbox:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2014-12-29 15:23:44,285 INFO  [master:sandbox:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-12-29 15:23:44,307 DEBUG [master:sandbox:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2014-12-29 15:23:44,314 INFO  [master:sandbox:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-12-29 15:23:44,326 INFO  [master:sandbox:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-12-29 15:23:44,494 DEBUG [FifoRpcScheduler.handler1-thread-1] ipc.RpcServer: FifoRpcScheduler.handler1-thread-1: callId: 0 service: RegionServerStatusService methodName: RegionServerStartup size: 45 connection: 172.16.144.128:44246
org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:100)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:23:44,511 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=hconnection-0x46c2c1a8, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:23:44,512 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:23:44,514 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x46c2c1a8 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:23:44,518 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:23:44,521 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0014, negotiated timeout = 30000
2014-12-29 15:23:44,541 DEBUG [master:sandbox:60000] ipc.RpcClient: Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@3195e45d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2014-12-29 15:23:44,561 DEBUG [master:sandbox:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@258fbc3e
2014-12-29 15:23:44,676 INFO  [master:sandbox:60000] master.HMaster: Server active/primary master=sandbox.hortonworks.com,60000,1419866614925, sessionid=0x14a9675840d0011, setting cluster-up flag (Was=true)
2014-12-29 15:23:44,709 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/online-snapshot/acquired already exists and this is not a retry
2014-12-29 15:23:44,715 INFO  [master:sandbox:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase-unsecure/online-snapshot/acquired /hbase-unsecure/online-snapshot/reached /hbase-unsecure/online-snapshot/abort
2014-12-29 15:23:44,721 DEBUG [master:sandbox:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sandbox.hortonworks.com,60000,1419866614925
2014-12-29 15:23:44,866 INFO  [master:sandbox:60000] config.PolicyRefresher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval: 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:44,882 INFO  [master:sandbox:60000] config.ConfigWatcher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval(milliSeconds): 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:46,131 INFO  [master:sandbox:60000] config.ConfigWatcher: Policy Manager not available, using the last stored Policy File/etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:46,132 INFO  [master:sandbox:60000] config.ConfigWatcher: Unable to access Policy cache file...XAagent authorization not enabled
2014-12-29 15:23:46,132 ERROR [master:sandbox:60000] config.ConfigWatcher: Unable to get a valid response for isFileChanged()  call for [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase] = response code found [400]
2014-12-29 15:23:46,136 INFO  [master:sandbox:60000] hbase.HBaseAccessControllerFactory: Created a new instance of class: [com.xasecure.pdp.hbase.XASecureAuthorizer] for HBase Access verification.
2014-12-29 15:23:46,145 DEBUG [master:sandbox:60000] master.HMaster: Registered master coprocessor service: service=AccessControlService
2014-12-29 15:23:46,153 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: creating..
2014-12-29 15:23:46,154 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: initializing..
2014-12-29 15:23:46,320 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: creating..
2014-12-29 15:23:46,323 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:23:46,323 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider): creating..
2014-12-29 15:23:46,323 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.DbAuditProvider)
2014-12-29 15:23:46,356 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:23:46,356 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider): creating..
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.hdfs.HdfsAuditProvider)
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider).init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.init()
2014-12-29 15:23:46,357 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:23:46,461 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider).init()
2014-12-29 15:23:46,462 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:23:46,462 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:23:46,462 INFO  [master:sandbox:60000] hdfs.HdfsAuditProvider: HdfsAuditProvider.init()
2014-12-29 15:23:46,462 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:23:46,466 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.start()
2014-12-29 15:23:46,466 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: init()
2014-12-29 15:23:46,467 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2014-12-29 15:23:46,619 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Policy Manager not available, using the last stored Policy File/etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:46,620 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to access Policy cache file...XAagent authorization not enabled
2014-12-29 15:23:46,620 ERROR [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to get a valid response for isFileChanged()  call for [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase] = response code found [400]
2014-12-29 15:23:47,526 DEBUG [FifoRpcScheduler.handler1-thread-2] ipc.RpcServer: FifoRpcScheduler.handler1-thread-2: callId: 1 service: RegionServerStatusService methodName: RegionServerStartup size: 45 connection: 172.16.144.128:44246
org.apache.hadoop.hbase.ipc.ServerNotRunningYetException: Server is not running yet
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:100)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:23:48,353 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2014-12-29 15:23:48,354 INFO  [master:sandbox:60000] hbase.XaSecureAuthorizationCoprocessor: Start() - Adding Super User(hbase)
2014-12-29 15:23:48,361 INFO  [master:sandbox:60000] coprocessor.CoprocessorHost: System coprocessor com.xasecure.authorization.hbase.XaSecureAuthorizationCoprocessor was loaded successfully with priority (536870911).
2014-12-29 15:23:48,380 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:23:48,381 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:23:48,381 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:23:48,401 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:23:48,402 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sandbox:60000, corePoolSize=10, maxPoolSize=10
2014-12-29 15:23:48,402 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sandbox:60000, corePoolSize=1, maxPoolSize=1
2014-12-29 15:23:48,406 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-12-29 15:23:48,447 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=replicationLogCleaner, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:23:48,465 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:23:48,469 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:23:48,473 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0015, negotiated timeout = 30000
2014-12-29 15:23:48,475 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:23:48,518 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/replication/rs already exists and this is not a retry
2014-12-29 15:23:48,518 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-12-29 15:23:48,529 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-12-29 15:23:48,539 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-12-29 15:23:48,552 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-12-29 15:23:48,553 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-12-29 15:23:48,558 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:23:48,636 INFO  [DestinationDispatcherThread-1419866628353] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): failed in opening file hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20141229/sandbox.hortonworks.com-audit.log. Will try opening hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20141229/sandbox.hortonworks.com-audit-1.log
2014-12-29 15:23:48,636 INFO  [DestinationDispatcherThread-1419866628353] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): opening file for write hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20141229/sandbox.hortonworks.com-audit-1.log
2014-12-29 15:23:48,640 WARN  [DestinationDispatcherThread-1419866628353] hdfs.HdfsAuditProvider: HdfsLogDestination.createParents() failed
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=EXECUTE, inode="/ranger/audit/hbaseMaster":hbase:hdfs:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:208)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:171)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6515)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:4143)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:838)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:821)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1990)
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1118)
	at org.apache.hadoop.hdfs.DistributedFileSystem$18.doCall(DistributedFileSystem.java:1114)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1114)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1400)
	at com.xasecure.audit.provider.hdfs.HdfsLogDestination.createParents(HdfsLogDestination.java:370)
	at com.xasecure.audit.provider.hdfs.HdfsLogDestination.openFile(HdfsLogDestination.java:271)
	at com.xasecure.audit.provider.hdfs.HdfsLogDestination.start(HdfsLogDestination.java:113)
	at com.xasecure.audit.provider.DestinationDispatcherThread.doRun(LocalFileLogBuffer.java:435)
	at com.xasecure.audit.provider.DestinationDispatcherThread.access$000(LocalFileLogBuffer.java:362)
	at com.xasecure.audit.provider.DestinationDispatcherThread$1.run(LocalFileLogBuffer.java:425)
	at com.xasecure.audit.provider.DestinationDispatcherThread$1.run(LocalFileLogBuffer.java:422)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:356)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1608)
	at com.xasecure.audit.provider.DestinationDispatcherThread.run(LocalFileLogBuffer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=EXECUTE, inode="/ranger/audit/hbaseMaster":hbase:hdfs:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:208)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:171)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6515)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:4143)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:838)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getFileInfo(ClientNamenodeProtocolServerSideTranslatorPB.java:821)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:752)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.getFileInfo(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.getFileInfo(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1988)
	... 16 more
2014-12-29 15:23:48,664 WARN  [DestinationDispatcherThread-1419866628353] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile() failed
org.apache.hadoop.security.AccessControlException: Permission denied: user=hbase, access=EXECUTE, inode="/ranger/audit/hbaseMaster":hbase:hdfs:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:208)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:171)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6515)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6497)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6449)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2715)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2634)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2521)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1731)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1668)
	at org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1593)
	at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:397)
	at org.apache.hadoop.hdfs.DistributedFileSystem$6.doCall(DistributedFileSystem.java:393)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:393)
	at org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:337)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:908)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:889)
	at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:786)
	at com.xasecure.audit.provider.hdfs.HdfsLogDestination.openFile(HdfsLogDestination.java:272)
	at com.xasecure.audit.provider.hdfs.HdfsLogDestination.start(HdfsLogDestination.java:113)
	at com.xasecure.audit.provider.DestinationDispatcherThread.doRun(LocalFileLogBuffer.java:435)
	at com.xasecure.audit.provider.DestinationDispatcherThread.access$000(LocalFileLogBuffer.java:362)
	at com.xasecure.audit.provider.DestinationDispatcherThread$1.run(LocalFileLogBuffer.java:425)
	at com.xasecure.audit.provider.DestinationDispatcherThread$1.run(LocalFileLogBuffer.java:422)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:356)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1608)
	at com.xasecure.audit.provider.DestinationDispatcherThread.run(LocalFileLogBuffer.java:422)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Permission denied: user=hbase, access=EXECUTE, inode="/ranger/audit/hbaseMaster":hbase:hdfs:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:208)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:171)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6515)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:6497)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:6449)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2715)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2634)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2521)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:566)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:394)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.create(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:295)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.create(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.create(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:1726)
	... 20 more
2014-12-29 15:23:48,695 WARN  [DestinationDispatcherThread-1419866628353] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): failed to open file for write hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20141229/sandbox.hortonworks.com-audit-1.log
2014-12-29 15:23:50,070 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1512 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:23:50,568 INFO  [FifoRpcScheduler.handler1-thread-3] master.ServerManager: Registering server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:23:50,575 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 2017 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:23:50,577 INFO  [FifoRpcScheduler.handler1-thread-3] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 15:23:50,607 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase-unsecure/rs/sandbox.hortonworks.com,60020,1419866617361 data: PBUF
2014-12-29 15:23:52,082 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 3524 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:23:52,678 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Policy Manager not available, using the last stored Policy File/etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:52,678 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to access Policy cache file...XAagent authorization not enabled
2014-12-29 15:23:52,678 ERROR [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to get a valid response for isFileChanged()  call for [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase] = response code found [400]
2014-12-29 15:23:53,086 INFO  [master:sandbox:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4528 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-12-29 15:23:53,095 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419866617361 belongs to an existing region server
2014-12-29 15:23:54,177 INFO  [master:sandbox:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-12-29 15:23:54,180 WARN  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/meta-region-server already deleted, retry=false
2014-12-29 15:23:54,319 DEBUG [master:sandbox:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sandbox.hortonworks.com,60020,1419866617361; 1 (online=1, available=1) available servers, forceNewPlan=false
2014-12-29 15:23:54,320 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-12-29 15:23:54,346 INFO  [master:sandbox:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:23:54,347 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1419866634320, server=null} to {1588230740 state=PENDING_OPEN, ts=1419866634347, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:23:54,347 DEBUG [master:sandbox:60000] master.ServerManager: New admin connection to sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:23:54,477 DEBUG [master:sandbox:60000] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2014-12-29 15:23:54,482 DEBUG [master:sandbox:60000] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:23:55,033 INFO  [master:sandbox:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-12-29 15:23:55,123 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419866617361, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1419866634347, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:23:55,125 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1419866634347, server=sandbox.hortonworks.com,60020,1419866617361} to {1588230740 state=OPENING, ts=1419866635125, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:23:58,781 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Policy Manager not available, using the last stored Policy File/etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:23:58,782 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to access Policy cache file...XAagent authorization not enabled
2014-12-29 15:23:58,782 ERROR [XaSecureConfigURLWatcher] config.ConfigWatcher: Unable to get a valid response for isFileChanged()  call for [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase] = response code found [400]
2014-12-29 15:24:01,203 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47599; # active connections: 2
2014-12-29 15:24:01,205 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47599 because read count=-1. Number of active connections: 2
2014-12-29 15:24:05,087 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: URL: [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase], isModified: true, lastModifiedTime:1419866643000
2014-12-29 15:24:09,464 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419866617361, region=1588230740, current_state={1588230740 state=OPENING, ts=1419866635125, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:09,464 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1419866635125, server=sandbox.hortonworks.com,60020,1419866617361} to {1588230740 state=OPEN, ts=1419866649464, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:09,470 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sandbox.hortonworks.com,60020,1419866617361; deleting unassigned node
2014-12-29 15:24:09,482 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-12-29 15:24:09,490 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1419866649464, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:09,490 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sandbox.hortonworks.com,60020,1419866617361 {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:24:09,491 INFO  [master:sandbox:60000] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:09,685 DEBUG [htable-pool3-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:24:09,686 DEBUG [htable-pool3-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:24:09,855 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-12-29 15:24:09,923 INFO  [master:sandbox:60000] master.AssignmentManager: Clean cluster startup. Assigning userregions
2014-12-29 15:24:09,923 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleting any existing unassigned nodes
2014-12-29 15:24:09,936 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2014-12-29 15:24:09,973 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2014-12-29 15:24:10,044 INFO  [master:sandbox:60000] balancer.BaseLoadBalancer: Reassigned 1 regions. 1 retained the pre-restart assignment. 
2014-12-29 15:24:10,044 DEBUG [master:sandbox:60000] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:10,055 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node db8d9fe8d0471c86ef90518de99b1581 with OFFLINE state
2014-12-29 15:24:10,069 DEBUG [main-EventThread] master.OfflineCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419866649922, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:10,070 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419866649922, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:10,071 INFO  [master:sandbox:60000] master.AssignmentManager: sandbox.hortonworks.com,60020,1419866617361 unassigned znodes=1 of total=1
2014-12-29 15:24:10,072 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419866650054, server=null} to {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419866650072, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:10,202 DEBUG [master:sandbox:60000] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:10,259 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419866617361, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419866650072, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:10,259 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419866650072, server=sandbox.hortonworks.com,60020,1419866617361} to {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419866650259, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:11,081 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419866617361, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419866650259, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:11,081 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419866650259, server=sandbox.hortonworks.com,60020,1419866617361} to {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419866651081, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:11,081 DEBUG [AM.ZK.Worker-pool2-t6] handler.OpenedRegionHandler: Handling OPENED of db8d9fe8d0471c86ef90518de99b1581 from sandbox.hortonworks.com,60020,1419866617361; deleting unassigned node
2014-12-29 15:24:11,088 DEBUG [AM.ZK.Worker-pool2-t6] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node db8d9fe8d0471c86ef90518de99b1581 in expected state RS_ZK_REGION_OPENED
2014-12-29 15:24:11,095 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Znode hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581. deleted, state: {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419866651081, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:11,096 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Onlined db8d9fe8d0471c86ef90518de99b1581 on sandbox.hortonworks.com,60020,1419866617361 {ENCODED => db8d9fe8d0471c86ef90518de99b1581, NAME => 'hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:24:11,190 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-12-29 15:24:11,195 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-12-29 15:24:11,391 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/default already exists and this is not a retry
2014-12-29 15:24:11,401 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/hbase already exists and this is not a retry
2014-12-29 15:24:11,404 INFO  [master:sandbox:60000] master.HMaster: Master has completed initialization
2014-12-29 15:24:11,462 INFO  [master:sandbox:60000] master.HMaster: Client=null/null create 'hbase:acl', {NAME => 'l', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'}
2014-12-29 15:24:11,502 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000000
2014-12-29 15:24:11,570 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table hbase:acl
2014-12-29 15:24:12,450 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/hbase/acl/.tabledesc/.tableinfo.0000000001
2014-12-29 15:24:12,471 INFO  [RegionOpenAndInitThread-hbase:acl-1] regionserver.HRegion: creating HRegion hbase:acl HTD == 'hbase:acl', {NAME => 'l', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == hbase:acl
2014-12-29 15:24:12,564 DEBUG [RegionOpenAndInitThread-hbase:acl-1] regionserver.HRegion: Instantiated hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.
2014-12-29 15:24:12,564 DEBUG [RegionOpenAndInitThread-hbase:acl-1] regionserver.HRegion: Closing hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.: disabling compactions & flushes
2014-12-29 15:24:12,564 DEBUG [RegionOpenAndInitThread-hbase:acl-1] regionserver.HRegion: Updates disabled for region hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.
2014-12-29 15:24:12,565 INFO  [RegionOpenAndInitThread-hbase:acl-1] regionserver.HRegion: Closed hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.
2014-12-29 15:24:12,698 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2014-12-29 15:24:12,728 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:12,731 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 3b4c25a80758728ef4f550bbd330f05b with OFFLINE state
2014-12-29 15:24:12,738 DEBUG [main-EventThread] master.OfflineCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419866652698, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:12,738 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419866652698, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:12,738 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1419866617361 unassigned znodes=1 of total=1
2014-12-29 15:24:12,739 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419866652731, server=null} to {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419866652739, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,775 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:24:12,785 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000000
2014-12-29 15:24:12,785 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, hbase:acl, creation successful
2014-12-29 15:24:12,809 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419866617361, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419866652739, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,809 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419866652739, server=sandbox.hortonworks.com,60020,1419866617361} to {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419866652809, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,943 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419866617361, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419866652809, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,943 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419866652809, server=sandbox.hortonworks.com,60020,1419866617361} to {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1419866652943, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,944 DEBUG [AM.ZK.Worker-pool2-t11] handler.OpenedRegionHandler: Handling OPENED of 3b4c25a80758728ef4f550bbd330f05b from sandbox.hortonworks.com,60020,1419866617361; deleting unassigned node
2014-12-29 15:24:12,949 DEBUG [AM.ZK.Worker-pool2-t11] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 3b4c25a80758728ef4f550bbd330f05b in expected state RS_ZK_REGION_OPENED
2014-12-29 15:24:12,955 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b. deleted, state: {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1419866652943, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:24:12,955 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined 3b4c25a80758728ef4f550bbd330f05b on sandbox.hortonworks.com,60020,1419866617361 {ENCODED => 3b4c25a80758728ef4f550bbd330f05b, NAME => 'hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:24:31,229 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47699; # active connections: 2
2014-12-29 15:24:31,230 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47699 because read count=-1. Number of active connections: 2
2014-12-29 15:24:48,300 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: URL: [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase], isModified: true, lastModifiedTime:1419866686000
2014-12-29 15:25:01,330 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47789; # active connections: 2
2014-12-29 15:25:01,331 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47789 because read count=-1. Number of active connections: 2
2014-12-29 15:25:31,219 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47885; # active connections: 2
2014-12-29 15:25:31,220 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47885 because read count=-1. Number of active connections: 2
2014-12-29 15:25:46,324 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 02:00.000 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2014-12-29 15:25:46,324 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2014-12-29 15:25:46,360 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 02:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2014-12-29 15:25:46,362 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2014-12-29 15:26:01,308 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:47973; # active connections: 2
2014-12-29 15:26:01,309 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:47973 because read count=-1. Number of active connections: 2
2014-12-29 15:26:31,295 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48073; # active connections: 2
2014-12-29 15:26:31,296 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48073 because read count=-1. Number of active connections: 2
2014-12-29 15:27:01,187 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48157; # active connections: 2
2014-12-29 15:27:01,187 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48157 because read count=-1. Number of active connections: 2
2014-12-29 15:27:31,200 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48258; # active connections: 2
2014-12-29 15:27:31,201 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48258 because read count=-1. Number of active connections: 2
2014-12-29 15:28:01,343 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48344; # active connections: 2
2014-12-29 15:28:01,345 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48344 because read count=-1. Number of active connections: 2
2014-12-29 15:28:31,108 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48439; # active connections: 2
2014-12-29 15:28:31,108 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48439 because read count=-1. Number of active connections: 2
2014-12-29 15:28:41,049 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48466; # active connections: 2
2014-12-29 15:28:41,111 INFO  [FifoRpcScheduler.handler1-thread-41] master.HMaster: Client=hbase//172.16.144.128 create 'iemployee', {NAME => 'insurance', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'payroll', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'personal', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'skills', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2014-12-29 15:28:41,131 DEBUG [FifoRpcScheduler.handler1-thread-41] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/iemployee/write-master:600000000000000
2014-12-29 15:28:41,134 DEBUG [htable-pool12-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:28:41,135 DEBUG [htable-pool12-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:28:41,164 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table iemployee
2014-12-29 15:28:41,165 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:54.840 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2014-12-29 15:28:41,165 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=2, outLogs=2, dropped=0
2014-12-29 15:28:41,261 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/iemployee/.tabledesc/.tableinfo.0000000001
2014-12-29 15:28:41,271 INFO  [RegionOpenAndInitThread-iemployee-1] regionserver.HRegion: creating HRegion iemployee HTD == 'iemployee', {NAME => 'insurance', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'payroll', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'personal', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'skills', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == iemployee
2014-12-29 15:28:41,318 DEBUG [RegionOpenAndInitThread-iemployee-1] regionserver.HRegion: Instantiated iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.
2014-12-29 15:28:41,318 DEBUG [RegionOpenAndInitThread-iemployee-1] regionserver.HRegion: Closing iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.: disabling compactions & flushes
2014-12-29 15:28:41,318 DEBUG [RegionOpenAndInitThread-iemployee-1] regionserver.HRegion: Updates disabled for region iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.
2014-12-29 15:28:41,318 INFO  [RegionOpenAndInitThread-iemployee-1] regionserver.HRegion: Closed iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.
2014-12-29 15:28:41,384 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2014-12-29 15:28:41,474 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:28:41,474 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node bf93a1f8a3cdac77590e5033ba6ae70f with OFFLINE state
2014-12-29 15:28:41,478 DEBUG [main-EventThread] master.OfflineCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419866921386, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:28:41,480 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419866921386, server=null}, server=sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:28:41,485 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1419866617361 unassigned znodes=1 of total=1
2014-12-29 15:28:41,485 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419866921474, server=null} to {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419866921485, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,486 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2014-12-29 15:28:41,486 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:28:41,596 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1419866617361
2014-12-29 15:28:41,617 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/iemployee/write-master:600000000000000
2014-12-29 15:28:41,617 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, iemployee, creation successful
2014-12-29 15:28:41,623 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419866617361, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419866921485, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,623 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419866921485, server=sandbox.hortonworks.com,60020,1419866617361} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419866921623, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,868 DEBUG [AM.ZK.Worker-pool2-t16] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419866617361, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419866921623, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,868 INFO  [AM.ZK.Worker-pool2-t16] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419866921623, server=sandbox.hortonworks.com,60020,1419866617361} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1419866921868, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,869 DEBUG [AM.ZK.Worker-pool2-t16] handler.OpenedRegionHandler: Handling OPENED of bf93a1f8a3cdac77590e5033ba6ae70f from sandbox.hortonworks.com,60020,1419866617361; deleting unassigned node
2014-12-29 15:28:41,874 DEBUG [AM.ZK.Worker-pool2-t16] zookeeper.ZKAssign: master:60000-0x14a9675840d0011, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node bf93a1f8a3cdac77590e5033ba6ae70f in expected state RS_ZK_REGION_OPENED
2014-12-29 15:28:41,875 DEBUG [AM.ZK.Worker-pool2-t18] master.AssignmentManager: Znode iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f. deleted, state: {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1419866921868, server=sandbox.hortonworks.com,60020,1419866617361}
2014-12-29 15:28:41,876 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Onlined bf93a1f8a3cdac77590e5033ba6ae70f on sandbox.hortonworks.com,60020,1419866617361 {ENCODED => bf93a1f8a3cdac77590e5033ba6ae70f, NAME => 'iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:28:42,839 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48466 because read count=-1. Number of active connections: 2
2014-12-29 15:29:01,265 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48527; # active connections: 2
2014-12-29 15:29:01,266 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48527 because read count=-1. Number of active connections: 2
2014-12-29 15:29:10,271 DEBUG [sandbox.hortonworks.com,60000,1419866614925-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:29:36,369 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48622; # active connections: 2
2014-12-29 15:29:36,372 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48622 because read count=-1. Number of active connections: 2
2014-12-29 15:29:46,369 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 02:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2014-12-29 15:29:46,369 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=2, outLogs=2, dropped=0
2014-12-29 15:30:01,282 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48703; # active connections: 2
2014-12-29 15:30:01,283 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48703 because read count=-1. Number of active connections: 2
Mon Dec 29 15:30:05 UTC 2014 Terminating master
2014-12-29 15:30:05,978 INFO  [Thread-18] provider.DbAuditProvider: DbAuditProvider.waitToComplete()
2014-12-29 15:30:31,310 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48799; # active connections: 2
2014-12-29 15:30:31,312 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48799 because read count=-1. Number of active connections: 2
2014-12-29 15:30:40,952 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2014-12-29 15:30:40,953 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2014-12-29 15:30:40,953 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2014-12-29 15:30:42,110 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2014-12-29 15:30:42,110 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2014-12-29 15:30:42,111 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2014-12-29 15:30:42,111 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-12-29 15:30:42,111 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2014-12-29 15:30:42,111 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-master/bin/..:/usr/hdp/current/hbase-master/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-master/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-master/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-master/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-master/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-master/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-master/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-master/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-master/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-master/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-master/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-master/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-master/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-master/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-master/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-master/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-master/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-master/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-master/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-master/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-master/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-master/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-master/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-master/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-master/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-master/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-master/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-master/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-master/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-master/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-master/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-master/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-master/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-master/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2014-12-29 15:30:42,113 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2014-12-29 15:30:42,114 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2014-12-29 15:30:42,115 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=clean znode for master, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:30:42,199 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:30:42,200 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=clean znode for master connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:30:42,230 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:30:42,258 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0020, negotiated timeout = 30000
Mon Dec 29 15:30:45 UTC 2014 Starting master on sandbox.hortonworks.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 30509
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2014-12-29 15:30:45,572 INFO  [main-EventThread] zookeeper.ClientCnxn: EventThread shut down
2014-12-29 15:30:45,572 INFO  [main] zookeeper.ZooKeeper: Session: 0x14a9675840d0020 closed
2014-12-29 15:30:48,567 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2014-12-29 15:30:48,568 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2014-12-29 15:30:48,568 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:TERM=xterm
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/hdp/current/hbase-client/bin/..
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hbase
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:HOSTNAME=sandbox.hortonworks.com
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-master.znode
2014-12-29 15:30:49,572 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xmx1024m
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:ZOOKEEPER_HOME=/usr/hdp/2.2.0.0-2041/zookeeper
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xmn200m -XX:CMSInitiatingOccupancyFraction=70  -Xms1024m -Xmx1024m
2014-12-29 15:30:49,573 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin:/home/hbase/bin
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF=/usr/hdp/2.2.0.0-2041/hadoop/conf
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:HDP_VERSION=2.2.0.0-2041
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVERS=/etc/hbase/conf/regionservers
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-master.autorestart
2014-12-29 15:30:49,574 INFO  [main] util.ServerCommandLine: env:SERVER_GC_OPTS=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291530
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-master-sandbox.hortonworks.com.log
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-Dhdp.version=2.2.0.0-2041  -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201412291530  -Xmx1024m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/etc/hbase/conf
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2014-12-29 15:30:49,575 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/hdp/2.2.0.0-2041/hadoop
2014-12-29 15:30:49,576 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2014-12-29 15:30:49,576 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=::/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:30:49,576 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2014-12-29 15:30:49,576 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2014-12-29 15:30:49,576 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/hadoop/.//*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//*::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/*:/usr/hdp/current/tez-client/*:/usr/hdp/current/tez-client/lib/*:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/*:/usr/hdp/2.2.0.0-2041/tez/lib/*:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:USER=hbase
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:HOME=/home/hbase
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2014-12-29 15:30:49,577 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2014-12-29 15:30:49,578 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-master-sandbox.hortonworks.com
2014-12-29 15:30:49,578 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2014-12-29 15:30:49,578 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2014-12-29 15:30:49,581 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.65-b04
2014-12-29 15:30:49,582 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -Dhdp.version=2.2.0.0-2041, -XX:+UseConcMarkSweepGC, -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log, -verbose:gc, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -Xloggc:/var/log/hbase/gc.log-201412291530, -Xmx1024m, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log, -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.., -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2014-12-29 15:30:49,748 DEBUG [main] master.HMaster: master/sandbox.hortonworks.com/172.16.144.128:60000 HConnection server-to-server retries=350
2014-12-29 15:30:50,829 INFO  [main] ipc.RpcServer: master/sandbox.hortonworks.com/172.16.144.128:60000: started 10 reader(s).
2014-12-29 15:30:51,216 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2014-12-29 15:30:51,698 INFO  [main] impl.MetricsSinkAdapter: Sink ganglia started
2014-12-29 15:30:52,222 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2014-12-29 15:30:52,222 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2014-12-29 15:30:56,264 INFO  [main] master.HMaster: hbase.rootdir=hdfs://sandbox.hortonworks.com:8020/apps/hbase/data, hbase.cluster.distributed=true
2014-12-29 15:30:56,302 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2014-12-29 15:30:56,636 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2014-12-29 15:30:56,637 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2014-12-29 15:30:56,638 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=master:60000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:30:56,666 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:30:56,675 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:30:56,683 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:30:56,699 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0021, negotiated timeout = 30000
2014-12-29 15:30:56,714 INFO  [main] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure already exists and this is not a retry
2014-12-29 15:30:56,749 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2014-12-29 15:30:56,750 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2014-12-29 15:30:56,942 INFO  [master:sandbox:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2014-12-29 15:30:57,080 INFO  [master:sandbox:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2014-12-29 15:30:57,108 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2014-12-29 15:30:57,108 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2014-12-29 15:30:57,179 INFO  [master:sandbox:60000] http.HttpServer: Jetty bound to port 60010
2014-12-29 15:30:57,180 INFO  [master:sandbox:60000] mortbay.log: jetty-6.1.26
2014-12-29 15:30:59,267 INFO  [master:sandbox:60000] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60010
2014-12-29 15:30:59,668 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2014-12-29 15:30:59,673 INFO  [master:sandbox:60000] master.ActiveMasterManager: Registered Active Master=sandbox.hortonworks.com,60000,1419867053067
2014-12-29 15:30:59,702 INFO  [master:sandbox:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 15:31:01,071 DEBUG [master:sandbox:60000] hbase.HRegionInfo: 1588230740
2014-12-29 15:31:01,109 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48889; # active connections: 1
2014-12-29 15:31:01,111 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48889 because read count=-1. Number of active connections: 1
2014-12-29 15:31:01,201 INFO  [master:sandbox:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2014-12-29 15:31:01,483 DEBUG [master:sandbox:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2014-12-29 15:31:01,537 DEBUG [master:sandbox:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2014-12-29 15:31:01,684 INFO  [master:sandbox:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2014-12-29 15:31:01,699 DEBUG [master:sandbox:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2014-12-29 15:31:01,709 INFO  [master:sandbox:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2014-12-29 15:31:01,719 INFO  [master:sandbox:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2014-12-29 15:31:01,835 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=hconnection-0x770ed526, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:31:01,836 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x770ed526 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:31:01,840 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:31:01,841 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:31:01,845 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0022, negotiated timeout = 30000
2014-12-29 15:31:01,861 DEBUG [master:sandbox:60000] ipc.RpcClient: Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@52e6891d, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2014-12-29 15:31:01,892 DEBUG [master:sandbox:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@7debe95d
2014-12-29 15:31:02,022 INFO  [master:sandbox:60000] master.HMaster: Server active/primary master=sandbox.hortonworks.com,60000,1419867053067, sessionid=0x14a9675840d0021, setting cluster-up flag (Was=true)
2014-12-29 15:31:02,051 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/online-snapshot/acquired already exists and this is not a retry
2014-12-29 15:31:02,055 INFO  [master:sandbox:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase-unsecure/online-snapshot/acquired /hbase-unsecure/online-snapshot/reached /hbase-unsecure/online-snapshot/abort
2014-12-29 15:31:02,059 DEBUG [master:sandbox:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sandbox.hortonworks.com,60000,1419867053067
2014-12-29 15:31:02,161 INFO  [master:sandbox:60000] config.PolicyRefresher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval: 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:31:02,170 INFO  [master:sandbox:60000] config.ConfigWatcher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval(milliSeconds): 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2014-12-29 15:31:03,657 INFO  [master:sandbox:60000] config.ConfigWatcher: URL: [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase], isModified: true, lastModifiedTime:1419866686000
2014-12-29 15:31:03,681 INFO  [master:sandbox:60000] hbase.HBaseAccessControllerFactory: Created a new instance of class: [com.xasecure.pdp.hbase.XASecureAuthorizer] for HBase Access verification.
2014-12-29 15:31:03,825 DEBUG [master:sandbox:60000] master.HMaster: Registered master coprocessor service: service=AccessControlService
2014-12-29 15:31:03,831 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: creating..
2014-12-29 15:31:03,831 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: initializing..
2014-12-29 15:31:03,840 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: creating..
2014-12-29 15:31:03,842 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:31:03,842 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider): creating..
2014-12-29 15:31:03,842 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.DbAuditProvider)
2014-12-29 15:31:03,845 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:31:03,845 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider): creating..
2014-12-29 15:31:03,860 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.hdfs.HdfsAuditProvider)
2014-12-29 15:31:03,861 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2014-12-29 15:31:03,861 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2014-12-29 15:31:03,861 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2014-12-29 15:31:03,861 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:31:03,861 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:31:03,862 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider).init()
2014-12-29 15:31:03,862 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:31:03,862 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:31:03,862 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.init()
2014-12-29 15:31:03,862 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:31:03,991 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider).init()
2014-12-29 15:31:03,991 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2014-12-29 15:31:03,991 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:31:03,991 INFO  [master:sandbox:60000] hdfs.HdfsAuditProvider: HdfsAuditProvider.init()
2014-12-29 15:31:03,992 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2014-12-29 15:31:03,999 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.start()
2014-12-29 15:31:03,999 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: init()
2014-12-29 15:31:04,000 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2014-12-29 15:31:05,441 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2014-12-29 15:31:05,447 INFO  [master:sandbox:60000] hbase.XaSecureAuthorizationCoprocessor: Start() - Adding Super User(hbase)
2014-12-29 15:31:05,460 INFO  [master:sandbox:60000] coprocessor.CoprocessorHost: System coprocessor com.xasecure.authorization.hbase.XaSecureAuthorizationCoprocessor was loaded successfully with priority (536870911).
2014-12-29 15:31:05,469 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:31:05,469 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:31:05,470 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:31:05,470 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2014-12-29 15:31:05,470 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sandbox:60000, corePoolSize=10, maxPoolSize=10
2014-12-29 15:31:05,471 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sandbox:60000, corePoolSize=1, maxPoolSize=1
2014-12-29 15:31:05,474 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2014-12-29 15:31:05,497 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=replicationLogCleaner, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2014-12-29 15:31:05,501 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/172.16.144.128:2181. Will not attempt to authenticate using SASL (unknown error)
2014-12-29 15:31:05,502 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/172.16.144.128:2181, initiating session
2014-12-29 15:31:05,502 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2014-12-29 15:31:05,508 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/172.16.144.128:2181, sessionid = 0x14a9675840d0023, negotiated timeout = 30000
2014-12-29 15:31:05,536 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/replication/rs already exists and this is not a retry
2014-12-29 15:31:05,536 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2014-12-29 15:31:05,544 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2014-12-29 15:31:05,550 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2014-12-29 15:31:05,555 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2014-12-29 15:31:05,556 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2014-12-29 15:31:05,560 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:05,606 INFO  [DestinationDispatcherThread-1419867065441] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): opening file for write hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20141229/sandbox.hortonworks.com-audit.log
2014-12-29 15:31:07,068 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1508 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:08,579 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 3019 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:10,091 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 4531 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:11,599 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 6038 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:13,111 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 7550 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:14,623 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 9063 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:16,135 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 10575 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:17,650 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 12088 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:19,172 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 13612 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:20,682 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 15122 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:22,196 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 16636 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:23,712 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 18152 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:25,229 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 19668 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:26,738 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 21178 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:28,249 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 22689 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:29,762 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 24202 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:31,275 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 25715 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:31,314 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:48988; # active connections: 1
2014-12-29 15:31:31,315 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:48988 because read count=-1. Number of active connections: 1
2014-12-29 15:31:32,781 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 27221 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:34,290 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 28730 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:35,799 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 30239 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:37,314 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 31754 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:38,820 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 33260 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:40,328 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 34768 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:41,263 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:43450; # active connections: 1
2014-12-29 15:31:41,458 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:41,467 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2014-12-29 15:31:41,486 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 35926 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2014-12-29 15:31:41,539 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase-unsecure/rs/sandbox.hortonworks.com,60020,1419867094938 data: PBUF
2014-12-29 15:31:42,996 INFO  [master:sandbox:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 37436 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2014-12-29 15:31:43,004 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938 belongs to an existing region server
2014-12-29 15:31:43,236 DEBUG [master:sandbox:60000] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2014-12-29 15:31:43,265 DEBUG [master:sandbox:60000] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:31:43,994 INFO  [master:sandbox:60000] catalog.CatalogTracker: Failed verification of hbase:meta,,1 at address=sandbox.hortonworks.com,60020,1419866617361, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sandbox.hortonworks.com,60020,1419867094938
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2774)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4257)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionInfo(HRegionServer.java:3599)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20370)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:745)

2014-12-29 15:31:44,005 INFO  [master:sandbox:60000] master.MasterFileSystem: Log dir for server sandbox.hortonworks.com,60020,1419866617361 does not exist
2014-12-29 15:31:44,005 INFO  [master:sandbox:60000] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1419866617361]
2014-12-29 15:31:44,005 DEBUG [master:sandbox:60000] master.SplitLogManager: Scheduling batch of logs to split
2014-12-29 15:31:44,006 INFO  [master:sandbox:60000] master.SplitLogManager: started splitting 0 logs in []
2014-12-29 15:31:44,007 INFO  [master:sandbox:60000] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [] in 1ms
2014-12-29 15:31:44,007 INFO  [master:sandbox:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2014-12-29 15:31:44,183 DEBUG [master:sandbox:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sandbox.hortonworks.com,60020,1419867094938; 1 (online=1, available=1) available servers, forceNewPlan=false
2014-12-29 15:31:44,183 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating (or updating) unassigned node 1588230740 with OFFLINE state
2014-12-29 15:31:44,226 INFO  [master:sandbox:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:44,227 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1419867104183, server=null} to {1588230740 state=PENDING_OPEN, ts=1419867104227, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:44,227 DEBUG [master:sandbox:60000] master.ServerManager: New admin connection to sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:45,119 INFO  [master:sandbox:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2014-12-29 15:31:45,187 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419867094938, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1419867104227, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:45,187 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1419867104227, server=sandbox.hortonworks.com,60020,1419867094938} to {1588230740 state=OPENING, ts=1419867105187, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,008 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419867094938, region=1588230740, current_state={1588230740 state=OPENING, ts=1419867105187, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,009 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1419867105187, server=sandbox.hortonworks.com,60020,1419867094938} to {1588230740 state=OPEN, ts=1419867112009, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,014 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sandbox.hortonworks.com,60020,1419867094938; deleting unassigned node
2014-12-29 15:31:52,019 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2014-12-29 15:31:52,022 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1419867112009, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,022 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sandbox.hortonworks.com,60020,1419867094938 {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:31:52,029 INFO  [master:sandbox:60000] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,202 DEBUG [htable-pool3-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:31:52,203 DEBUG [htable-pool3-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:31:52,417 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2014-12-29 15:31:52,505 INFO  [master:sandbox:60000] master.AssignmentManager: Clean cluster startup. Assigning userregions
2014-12-29 15:31:52,505 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleting any existing unassigned nodes
2014-12-29 15:31:52,523 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Start to scan the hbase:meta for the current region assignment snappshot
2014-12-29 15:31:52,584 INFO  [master:sandbox:60000] master.SnapshotOfRegionAssignmentFromMeta: Finished to scan the hbase:meta for the current region assignmentsnapshot
2014-12-29 15:31:52,802 INFO  [master:sandbox:60000] balancer.BaseLoadBalancer: Reassigned 3 regions. 3 retained the pre-restart assignment. 
2014-12-29 15:31:52,802 DEBUG [master:sandbox:60000] master.AssignmentManager: Assigning 3 region(s) to sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,807 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 3b4c25a80758728ef4f550bbd330f05b with OFFLINE state
2014-12-29 15:31:52,809 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node bf93a1f8a3cdac77590e5033ba6ae70f with OFFLINE state
2014-12-29 15:31:52,814 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node db8d9fe8d0471c86ef90518de99b1581 with OFFLINE state
2014-12-29 15:31:52,821 DEBUG [main-EventThread] master.OfflineCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419867112492, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,824 DEBUG [main-EventThread] master.OfflineCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419867112500, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,825 DEBUG [main-EventThread] master.OfflineCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419867112498, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,825 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419867112492, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,826 INFO  [master:sandbox:60000] master.AssignmentManager: sandbox.hortonworks.com,60020,1419867094938 unassigned znodes=1 of total=3
2014-12-29 15:31:52,829 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419867112500, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,829 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419867112498, server=null}, server=sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,832 INFO  [master:sandbox:60000] master.AssignmentManager: sandbox.hortonworks.com,60020,1419867094938 unassigned znodes=3 of total=3
2014-12-29 15:31:52,834 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1419867112807, server=null} to {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419867112834, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,852 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1419867112809, server=null} to {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419867112852, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,853 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1419867112814, server=null} to {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419867112853, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,938 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419867094938, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419867112834, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,962 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419867094938, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419867112852, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,991 DEBUG [master:sandbox:60000] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1419867094938
2014-12-29 15:31:52,991 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1419867112852, server=sandbox.hortonworks.com,60020,1419867094938} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419867112991, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:52,992 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1419867112834, server=sandbox.hortonworks.com,60020,1419867094938} to {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419867112992, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,044 DEBUG [AM.ZK.Worker-pool2-t7] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1419867094938, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419867112853, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,045 INFO  [AM.ZK.Worker-pool2-t7] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1419867112853, server=sandbox.hortonworks.com,60020,1419867094938} to {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419867113044, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,902 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419867094938, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419867112992, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,902 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1419867112992, server=sandbox.hortonworks.com,60020,1419867094938} to {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1419867113902, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,902 DEBUG [AM.ZK.Worker-pool2-t8] handler.OpenedRegionHandler: Handling OPENED of 3b4c25a80758728ef4f550bbd330f05b from sandbox.hortonworks.com,60020,1419867094938; deleting unassigned node
2014-12-29 15:31:53,913 DEBUG [AM.ZK.Worker-pool2-t8] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 3b4c25a80758728ef4f550bbd330f05b in expected state RS_ZK_REGION_OPENED
2014-12-29 15:31:53,914 DEBUG [AM.ZK.Worker-pool2-t9] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419867094938, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419867112991, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,915 INFO  [AM.ZK.Worker-pool2-t9] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1419867112991, server=sandbox.hortonworks.com,60020,1419867094938} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1419867113915, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,915 DEBUG [AM.ZK.Worker-pool2-t9] handler.OpenedRegionHandler: Handling OPENED of bf93a1f8a3cdac77590e5033ba6ae70f from sandbox.hortonworks.com,60020,1419867094938; deleting unassigned node
2014-12-29 15:31:53,926 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1419867094938, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419867113044, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,926 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1419867113044, server=sandbox.hortonworks.com,60020,1419867094938} to {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419867113926, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,926 DEBUG [AM.ZK.Worker-pool2-t10] handler.OpenedRegionHandler: Handling OPENED of db8d9fe8d0471c86ef90518de99b1581 from sandbox.hortonworks.com,60020,1419867094938; deleting unassigned node
2014-12-29 15:31:53,932 DEBUG [AM.ZK.Worker-pool2-t11] master.AssignmentManager: Znode hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b. deleted, state: {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1419867113902, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,932 INFO  [AM.ZK.Worker-pool2-t11] master.RegionStates: Onlined 3b4c25a80758728ef4f550bbd330f05b on sandbox.hortonworks.com,60020,1419867094938 {ENCODED => 3b4c25a80758728ef4f550bbd330f05b, NAME => 'hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:31:53,937 DEBUG [AM.ZK.Worker-pool2-t9] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node bf93a1f8a3cdac77590e5033ba6ae70f in expected state RS_ZK_REGION_OPENED
2014-12-29 15:31:53,936 DEBUG [AM.ZK.Worker-pool2-t10] zookeeper.ZKAssign: master:60000-0x14a9675840d0021, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node db8d9fe8d0471c86ef90518de99b1581 in expected state RS_ZK_REGION_OPENED
2014-12-29 15:31:53,962 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581. deleted, state: {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1419867113926, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,962 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined db8d9fe8d0471c86ef90518de99b1581 on sandbox.hortonworks.com,60020,1419867094938 {ENCODED => db8d9fe8d0471c86ef90518de99b1581, NAME => 'hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:31:53,973 DEBUG [AM.ZK.Worker-pool2-t14] master.AssignmentManager: Znode iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f. deleted, state: {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1419867113915, server=sandbox.hortonworks.com,60020,1419867094938}
2014-12-29 15:31:53,973 INFO  [AM.ZK.Worker-pool2-t14] master.RegionStates: Onlined bf93a1f8a3cdac77590e5033ba6ae70f on sandbox.hortonworks.com,60020,1419867094938 {ENCODED => bf93a1f8a3cdac77590e5033ba6ae70f, NAME => 'iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.', STARTKEY => '', ENDKEY => ''}
2014-12-29 15:31:54,004 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2014-12-29 15:31:54,010 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2014-12-29 15:31:54,296 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/default already exists and this is not a retry
2014-12-29 15:31:54,304 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/hbase already exists and this is not a retry
2014-12-29 15:31:54,306 INFO  [master:sandbox:60000] master.HMaster: Master has completed initialization
2014-12-29 15:31:54,394 INFO  [master:sandbox:60000] master.HMaster: Client=null/null create 'hbase:acl', {NAME => 'l', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'}
2014-12-29 15:31:54,455 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000001
2014-12-29 15:31:54,514 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000001
2014-12-29 15:32:01,379 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49077; # active connections: 2
2014-12-29 15:32:01,380 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49077 because read count=-1. Number of active connections: 2
2014-12-29 15:32:31,298 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49164; # active connections: 2
2014-12-29 15:32:31,299 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49164 because read count=-1. Number of active connections: 2
2014-12-29 15:33:01,213 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49242; # active connections: 2
2014-12-29 15:33:01,215 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49242 because read count=-1. Number of active connections: 2
2014-12-29 15:33:31,329 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49329; # active connections: 2
2014-12-29 15:33:31,330 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49329 because read count=-1. Number of active connections: 2
2014-12-29 15:34:01,278 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49412; # active connections: 2
2014-12-29 15:34:01,279 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49412 because read count=-1. Number of active connections: 2
2014-12-29 15:34:05,573 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419863721426.1419863727651
2014-12-29 15:34:05,588 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419863721426.1419863730570.meta
2014-12-29 15:34:31,179 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49498; # active connections: 2
2014-12-29 15:34:31,179 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49498 because read count=-1. Number of active connections: 2
2014-12-29 15:35:01,285 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49580; # active connections: 2
2014-12-29 15:35:01,287 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49580 because read count=-1. Number of active connections: 2
2014-12-29 15:35:31,166 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49669; # active connections: 2
2014-12-29 15:35:31,167 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49669 because read count=-1. Number of active connections: 2
2014-12-29 15:36:01,335 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49757; # active connections: 2
2014-12-29 15:36:01,336 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49757 because read count=-1. Number of active connections: 2
2014-12-29 15:36:31,296 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49848; # active connections: 2
2014-12-29 15:36:31,299 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49848 because read count=-1. Number of active connections: 2
2014-12-29 15:36:53,077 DEBUG [sandbox.hortonworks.com,60000,1419867053067-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2014-12-29 15:36:53,087 DEBUG [htable-pool11-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2014-12-29 15:36:53,088 DEBUG [htable-pool11-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/172.16.144.128:60020
2014-12-29 15:37:01,375 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:49928; # active connections: 2
2014-12-29 15:37:01,375 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:49928 because read count=-1. Number of active connections: 2
2014-12-29 15:37:31,236 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:50020; # active connections: 2
2014-12-29 15:37:31,240 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:50020 because read count=-1. Number of active connections: 2
2014-12-29 15:38:01,672 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:50102; # active connections: 2
2014-12-29 15:38:01,673 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:50102 because read count=-1. Number of active connections: 2
2014-12-29 15:38:31,216 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 172.16.144.128:50187; # active connections: 2
2014-12-29 15:38:31,228 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 172.16.144.128:50187 because read count=-1. Number of active connections: 2
2014-12-29 15:38:36,096 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 30 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:37,104 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 31 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:38,108 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 32 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:39,115 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 33 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:40,123 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 34 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:41,131 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 35 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:42,143 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 36 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:43,152 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 37 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:44,159 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 38 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:45,170 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 39 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:46,179 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 40 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:47,191 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 41 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:48,200 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 42 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:49,206 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1006369618_1] for 43 seconds.  Will retry shortly ...
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot renew lease for DFSClient_NONMAPREDUCE_-1006369618_1. Name node is in safe mode.
Resources are low on NN. Please add or free up more resources then turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1366)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:4895)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.renewLease(NameNodeRpcServer.java:820)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.renewLease(ClientNamenodeProtocolServerSideTranslatorPB.java:630)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:415)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)

	at org.apache.hadoop.ipc.Client.call(Client.java:1468)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor19.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
2014-12-29 15:38:52,231 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception, retry in 3640ms
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2014-12-29 15:38:55,873 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception and over retry limit, suppressing further error messages
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2014-12-29 15:38:56,615 INFO  [Thread-18] provider.DbAuditProvider: DbAuditProvider.waitToComplete()
Sat Jan 16 20:36:55 UTC 2016 Starting master on sandbox.hortonworks.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 55707
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-01-16 20:36:59,080 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2016-01-16 20:36:59,081 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2016-01-16 20:36:59,081 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2016-01-16 20:37:00,093 INFO  [main] util.ServerCommandLine: env:TERM=linux
2016-01-16 20:37:00,093 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64
2016-01-16 20:37:00,093 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/hdp/current/hbase-client/bin/..
2016-01-16 20:37:00,093 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-01-16 20:37:00,093 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hbase
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HOSTNAME=sandbox.hortonworks.com
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-master.znode
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xmx1024m
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-01-16 20:37:00,094 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:ZOOKEEPER_HOME=/usr/hdp/2.2.0.0-2041/zookeeper
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xmn200m -XX:CMSInitiatingOccupancyFraction=70  -Xms1024m -Xmx1024m
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin:/home/hbase/bin
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF=/usr/hdp/2.2.0.0-2041/hadoop/conf
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:HDP_VERSION=2.2.0.0-2041
2016-01-16 20:37:00,095 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVERS=/etc/hbase/conf/regionservers
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-master.autorestart
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:SERVER_GC_OPTS=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201601162036
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-master-sandbox.hortonworks.com.log
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-Dhdp.version=2.2.0.0-2041  -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201601162036  -Xmx1024m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-01-16 20:37:00,096 INFO  [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/etc/hbase/conf
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/hdp/2.2.0.0-2041/hadoop
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=::/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-01-16 20:37:00,097 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/hadoop/.//*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//*::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/*:/usr/hdp/current/tez-client/*:/usr/hdp/current/tez-client/lib/*:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/*:/usr/hdp/2.2.0.0-2041/tez/lib/*:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:HOME=/home/hbase
2016-01-16 20:37:00,102 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2016-01-16 20:37:00,103 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2016-01-16 20:37:00,103 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-master-sandbox.hortonworks.com
2016-01-16 20:37:00,103 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-01-16 20:37:00,103 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-01-16 20:37:00,106 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.65-b04
2016-01-16 20:37:00,107 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -Dhdp.version=2.2.0.0-2041, -XX:+UseConcMarkSweepGC, -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log, -verbose:gc, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -Xloggc:/var/log/hbase/gc.log-201601162036, -Xmx1024m, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log, -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.., -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2016-01-16 20:37:00,266 DEBUG [main] master.HMaster: master/sandbox.hortonworks.com/10.0.0.4:60000 HConnection server-to-server retries=350
2016-01-16 20:37:01,004 INFO  [main] ipc.RpcServer: master/sandbox.hortonworks.com/10.0.0.4:60000: started 10 reader(s).
2016-01-16 20:37:01,289 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-01-16 20:37:01,639 INFO  [main] impl.MetricsSinkAdapter: Sink ganglia started
2016-01-16 20:37:02,022 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-01-16 20:37:02,023 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-01-16 20:37:06,237 INFO  [main] master.HMaster: hbase.rootdir=hdfs://sandbox.hortonworks.com:8020/apps/hbase/data, hbase.cluster.distributed=true
2016-01-16 20:37:06,258 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-01-16 20:37:06,553 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2016-01-16 20:37:06,554 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2016-01-16 20:37:06,555 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2016-01-16 20:37:06,556 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=master:60000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-16 20:37:06,599 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-16 20:37:06,599 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-16 20:37:06,605 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-16 20:37:06,676 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x1524c1e05200002, negotiated timeout = 30000
2016-01-16 20:37:06,712 INFO  [main] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure already exists and this is not a retry
2016-01-16 20:37:06,743 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2016-01-16 20:37:06,743 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-01-16 20:37:06,932 INFO  [master:sandbox:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-01-16 20:37:07,151 INFO  [master:sandbox:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-01-16 20:37:07,161 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2016-01-16 20:37:07,162 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-01-16 20:37:07,200 INFO  [master:sandbox:60000] http.HttpServer: Jetty bound to port 60010
2016-01-16 20:37:07,200 INFO  [master:sandbox:60000] mortbay.log: jetty-6.1.26
2016-01-16 20:37:08,693 INFO  [master:sandbox:60000] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60010
2016-01-16 20:37:09,303 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2016-01-16 20:37:09,310 INFO  [master:sandbox:60000] master.ActiveMasterManager: Registered Active Master=sandbox.hortonworks.com,60000,1452976622547
2016-01-16 20:37:09,390 INFO  [master:sandbox:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-01-16 20:37:10,609 DEBUG [master:sandbox:60000] hbase.HRegionInfo: 1588230740
2016-01-16 20:37:10,796 INFO  [master:sandbox:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-01-16 20:37:11,246 DEBUG [master:sandbox:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2016-01-16 20:37:11,343 DEBUG [master:sandbox:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2016-01-16 20:37:11,562 INFO  [master:sandbox:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-01-16 20:37:11,610 DEBUG [master:sandbox:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2016-01-16 20:37:11,639 INFO  [master:sandbox:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2016-01-16 20:37:11,669 INFO  [master:sandbox:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2016-01-16 20:37:11,909 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=hconnection-0x334c3ee7, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-16 20:37:11,923 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-16 20:37:11,924 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x334c3ee7 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-16 20:37:11,933 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-16 20:37:11,953 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x1524c1e05200003, negotiated timeout = 30000
2016-01-16 20:37:11,989 DEBUG [master:sandbox:60000] ipc.RpcClient: Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@66d5a046, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-01-16 20:37:12,034 DEBUG [master:sandbox:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@56982ae0
2016-01-16 20:37:12,342 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35415; # active connections: 1
2016-01-16 20:37:12,348 INFO  [master:sandbox:60000] master.HMaster: Server active/primary master=sandbox.hortonworks.com,60000,1452976622547, sessionid=0x1524c1e05200002, setting cluster-up flag (Was=true)
2016-01-16 20:37:12,349 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35415 because read count=-1. Number of active connections: 1
2016-01-16 20:37:12,500 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/online-snapshot/acquired already exists and this is not a retry
2016-01-16 20:37:12,506 INFO  [master:sandbox:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase-unsecure/online-snapshot/acquired /hbase-unsecure/online-snapshot/reached /hbase-unsecure/online-snapshot/abort
2016-01-16 20:37:12,514 DEBUG [master:sandbox:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sandbox.hortonworks.com,60000,1452976622547
2016-01-16 20:37:12,800 INFO  [master:sandbox:60000] config.PolicyRefresher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval: 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2016-01-16 20:37:12,810 INFO  [master:sandbox:60000] config.ConfigWatcher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval(milliSeconds): 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2016-01-16 20:37:14,951 INFO  [master:sandbox:60000] config.ConfigWatcher: URL: [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase], isModified: true, lastModifiedTime:1419866686000
2016-01-16 20:37:15,005 INFO  [master:sandbox:60000] hbase.HBaseAccessControllerFactory: Created a new instance of class: [com.xasecure.pdp.hbase.XASecureAuthorizer] for HBase Access verification.
2016-01-16 20:37:15,587 DEBUG [master:sandbox:60000] master.HMaster: Registered master coprocessor service: service=AccessControlService
2016-01-16 20:37:15,609 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: creating..
2016-01-16 20:37:15,618 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: initializing..
2016-01-16 20:37:15,662 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: creating..
2016-01-16 20:37:15,689 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-16 20:37:15,689 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider): creating..
2016-01-16 20:37:15,689 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.DbAuditProvider)
2016-01-16 20:37:15,697 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-16 20:37:15,697 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider): creating..
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.hdfs.HdfsAuditProvider)
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider).init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.init()
2016-01-16 20:37:15,698 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-16 20:37:15,830 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider).init()
2016-01-16 20:37:15,830 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-16 20:37:15,830 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-16 20:37:15,830 INFO  [master:sandbox:60000] hdfs.HdfsAuditProvider: HdfsAuditProvider.init()
2016-01-16 20:37:15,830 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-16 20:37:15,872 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.start()
2016-01-16 20:37:15,872 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: init()
2016-01-16 20:37:15,872 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2016-01-16 20:37:21,494 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2016-01-16 20:37:21,501 INFO  [master:sandbox:60000] hbase.XaSecureAuthorizationCoprocessor: Start() - Adding Super User(hbase)
2016-01-16 20:37:21,501 INFO  [master:sandbox:60000] coprocessor.CoprocessorHost: System coprocessor com.xasecure.authorization.hbase.XaSecureAuthorizationCoprocessor was loaded successfully with priority (536870911).
2016-01-16 20:37:21,512 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-16 20:37:21,512 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-16 20:37:21,512 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-16 20:37:21,512 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-16 20:37:21,512 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sandbox:60000, corePoolSize=10, maxPoolSize=10
2016-01-16 20:37:21,513 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sandbox:60000, corePoolSize=1, maxPoolSize=1
2016-01-16 20:37:21,521 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2016-01-16 20:37:21,541 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=replicationLogCleaner, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-16 20:37:21,555 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-16 20:37:21,559 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-16 20:37:21,561 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-16 20:37:21,582 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x1524c1e05200004, negotiated timeout = 30000
2016-01-16 20:37:21,641 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/replication/rs already exists and this is not a retry
2016-01-16 20:37:21,641 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2016-01-16 20:37:21,653 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2016-01-16 20:37:21,666 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2016-01-16 20:37:21,675 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2016-01-16 20:37:21,681 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2016-01-16 20:37:21,681 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:21,765 INFO  [DestinationDispatcherThread-1452976641500] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): opening file for write hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20160116/sandbox.hortonworks.com-audit.log
2016-01-16 20:37:23,196 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1515 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:24,738 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 3057 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:26,281 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 4599 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:27,827 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 6145 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:29,377 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 7696 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:30,918 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 9237 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:32,467 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 10786 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:34,005 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 12324 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:35,513 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 13832 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:37,049 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 15368 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:38,559 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 16878 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:40,074 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 18392 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:41,596 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 19915 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:42,355 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35555; # active connections: 1
2016-01-16 20:37:42,356 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35555 because read count=-1. Number of active connections: 1
2016-01-16 20:37:43,128 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 21447 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:44,669 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 22988 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:45,389 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37461; # active connections: 1
2016-01-16 20:37:45,586 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:45,597 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-01-16 20:37:45,637 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 23956 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-16 20:37:45,834 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase-unsecure/rs/sandbox.hortonworks.com,60020,1452976657923 data: PBUF
2016-01-16 20:37:47,168 INFO  [master:sandbox:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 25487 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2016-01-16 20:37:47,182 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938 doesn't belong to a known region server, splitting
2016-01-16 20:37:47,182 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923 belongs to an existing region server
2016-01-16 20:37:47,270 DEBUG [master:sandbox:60000] master.MasterFileSystem: Renamed region directory: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting
2016-01-16 20:37:47,271 INFO  [master:sandbox:60000] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1419867094938]
2016-01-16 20:37:47,300 DEBUG [master:sandbox:60000] master.SplitLogManager: Scheduling batch of logs to split
2016-01-16 20:37:47,306 INFO  [master:sandbox:60000] master.SplitLogManager: started splitting 1 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting]
2016-01-16 20:37:47,392 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta
2016-01-16 20:37:47,398 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta ver = 0
2016-01-16 20:37:47,967 INFO  [sandbox.hortonworks.com,60000,1452976622547.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 1 tasks={/hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta=last_update = -1 last_version = -1 cur_worker_name = null status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2016-01-16 20:37:48,885 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta acquired by sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:50,316 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta entered state: DONE sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:50,423 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting/sandbox.hortonworks.com%2C60020%2C1419867094938.1419867105176.meta to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/oldWALs/sandbox.hortonworks.com%2C60020%2C1419867094938.1419867105176.meta
2016-01-16 20:37:50,427 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta
2016-01-16 20:37:50,455 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867105176.meta
2016-01-16 20:37:50,455 WARN  [master:sandbox:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting
2016-01-16 20:37:50,455 INFO  [master:sandbox:60000] master.SplitLogManager: finished splitting (more than or equal to) 2071 bytes in 1 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting] in 3149ms
2016-01-16 20:37:50,619 DEBUG [master:sandbox:60000] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 20:37:50,629 DEBUG [master:sandbox:60000] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:37:50,721 INFO  [master:sandbox:60000] catalog.CatalogTracker: Failed verification of hbase:meta,,1 at address=sandbox.hortonworks.com,60020,1419867094938, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sandbox.hortonworks.com,60020,1452976657923
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2774)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4257)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionInfo(HRegionServer.java:3599)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20370)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:745)

2016-01-16 20:37:50,742 INFO  [master:sandbox:60000] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1419867094938]
2016-01-16 20:37:50,754 INFO  [master:sandbox:60000] master.SplitLogManager: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting is empty dir, no logs to split
2016-01-16 20:37:50,754 DEBUG [master:sandbox:60000] master.SplitLogManager: Scheduling batch of logs to split
2016-01-16 20:37:50,754 INFO  [master:sandbox:60000] master.SplitLogManager: started splitting 0 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting]
2016-01-16 20:37:50,772 WARN  [master:sandbox:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting
2016-01-16 20:37:50,772 INFO  [master:sandbox:60000] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting] in 18ms
2016-01-16 20:37:50,773 INFO  [master:sandbox:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2016-01-16 20:37:50,888 DEBUG [master:sandbox:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sandbox.hortonworks.com,60020,1452976657923; 1 (online=1, available=1) available servers, forceNewPlan=false
2016-01-16 20:37:50,888 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating (or updating) unassigned node 1588230740 with OFFLINE state
2016-01-16 20:37:50,925 INFO  [master:sandbox:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:50,926 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1452976670888, server=null} to {1588230740 state=PENDING_OPEN, ts=1452976670926, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:50,926 DEBUG [master:sandbox:60000] master.ServerManager: New admin connection to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:51,489 INFO  [master:sandbox:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2016-01-16 20:37:51,595 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1452976670926, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:51,595 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1452976670926, server=sandbox.hortonworks.com,60020,1452976657923} to {1588230740 state=OPENING, ts=1452976671595, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:58,955 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=1588230740, current_state={1588230740 state=OPENING, ts=1452976671595, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:58,955 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1452976671595, server=sandbox.hortonworks.com,60020,1452976657923} to {1588230740 state=OPEN, ts=1452976678955, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:58,959 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 20:37:58,992 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2016-01-16 20:37:58,994 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1452976678955, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:37:58,995 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:37:59,001 INFO  [master:sandbox:60000] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:59,188 DEBUG [htable-pool3-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 20:37:59,189 DEBUG [htable-pool3-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:37:59,351 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2016-01-16 20:37:59,420 INFO  [master:sandbox:60000] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2016-01-16 20:37:59,458 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Splitting logs for sandbox.hortonworks.com,60020,1419867094938 before assignment.
2016-01-16 20:37:59,471 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1419867094938]
2016-01-16 20:37:59,507 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2016-01-16 20:37:59,507 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: started splitting 1 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting]
2016-01-16 20:37:59,539 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132
2016-01-16 20:37:59,541 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132 ver = 0
2016-01-16 20:37:59,572 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132 acquired by sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:37:59,988 INFO  [sandbox.hortonworks.com,60000,1452976622547.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132=last_update = 1452976679708 last_version = 2 cur_worker_name = sandbox.hortonworks.com,60020,1452976657923 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2016-01-16 20:38:00,791 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132 entered state: DONE sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:00,851 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting/sandbox.hortonworks.com%2C60020%2C1419867094938.1419867102132 to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/oldWALs/sandbox.hortonworks.com%2C60020%2C1419867094938.1419867102132
2016-01-16 20:38:00,854 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132
2016-01-16 20:38:00,883 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1419867094938-splitting%2Fsandbox.hortonworks.com%252C60020%252C1419867094938.1419867102132
2016-01-16 20:38:00,883 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 1151 bytes in 1 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1419867094938-splitting] in 1375ms
2016-01-16 20:38:00,885 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Reassigning 3 region(s) that sandbox.hortonworks.com,60020,1419867094938 was carrying (and 0 regions(s) that were opening on this server)
2016-01-16 20:38:01,493 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 3 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,496 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 3b4c25a80758728ef4f550bbd330f05b with OFFLINE state
2016-01-16 20:38:01,501 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node bf93a1f8a3cdac77590e5033ba6ae70f with OFFLINE state
2016-01-16 20:38:01,502 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node db8d9fe8d0471c86ef90518de99b1581 with OFFLINE state
2016-01-16 20:38:01,534 DEBUG [main-EventThread] master.OfflineCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1452976679415, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,554 DEBUG [main-EventThread] master.OfflineCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1452976679418, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,554 DEBUG [main-EventThread] master.OfflineCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1452976679416, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,555 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1452976679415, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,556 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1452976679418, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,556 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1452976679416, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,563 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=3 of total=3
2016-01-16 20:38:01,564 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1452976681496, server=null} to {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,564 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1452976681501, server=null} to {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,564 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1452976681502, server=null} to {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,710 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,852 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,860 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:38:01,861 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.DeadServer: Finished processing sandbox.hortonworks.com,60020,1419867094938
2016-01-16 20:38:01,861 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923} to {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1452976681861, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,861 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Finished processing of shutdown of sandbox.hortonworks.com,60020,1419867094938
2016-01-16 20:38:01,865 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1452976681865, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,949 DEBUG [AM.ZK.Worker-pool2-t7] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:01,949 INFO  [AM.ZK.Worker-pool2-t7] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1452976681564, server=sandbox.hortonworks.com,60020,1452976657923} to {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1452976681949, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,169 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1452976681865, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,169 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1452976681865, server=sandbox.hortonworks.com,60020,1452976657923} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1452976683169, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,177 DEBUG [AM.ZK.Worker-pool2-t9] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1452976681949, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,178 INFO  [AM.ZK.Worker-pool2-t9] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1452976681949, server=sandbox.hortonworks.com,60020,1452976657923} to {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1452976683178, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,169 DEBUG [AM.ZK.Worker-pool2-t8] handler.OpenedRegionHandler: Handling OPENED of bf93a1f8a3cdac77590e5033ba6ae70f from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 20:38:03,178 DEBUG [AM.ZK.Worker-pool2-t9] handler.OpenedRegionHandler: Handling OPENED of db8d9fe8d0471c86ef90518de99b1581 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 20:38:03,197 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1452976681861, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,199 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1452976681861, server=sandbox.hortonworks.com,60020,1452976657923} to {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1452976683199, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,199 DEBUG [AM.ZK.Worker-pool2-t10] handler.OpenedRegionHandler: Handling OPENED of 3b4c25a80758728ef4f550bbd330f05b from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 20:38:03,229 DEBUG [AM.ZK.Worker-pool2-t8] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node bf93a1f8a3cdac77590e5033ba6ae70f in expected state RS_ZK_REGION_OPENED
2016-01-16 20:38:03,261 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Znode iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f. deleted, state: {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1452976683169, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,262 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Onlined bf93a1f8a3cdac77590e5033ba6ae70f on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => bf93a1f8a3cdac77590e5033ba6ae70f, NAME => 'iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:38:03,267 DEBUG [AM.ZK.Worker-pool2-t9] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node db8d9fe8d0471c86ef90518de99b1581 in expected state RS_ZK_REGION_OPENED
2016-01-16 20:38:03,306 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581. deleted, state: {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1452976683178, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,306 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined db8d9fe8d0471c86ef90518de99b1581 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => db8d9fe8d0471c86ef90518de99b1581, NAME => 'hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:38:03,308 DEBUG [AM.ZK.Worker-pool2-t10] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 3b4c25a80758728ef4f550bbd330f05b in expected state RS_ZK_REGION_OPENED
2016-01-16 20:38:03,380 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Znode hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b. deleted, state: {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1452976683199, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:38:03,380 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Onlined 3b4c25a80758728ef4f550bbd330f05b on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 3b4c25a80758728ef4f550bbd330f05b, NAME => 'hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:38:03,410 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2016-01-16 20:38:03,415 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2016-01-16 20:38:03,851 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/default already exists and this is not a retry
2016-01-16 20:38:03,917 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/hbase already exists and this is not a retry
2016-01-16 20:38:03,949 INFO  [master:sandbox:60000] master.HMaster: Master has completed initialization
2016-01-16 20:38:03,999 INFO  [master:sandbox:60000] master.HMaster: Client=null/null create 'hbase:acl', {NAME => 'l', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'}
2016-01-16 20:38:04,061 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000002
2016-01-16 20:38:04,136 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000002
2016-01-16 20:38:12,419 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35711; # active connections: 2
2016-01-16 20:38:12,419 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35711 because read count=-1. Number of active connections: 2
2016-01-16 20:38:21,690 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419866617361.1419866631079
2016-01-16 20:38:21,727 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419866617361.1419866635110.meta
2016-01-16 20:38:42,271 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35849; # active connections: 2
2016-01-16 20:38:42,271 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35849 because read count=-1. Number of active connections: 2
2016-01-16 20:39:12,337 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35988; # active connections: 2
2016-01-16 20:39:12,337 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35988 because read count=-1. Number of active connections: 2
2016-01-16 20:39:21,781 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36049; # active connections: 2
2016-01-16 20:39:21,859 INFO  [FifoRpcScheduler.handler1-thread-38] master.HMaster: Client=thenson//10.0.0.4 create 'thomas', {NAME => 'time', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 20:39:22,051 DEBUG [FifoRpcScheduler.handler1-thread-38] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/thomas/write-master:600000000000000
2016-01-16 20:39:22,114 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table thomas
2016-01-16 20:39:22,126 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:06.426 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:39:22,126 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2016-01-16 20:39:22,702 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/.tabledesc/.tableinfo.0000000001
2016-01-16 20:39:22,711 INFO  [RegionOpenAndInitThread-thomas-1] regionserver.HRegion: creating HRegion thomas HTD == 'thomas', {NAME => 'time', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == thomas
2016-01-16 20:39:22,817 DEBUG [RegionOpenAndInitThread-thomas-1] regionserver.HRegion: Instantiated thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.
2016-01-16 20:39:22,817 DEBUG [RegionOpenAndInitThread-thomas-1] regionserver.HRegion: Closing thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.: disabling compactions & flushes
2016-01-16 20:39:22,817 DEBUG [RegionOpenAndInitThread-thomas-1] regionserver.HRegion: Updates disabled for region thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.
2016-01-16 20:39:22,818 INFO  [RegionOpenAndInitThread-thomas-1] regionserver.HRegion: Closed thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.
2016-01-16 20:39:22,963 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 20:39:22,980 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:39:22,981 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 9b74aefbc63fd7c7d79f36073fc35ce4 with OFFLINE state
2016-01-16 20:39:22,998 DEBUG [main-EventThread] master.OfflineCallback: rs={9b74aefbc63fd7c7d79f36073fc35ce4 state=OFFLINE, ts=1452976762964, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:39:23,000 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={9b74aefbc63fd7c7d79f36073fc35ce4 state=OFFLINE, ts=1452976762964, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:39:23,001 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 20:39:23,002 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {9b74aefbc63fd7c7d79f36073fc35ce4 state=OFFLINE, ts=1452976762981, server=null} to {9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_OPEN, ts=1452976763002, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,029 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:39:23,079 DEBUG [AM.ZK.Worker-pool2-t17] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=9b74aefbc63fd7c7d79f36073fc35ce4, current_state={9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_OPEN, ts=1452976763002, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,079 INFO  [AM.ZK.Worker-pool2-t17] master.RegionStates: Transitioned {9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_OPEN, ts=1452976763002, server=sandbox.hortonworks.com,60020,1452976657923} to {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPENING, ts=1452976763079, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,108 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/thomas/write-master:600000000000000
2016-01-16 20:39:23,108 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, thomas, creation successful
2016-01-16 20:39:23,234 DEBUG [AM.ZK.Worker-pool2-t18] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=9b74aefbc63fd7c7d79f36073fc35ce4, current_state={9b74aefbc63fd7c7d79f36073fc35ce4 state=OPENING, ts=1452976763079, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,234 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Transitioned {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPENING, ts=1452976763079, server=sandbox.hortonworks.com,60020,1452976657923} to {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPEN, ts=1452976763234, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,235 DEBUG [AM.ZK.Worker-pool2-t18] handler.OpenedRegionHandler: Handling OPENED of 9b74aefbc63fd7c7d79f36073fc35ce4 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 20:39:23,264 DEBUG [AM.ZK.Worker-pool2-t18] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 9b74aefbc63fd7c7d79f36073fc35ce4 in expected state RS_ZK_REGION_OPENED
2016-01-16 20:39:23,265 DEBUG [AM.ZK.Worker-pool2-t20] master.AssignmentManager: Znode thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4. deleted, state: {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPEN, ts=1452976763234, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:39:23,265 INFO  [AM.ZK.Worker-pool2-t20] master.RegionStates: Onlined 9b74aefbc63fd7c7d79f36073fc35ce4 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 9b74aefbc63fd7c7d79f36073fc35ce4, NAME => 'thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:39:42,294 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36138; # active connections: 3
2016-01-16 20:39:42,299 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36138 because read count=-1. Number of active connections: 3
2016-01-16 20:40:12,098 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36280; # active connections: 3
2016-01-16 20:40:12,099 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36280 because read count=-1. Number of active connections: 3
2016-01-16 20:40:15,695 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:40:15,695 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2016-01-16 20:40:42,070 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36414; # active connections: 3
2016-01-16 20:40:42,070 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36414 because read count=-1. Number of active connections: 3
2016-01-16 20:41:12,355 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36563; # active connections: 3
2016-01-16 20:41:12,355 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36563 because read count=-1. Number of active connections: 3
2016-01-16 20:41:42,291 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36694; # active connections: 3
2016-01-16 20:41:42,295 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36694 because read count=-1. Number of active connections: 3
2016-01-16 20:42:12,315 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36836; # active connections: 3
2016-01-16 20:42:12,319 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36836 because read count=-1. Number of active connections: 3
2016-01-16 20:42:15,700 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:42:15,700 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=2, outLogs=2, dropped=0
2016-01-16 20:42:22,129 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:42:22,129 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=2, outLogs=2, dropped=0
2016-01-16 20:42:42,284 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36973; # active connections: 3
2016-01-16 20:42:42,292 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36973 because read count=-1. Number of active connections: 3
2016-01-16 20:42:59,454 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 20:42:59,461 DEBUG [htable-pool13-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 20:42:59,461 DEBUG [htable-pool13-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:43:12,361 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37115; # active connections: 3
2016-01-16 20:43:12,361 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37115 because read count=-1. Number of active connections: 3
2016-01-16 20:43:15,702 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:43:15,702 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=3, outLogs=3, dropped=0
2016-01-16 20:43:22,131 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:43:22,131 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=3, outLogs=3, dropped=0
2016-01-16 20:43:42,297 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37251; # active connections: 3
2016-01-16 20:43:42,297 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37251 because read count=-1. Number of active connections: 3
2016-01-16 20:44:12,316 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37392; # active connections: 3
2016-01-16 20:44:12,317 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37392 because read count=-1. Number of active connections: 3
2016-01-16 20:44:15,704 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:44:15,704 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=4, outLogs=4, dropped=0
2016-01-16 20:44:22,135 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.003 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 20:44:22,135 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=4, outLogs=4, dropped=0
2016-01-16 20:44:42,300 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37531; # active connections: 3
2016-01-16 20:44:42,304 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37531 because read count=-1. Number of active connections: 3
2016-01-16 20:45:12,312 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37678; # active connections: 3
2016-01-16 20:45:12,312 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37678 because read count=-1. Number of active connections: 3
2016-01-16 20:45:42,254 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37807; # active connections: 3
2016-01-16 20:45:42,254 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37807 because read count=-1. Number of active connections: 3
2016-01-16 20:45:52,016 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36049 because read count=-1. Number of active connections: 2
2016-01-16 20:46:12,326 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37963; # active connections: 2
2016-01-16 20:46:12,327 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37963 because read count=-1. Number of active connections: 2
2016-01-16 20:46:27,871 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38031; # active connections: 2
2016-01-16 20:46:27,891 INFO  [FifoRpcScheduler.handler1-thread-12] master.HMaster: Client=thenson//10.0.0.4 disable thomas
2016-01-16 20:46:27,911 DEBUG [FifoRpcScheduler.handler1-thread-12] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/thomas/write-master:600000000000001
2016-01-16 20:46:27,913 DEBUG [htable-pool14-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 20:46:27,913 DEBUG [htable-pool14-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:46:28,003 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table thomas
2016-01-16 20:46:28,019 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-16 20:46:28,024 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4. (offlining), current state: {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPEN, ts=1452976763265, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:46:28,024 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 9b74aefbc63fd7c7d79f36073fc35ce4 in a CLOSING state
2016-01-16 20:46:28,052 INFO  [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {9b74aefbc63fd7c7d79f36073fc35ce4 state=OPEN, ts=1452976763265, server=sandbox.hortonworks.com,60020,1452976657923} to {9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_CLOSE, ts=1452977188052, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:46:28,065 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 20:46:28,065 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:46:28,083 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1452976657923 for region thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.
2016-01-16 20:46:28,489 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1452976657923, region=9b74aefbc63fd7c7d79f36073fc35ce4, current_state={9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_CLOSE, ts=1452977188052, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:46:28,491 DEBUG [AM.ZK.Worker-pool2-t22] handler.ClosedRegionHandler: Handling CLOSED event for 9b74aefbc63fd7c7d79f36073fc35ce4
2016-01-16 20:46:28,492 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.
2016-01-16 20:46:28,551 DEBUG [AM.ZK.Worker-pool2-t22] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 9b74aefbc63fd7c7d79f36073fc35ce4 in expected state RS_ZK_REGION_CLOSED
2016-01-16 20:46:28,551 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 9b74aefbc63fd7c7d79f36073fc35ce4, NAME => 'thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.', STARTKEY => '', ENDKEY => ''}
2016-01-16 20:46:28,551 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Transitioned {9b74aefbc63fd7c7d79f36073fc35ce4 state=PENDING_CLOSE, ts=1452977188052, server=sandbox.hortonworks.com,60020,1452976657923} to {9b74aefbc63fd7c7d79f36073fc35ce4 state=OFFLINE, ts=1452977188551, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 20:46:28,551 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Offlined 9b74aefbc63fd7c7d79f36073fc35ce4 from sandbox.hortonworks.com,60020,1452976657923
2016-01-16 20:46:29,026 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-16 20:46:29,051 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, thomas, is done=true
2016-01-16 20:46:29,067 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/thomas/write-master:600000000000001
2016-01-16 20:46:33,671 INFO  [FifoRpcScheduler.handler1-thread-16] master.HMaster: Client=thenson//10.0.0.4 delete thomas
2016-01-16 20:46:33,700 DEBUG [FifoRpcScheduler.handler1-thread-16] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/thomas/write-master:600000000000002
2016-01-16 20:46:33,715 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table thomas
2016-01-16 20:46:33,731 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-16 20:46:33,880 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 9b74aefbc63fd7c7d79f36073fc35ce4, NAME => 'thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 20:46:33,905 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region thomas,,1452976761855.9b74aefbc63fd7c7d79f36073fc35ce4. from FS
2016-01-16 20:46:33,910 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4
2016-01-16 20:46:33,928 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/recovered.edits, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/time]
2016-01-16 20:46:34,015 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/recovered.edits/10_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/recovered.edits/10_seqid
2016-01-16 20:46:34,093 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/time/8be8900f3327478db58ad806208b3570, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4/time/8be8900f3327478db58ad806208b3570
2016-01-16 20:46:34,109 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/thomas/9b74aefbc63fd7c7d79f36073fc35ce4
2016-01-16 20:46:34,127 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'thomas' from region states.
2016-01-16 20:46:34,127 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'thomas' as deleted.
2016-01-16 20:46:34,218 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/thomas/write-master:600000000000002
2016-01-16 20:46:42,212 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38105; # active connections: 3
2016-01-16 20:46:42,213 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38105 because read count=-1. Number of active connections: 3
2016-01-16 20:47:12,168 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38243; # active connections: 3
2016-01-16 20:47:12,168 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38243 because read count=-1. Number of active connections: 3
2016-01-16 20:47:15,714 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.001 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 20:47:15,714 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=9, outLogs=9, dropped=0
2016-01-16 20:47:22,141 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 20:47:22,141 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=9, outLogs=9, dropped=0
2016-01-16 20:47:42,282 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38389; # active connections: 3
2016-01-16 20:47:42,282 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38389 because read count=-1. Number of active connections: 3
2016-01-16 20:47:59,454 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 20:48:12,283 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38536; # active connections: 3
2016-01-16 20:48:12,283 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38536 because read count=-1. Number of active connections: 3
2016-01-16 20:48:21,693 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419867094938.1419867102132
2016-01-16 20:48:21,984 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1419867094938.1419867105176.meta
2016-01-16 20:48:36,801 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38031 because read count=-1. Number of active connections: 2
2016-01-16 20:48:42,193 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38676; # active connections: 2
2016-01-16 20:48:42,194 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38676 because read count=-1. Number of active connections: 2
2016-01-16 20:49:12,205 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38817; # active connections: 2
2016-01-16 20:49:12,205 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38817 because read count=-1. Number of active connections: 2
2016-01-16 20:49:42,143 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38956; # active connections: 2
2016-01-16 20:49:42,143 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38956 because read count=-1. Number of active connections: 2
2016-01-16 20:50:12,232 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39099; # active connections: 2
2016-01-16 20:50:12,232 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39099 because read count=-1. Number of active connections: 2
2016-01-16 20:50:42,122 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39230; # active connections: 2
2016-01-16 20:50:42,122 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39230 because read count=-1. Number of active connections: 2
2016-01-16 20:51:12,137 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39362; # active connections: 2
2016-01-16 20:51:12,142 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39362 because read count=-1. Number of active connections: 2
2016-01-16 20:51:42,199 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39495; # active connections: 2
2016-01-16 20:51:42,200 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39495 because read count=-1. Number of active connections: 2
2016-01-16 20:52:12,156 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39637; # active connections: 2
2016-01-16 20:52:12,156 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39637 because read count=-1. Number of active connections: 2
2016-01-16 20:52:42,113 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39768; # active connections: 2
2016-01-16 20:52:42,114 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39768 because read count=-1. Number of active connections: 2
2016-01-16 20:52:59,456 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 20:52:59,462 DEBUG [htable-pool19-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 20:52:59,462 DEBUG [htable-pool19-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:53:12,110 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39900; # active connections: 2
2016-01-16 20:53:12,115 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39900 because read count=-1. Number of active connections: 2
2016-01-16 20:53:42,189 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40036; # active connections: 2
2016-01-16 20:53:42,189 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40036 because read count=-1. Number of active connections: 2
2016-01-16 20:54:12,266 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40180; # active connections: 2
2016-01-16 20:54:12,266 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40180 because read count=-1. Number of active connections: 2
2016-01-16 20:54:42,179 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40314; # active connections: 2
2016-01-16 20:54:42,179 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40314 because read count=-1. Number of active connections: 2
2016-01-16 20:55:12,321 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40445; # active connections: 2
2016-01-16 20:55:12,335 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40445 because read count=-1. Number of active connections: 2
2016-01-16 20:55:42,297 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40594; # active connections: 2
2016-01-16 20:55:42,297 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40594 because read count=-1. Number of active connections: 2
2016-01-16 20:56:12,171 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40761; # active connections: 2
2016-01-16 20:56:12,172 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40761 because read count=-1. Number of active connections: 2
2016-01-16 20:56:42,364 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40920; # active connections: 2
2016-01-16 20:56:42,364 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40920 because read count=-1. Number of active connections: 2
2016-01-16 20:57:18,317 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41078; # active connections: 2
2016-01-16 20:57:18,345 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41078 because read count=-1. Number of active connections: 2
2016-01-16 20:57:47,164 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41240; # active connections: 2
2016-01-16 20:57:47,167 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41240 because read count=-1. Number of active connections: 2
2016-01-16 20:57:59,457 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 20:57:59,464 DEBUG [htable-pool20-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 20:57:59,464 DEBUG [htable-pool20-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 20:58:17,222 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41373; # active connections: 2
2016-01-16 20:58:17,222 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41373 because read count=-1. Number of active connections: 2
2016-01-16 20:58:47,172 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41511; # active connections: 2
2016-01-16 20:58:47,172 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41511 because read count=-1. Number of active connections: 2
2016-01-16 20:59:17,239 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41636; # active connections: 2
2016-01-16 20:59:17,243 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41636 because read count=-1. Number of active connections: 2
2016-01-16 20:59:47,173 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41818; # active connections: 2
2016-01-16 20:59:47,174 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41818 because read count=-1. Number of active connections: 2
2016-01-16 21:00:17,402 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42021; # active connections: 2
2016-01-16 21:00:17,403 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42021 because read count=-1. Number of active connections: 2
2016-01-16 21:00:47,349 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42189; # active connections: 2
2016-01-16 21:00:47,358 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42189 because read count=-1. Number of active connections: 2
2016-01-16 21:01:17,382 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42376; # active connections: 2
2016-01-16 21:01:17,382 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42376 because read count=-1. Number of active connections: 2
2016-01-16 21:01:47,376 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42552; # active connections: 2
2016-01-16 21:01:47,377 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42552 because read count=-1. Number of active connections: 2
2016-01-16 21:02:17,553 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42702; # active connections: 2
2016-01-16 21:02:17,558 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42702 because read count=-1. Number of active connections: 2
2016-01-16 21:02:47,282 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42842; # active connections: 2
2016-01-16 21:02:47,283 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42842 because read count=-1. Number of active connections: 2
2016-01-16 21:02:59,458 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:02:59,466 DEBUG [htable-pool21-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:02:59,466 DEBUG [htable-pool21-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:03:17,346 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42973; # active connections: 2
2016-01-16 21:03:17,346 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42973 because read count=-1. Number of active connections: 2
2016-01-16 21:03:47,231 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43111; # active connections: 2
2016-01-16 21:03:47,231 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43111 because read count=-1. Number of active connections: 2
2016-01-16 21:04:17,368 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43259; # active connections: 2
2016-01-16 21:04:17,368 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43259 because read count=-1. Number of active connections: 2
2016-01-16 21:04:47,344 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43452; # active connections: 2
2016-01-16 21:04:47,344 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43452 because read count=-1. Number of active connections: 2
2016-01-16 21:05:17,244 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43629; # active connections: 2
2016-01-16 21:05:17,244 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43629 because read count=-1. Number of active connections: 2
2016-01-16 21:05:47,289 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43819; # active connections: 2
2016-01-16 21:05:47,291 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43819 because read count=-1. Number of active connections: 2
2016-01-16 21:06:17,418 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44011; # active connections: 2
2016-01-16 21:06:17,418 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44011 because read count=-1. Number of active connections: 2
2016-01-16 21:06:47,234 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44142; # active connections: 2
2016-01-16 21:06:47,234 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44142 because read count=-1. Number of active connections: 2
2016-01-16 21:07:17,231 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44273; # active connections: 2
2016-01-16 21:07:17,235 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44273 because read count=-1. Number of active connections: 2
2016-01-16 21:07:47,191 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44416; # active connections: 2
2016-01-16 21:07:47,191 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44416 because read count=-1. Number of active connections: 2
2016-01-16 21:07:59,458 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:07:59,466 DEBUG [htable-pool22-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:07:59,467 DEBUG [htable-pool22-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:08:17,279 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44575; # active connections: 2
2016-01-16 21:08:17,290 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44575 because read count=-1. Number of active connections: 2
2016-01-16 21:08:47,325 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44758; # active connections: 2
2016-01-16 21:08:47,329 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44758 because read count=-1. Number of active connections: 2
2016-01-16 21:09:17,463 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44948; # active connections: 2
2016-01-16 21:09:17,474 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44948 because read count=-1. Number of active connections: 2
2016-01-16 21:09:47,138 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45142; # active connections: 2
2016-01-16 21:09:47,138 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45142 because read count=-1. Number of active connections: 2
2016-01-16 21:10:17,207 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45313; # active connections: 2
2016-01-16 21:10:17,215 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45313 because read count=-1. Number of active connections: 2
2016-01-16 21:10:47,135 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45450; # active connections: 2
2016-01-16 21:10:47,135 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45450 because read count=-1. Number of active connections: 2
2016-01-16 21:10:55,500 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45498; # active connections: 2
2016-01-16 21:10:55,515 INFO  [FifoRpcScheduler.handler1-thread-32] master.HMaster: Client=thenson//10.0.0.4 create 'stock', {NAME => 'adj_close', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'close', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'date', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'high', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'low', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'open', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'volume', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 21:10:55,637 DEBUG [FifoRpcScheduler.handler1-thread-32] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/stock/write-master:600000000000000
2016-01-16 21:10:55,639 DEBUG [htable-pool23-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:10:55,640 DEBUG [htable-pool23-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:10:55,698 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table stock
2016-01-16 21:10:55,838 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/.tabledesc/.tableinfo.0000000001
2016-01-16 21:10:55,844 INFO  [RegionOpenAndInitThread-stock-1] regionserver.HRegion: creating HRegion stock HTD == 'stock', {NAME => 'adj_close', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'close', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'date', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'high', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'low', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'open', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'volume', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == stock
2016-01-16 21:10:56,011 DEBUG [RegionOpenAndInitThread-stock-1] regionserver.HRegion: Instantiated stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.
2016-01-16 21:10:56,012 DEBUG [RegionOpenAndInitThread-stock-1] regionserver.HRegion: Closing stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.: disabling compactions & flushes
2016-01-16 21:10:56,012 DEBUG [RegionOpenAndInitThread-stock-1] regionserver.HRegion: Updates disabled for region stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.
2016-01-16 21:10:56,012 INFO  [RegionOpenAndInitThread-stock-1] regionserver.HRegion: Closed stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.
2016-01-16 21:10:56,061 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 21:10:56,118 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:10:56,118 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 with OFFLINE state
2016-01-16 21:10:56,135 DEBUG [main-EventThread] master.OfflineCallback: rs={9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1452978656062, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:10:56,137 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1452978656062, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:10:56,145 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 21:10:56,146 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1452978656118, server=null} to {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1452978656145, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:56,146 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 21:10:56,146 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:10:56,166 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:10:56,229 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/stock/write-master:600000000000000
2016-01-16 21:10:56,229 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, stock, creation successful
2016-01-16 21:10:56,229 DEBUG [AM.ZK.Worker-pool2-t26] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=9b0335280e0a412ba7e69b46f0cf2a77, current_state={9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1452978656145, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:56,229 INFO  [AM.ZK.Worker-pool2-t26] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1452978656145, server=sandbox.hortonworks.com,60020,1452976657923} to {9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1452978656229, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:57,244 DEBUG [AM.ZK.Worker-pool2-t27] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=9b0335280e0a412ba7e69b46f0cf2a77, current_state={9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1452978656229, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:57,244 INFO  [AM.ZK.Worker-pool2-t27] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1452978656229, server=sandbox.hortonworks.com,60020,1452976657923} to {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1452978657244, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:57,244 DEBUG [AM.ZK.Worker-pool2-t27] handler.OpenedRegionHandler: Handling OPENED of 9b0335280e0a412ba7e69b46f0cf2a77 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 21:10:57,630 DEBUG [AM.ZK.Worker-pool2-t27] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 in expected state RS_ZK_REGION_OPENED
2016-01-16 21:10:57,630 DEBUG [AM.ZK.Worker-pool2-t29] master.AssignmentManager: Znode stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77. deleted, state: {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1452978657244, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:10:57,631 INFO  [AM.ZK.Worker-pool2-t29] master.RegionStates: Onlined 9b0335280e0a412ba7e69b46f0cf2a77 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 9b0335280e0a412ba7e69b46f0cf2a77, NAME => 'stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.', STARTKEY => '', ENDKEY => ''}
2016-01-16 21:11:15,778 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 21:11:15,778 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=10, outLogs=10, dropped=0
2016-01-16 21:11:17,307 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45599; # active connections: 3
2016-01-16 21:11:17,307 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45599 because read count=-1. Number of active connections: 3
2016-01-16 21:11:22,184 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 21:11:22,184 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=10, outLogs=10, dropped=0
2016-01-16 21:11:47,095 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45723; # active connections: 3
2016-01-16 21:11:47,096 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45723 because read count=-1. Number of active connections: 3
2016-01-16 21:12:17,406 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45863; # active connections: 3
2016-01-16 21:12:17,413 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45863 because read count=-1. Number of active connections: 3
2016-01-16 21:12:47,340 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46004; # active connections: 3
2016-01-16 21:12:47,341 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46004 because read count=-1. Number of active connections: 3
2016-01-16 21:12:55,924 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45498 because read count=-1. Number of active connections: 2
2016-01-16 21:12:59,459 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:12:59,476 DEBUG [htable-pool25-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:12:59,476 DEBUG [htable-pool25-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:13:17,399 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46140; # active connections: 2
2016-01-16 21:13:17,400 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46140 because read count=-1. Number of active connections: 2
2016-01-16 21:13:47,394 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46293; # active connections: 2
2016-01-16 21:13:47,401 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46293 because read count=-1. Number of active connections: 2
2016-01-16 21:14:17,300 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46476; # active connections: 2
2016-01-16 21:14:17,304 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46476 because read count=-1. Number of active connections: 2
2016-01-16 21:14:47,156 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46653; # active connections: 2
2016-01-16 21:14:47,161 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46653 because read count=-1. Number of active connections: 2
2016-01-16 21:15:17,261 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46809; # active connections: 2
2016-01-16 21:15:17,262 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46809 because read count=-1. Number of active connections: 2
2016-01-16 21:15:47,129 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46934; # active connections: 2
2016-01-16 21:15:47,130 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46934 because read count=-1. Number of active connections: 2
2016-01-16 21:16:17,161 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47075; # active connections: 2
2016-01-16 21:16:17,162 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47075 because read count=-1. Number of active connections: 2
2016-01-16 21:16:47,075 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47211; # active connections: 2
2016-01-16 21:16:47,075 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47211 because read count=-1. Number of active connections: 2
2016-01-16 21:17:17,407 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47345; # active connections: 2
2016-01-16 21:17:17,408 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47345 because read count=-1. Number of active connections: 2
2016-01-16 21:17:47,332 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47479; # active connections: 2
2016-01-16 21:17:47,332 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47479 because read count=-1. Number of active connections: 2
2016-01-16 21:17:59,460 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:17:59,473 DEBUG [htable-pool26-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:17:59,474 DEBUG [htable-pool26-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:18:17,440 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47616; # active connections: 2
2016-01-16 21:18:17,451 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47616 because read count=-1. Number of active connections: 2
2016-01-16 21:18:47,363 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47798; # active connections: 2
2016-01-16 21:18:47,363 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47798 because read count=-1. Number of active connections: 2
2016-01-16 21:19:17,230 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47969; # active connections: 2
2016-01-16 21:19:17,234 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47969 because read count=-1. Number of active connections: 2
2016-01-16 21:19:47,408 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48133; # active connections: 2
2016-01-16 21:19:47,409 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48133 because read count=-1. Number of active connections: 2
2016-01-16 21:20:17,385 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48265; # active connections: 2
2016-01-16 21:20:17,389 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48265 because read count=-1. Number of active connections: 2
2016-01-16 21:20:47,276 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48397; # active connections: 2
2016-01-16 21:20:47,276 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48397 because read count=-1. Number of active connections: 2
2016-01-16 21:21:17,392 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48534; # active connections: 2
2016-01-16 21:21:17,392 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48534 because read count=-1. Number of active connections: 2
2016-01-16 21:21:47,413 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48714; # active connections: 2
2016-01-16 21:21:47,413 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48714 because read count=-1. Number of active connections: 2
2016-01-16 21:22:17,489 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48884; # active connections: 2
2016-01-16 21:22:17,496 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48884 because read count=-1. Number of active connections: 2
2016-01-16 21:22:47,323 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49061; # active connections: 2
2016-01-16 21:22:47,331 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49061 because read count=-1. Number of active connections: 2
2016-01-16 21:22:59,460 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:22:59,487 DEBUG [htable-pool27-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:22:59,487 DEBUG [htable-pool27-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:23:17,402 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49204; # active connections: 2
2016-01-16 21:23:17,403 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49204 because read count=-1. Number of active connections: 2
2016-01-16 21:23:47,302 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49332; # active connections: 2
2016-01-16 21:23:47,303 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49332 because read count=-1. Number of active connections: 2
2016-01-16 21:24:17,371 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49459; # active connections: 2
2016-01-16 21:24:17,373 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49459 because read count=-1. Number of active connections: 2
2016-01-16 21:24:47,268 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49596; # active connections: 2
2016-01-16 21:24:47,268 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49596 because read count=-1. Number of active connections: 2
2016-01-16 21:24:52,402 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49623; # active connections: 2
2016-01-16 21:24:52,408 INFO  [FifoRpcScheduler.handler1-thread-12] master.HMaster: Client=thenson//10.0.0.4 create 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 21:24:52,478 DEBUG [FifoRpcScheduler.handler1-thread-12] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 21:24:52,523 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table tester
2016-01-16 21:24:52,726 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/.tabledesc/.tableinfo.0000000001
2016-01-16 21:24:52,730 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: creating HRegion tester HTD == 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == tester
2016-01-16 21:24:52,978 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Instantiated tester,,1452979492406.b45660a842120591786e0cb82bc427d7.
2016-01-16 21:24:52,978 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closing tester,,1452979492406.b45660a842120591786e0cb82bc427d7.: disabling compactions & flushes
2016-01-16 21:24:52,978 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Updates disabled for region tester,,1452979492406.b45660a842120591786e0cb82bc427d7.
2016-01-16 21:24:52,978 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closed tester,,1452979492406.b45660a842120591786e0cb82bc427d7.
2016-01-16 21:24:53,019 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 21:24:53,040 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:24:53,040 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node b45660a842120591786e0cb82bc427d7 with OFFLINE state
2016-01-16 21:24:53,071 DEBUG [main-EventThread] master.OfflineCallback: rs={b45660a842120591786e0cb82bc427d7 state=OFFLINE, ts=1452979493020, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:24:53,072 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={b45660a842120591786e0cb82bc427d7 state=OFFLINE, ts=1452979493020, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:24:53,076 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 21:24:53,076 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {b45660a842120591786e0cb82bc427d7 state=OFFLINE, ts=1452979493040, server=null} to {b45660a842120591786e0cb82bc427d7 state=PENDING_OPEN, ts=1452979493076, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,077 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 21:24:53,077 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:24:53,093 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 21:24:53,121 DEBUG [AM.ZK.Worker-pool2-t31] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=b45660a842120591786e0cb82bc427d7, current_state={b45660a842120591786e0cb82bc427d7 state=PENDING_OPEN, ts=1452979493076, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,121 INFO  [AM.ZK.Worker-pool2-t31] master.RegionStates: Transitioned {b45660a842120591786e0cb82bc427d7 state=PENDING_OPEN, ts=1452979493076, server=sandbox.hortonworks.com,60020,1452976657923} to {b45660a842120591786e0cb82bc427d7 state=OPENING, ts=1452979493121, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,133 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 21:24:53,133 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, tester, creation successful
2016-01-16 21:24:53,300 DEBUG [AM.ZK.Worker-pool2-t32] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=b45660a842120591786e0cb82bc427d7, current_state={b45660a842120591786e0cb82bc427d7 state=OPENING, ts=1452979493121, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,300 INFO  [AM.ZK.Worker-pool2-t32] master.RegionStates: Transitioned {b45660a842120591786e0cb82bc427d7 state=OPENING, ts=1452979493121, server=sandbox.hortonworks.com,60020,1452976657923} to {b45660a842120591786e0cb82bc427d7 state=OPEN, ts=1452979493300, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,300 DEBUG [AM.ZK.Worker-pool2-t32] handler.OpenedRegionHandler: Handling OPENED of b45660a842120591786e0cb82bc427d7 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 21:24:53,325 DEBUG [AM.ZK.Worker-pool2-t32] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node b45660a842120591786e0cb82bc427d7 in expected state RS_ZK_REGION_OPENED
2016-01-16 21:24:53,325 DEBUG [AM.ZK.Worker-pool2-t34] master.AssignmentManager: Znode tester,,1452979492406.b45660a842120591786e0cb82bc427d7. deleted, state: {b45660a842120591786e0cb82bc427d7 state=OPEN, ts=1452979493300, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 21:24:53,326 INFO  [AM.ZK.Worker-pool2-t34] master.RegionStates: Onlined b45660a842120591786e0cb82bc427d7 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}
2016-01-16 21:25:15,828 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.004 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 21:25:15,829 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=11, outLogs=11, dropped=0
2016-01-16 21:25:17,372 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49740; # active connections: 3
2016-01-16 21:25:17,372 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49740 because read count=-1. Number of active connections: 3
2016-01-16 21:25:22,205 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 21:25:22,205 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=11, outLogs=11, dropped=0
2016-01-16 21:25:47,311 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49885; # active connections: 3
2016-01-16 21:25:47,312 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49885 because read count=-1. Number of active connections: 3
2016-01-16 21:26:17,501 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50064; # active connections: 3
2016-01-16 21:26:17,518 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50064 because read count=-1. Number of active connections: 3
2016-01-16 21:26:47,085 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50236; # active connections: 3
2016-01-16 21:26:47,086 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50236 because read count=-1. Number of active connections: 3
2016-01-16 21:26:52,790 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49623 because read count=-1. Number of active connections: 2
2016-01-16 21:27:17,383 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50394; # active connections: 2
2016-01-16 21:27:17,384 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50394 because read count=-1. Number of active connections: 2
2016-01-16 21:27:47,324 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50530; # active connections: 2
2016-01-16 21:27:47,324 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50530 because read count=-1. Number of active connections: 2
2016-01-16 21:27:59,461 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:27:59,475 DEBUG [htable-pool30-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:27:59,475 DEBUG [htable-pool30-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:28:17,149 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50668; # active connections: 2
2016-01-16 21:28:17,151 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50668 because read count=-1. Number of active connections: 2
2016-01-16 21:28:47,305 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50820; # active connections: 2
2016-01-16 21:28:47,310 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50820 because read count=-1. Number of active connections: 2
2016-01-16 21:29:18,004 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50973; # active connections: 2
2016-01-16 21:29:18,005 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50973 because read count=-1. Number of active connections: 2
2016-01-16 21:29:47,302 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51123; # active connections: 2
2016-01-16 21:29:47,305 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51123 because read count=-1. Number of active connections: 2
2016-01-16 21:30:17,208 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51275; # active connections: 2
2016-01-16 21:30:17,208 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51275 because read count=-1. Number of active connections: 2
2016-01-16 21:30:47,230 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51411; # active connections: 2
2016-01-16 21:30:47,230 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51411 because read count=-1. Number of active connections: 2
2016-01-16 21:31:17,265 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51532; # active connections: 2
2016-01-16 21:31:17,276 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51532 because read count=-1. Number of active connections: 2
2016-01-16 21:31:47,183 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51702; # active connections: 2
2016-01-16 21:31:47,183 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51702 because read count=-1. Number of active connections: 2
2016-01-16 21:32:17,379 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51859; # active connections: 2
2016-01-16 21:32:17,395 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51859 because read count=-1. Number of active connections: 2
2016-01-16 21:32:47,193 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52020; # active connections: 2
2016-01-16 21:32:47,194 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52020 because read count=-1. Number of active connections: 2
2016-01-16 21:32:59,462 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:32:59,476 DEBUG [htable-pool31-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:32:59,477 DEBUG [htable-pool31-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:33:17,254 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52168; # active connections: 2
2016-01-16 21:33:17,254 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52168 because read count=-1. Number of active connections: 2
2016-01-16 21:33:47,158 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52304; # active connections: 2
2016-01-16 21:33:47,159 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52304 because read count=-1. Number of active connections: 2
2016-01-16 21:34:17,235 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52446; # active connections: 2
2016-01-16 21:34:17,235 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52446 because read count=-1. Number of active connections: 2
2016-01-16 21:34:47,166 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52582; # active connections: 2
2016-01-16 21:34:47,167 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52582 because read count=-1. Number of active connections: 2
2016-01-16 21:35:17,236 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52703; # active connections: 2
2016-01-16 21:35:17,237 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52703 because read count=-1. Number of active connections: 2
2016-01-16 21:35:47,136 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52839; # active connections: 2
2016-01-16 21:35:47,137 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52839 because read count=-1. Number of active connections: 2
2016-01-16 21:36:17,208 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52968; # active connections: 2
2016-01-16 21:36:17,208 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52968 because read count=-1. Number of active connections: 2
2016-01-16 21:36:47,136 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53103; # active connections: 2
2016-01-16 21:36:47,136 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53103 because read count=-1. Number of active connections: 2
2016-01-16 21:37:17,192 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53247; # active connections: 2
2016-01-16 21:37:17,202 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53247 because read count=-1. Number of active connections: 2
2016-01-16 21:37:47,285 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53438; # active connections: 2
2016-01-16 21:37:47,286 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53438 because read count=-1. Number of active connections: 2
2016-01-16 21:37:59,467 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:37:59,478 DEBUG [htable-pool32-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:37:59,478 DEBUG [htable-pool32-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:38:17,437 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53621; # active connections: 2
2016-01-16 21:38:17,448 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53621 because read count=-1. Number of active connections: 2
2016-01-16 21:38:47,302 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53774; # active connections: 2
2016-01-16 21:38:47,303 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53774 because read count=-1. Number of active connections: 2
2016-01-16 21:39:17,333 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53906; # active connections: 2
2016-01-16 21:39:17,340 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53906 because read count=-1. Number of active connections: 2
2016-01-16 21:39:47,085 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54044; # active connections: 2
2016-01-16 21:39:47,087 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54044 because read count=-1. Number of active connections: 2
2016-01-16 21:40:17,193 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54173; # active connections: 2
2016-01-16 21:40:17,194 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54173 because read count=-1. Number of active connections: 2
2016-01-16 21:40:47,365 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54311; # active connections: 2
2016-01-16 21:40:47,366 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54311 because read count=-1. Number of active connections: 2
2016-01-16 21:41:17,420 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54486; # active connections: 2
2016-01-16 21:41:17,420 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54486 because read count=-1. Number of active connections: 2
2016-01-16 21:41:47,410 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54633; # active connections: 2
2016-01-16 21:41:47,411 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54633 because read count=-1. Number of active connections: 2
2016-01-16 21:42:17,228 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54782; # active connections: 2
2016-01-16 21:42:17,228 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54782 because read count=-1. Number of active connections: 2
2016-01-16 21:42:47,238 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54926; # active connections: 2
2016-01-16 21:42:47,238 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54926 because read count=-1. Number of active connections: 2
2016-01-16 21:42:59,470 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:42:59,480 DEBUG [htable-pool33-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:42:59,480 DEBUG [htable-pool33-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:43:17,263 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55062; # active connections: 2
2016-01-16 21:43:17,264 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55062 because read count=-1. Number of active connections: 2
2016-01-16 21:43:47,351 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55190; # active connections: 2
2016-01-16 21:43:47,351 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55190 because read count=-1. Number of active connections: 2
2016-01-16 21:44:17,392 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55329; # active connections: 2
2016-01-16 21:44:17,393 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55329 because read count=-1. Number of active connections: 2
2016-01-16 21:44:47,329 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55466; # active connections: 2
2016-01-16 21:44:47,329 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55466 because read count=-1. Number of active connections: 2
2016-01-16 21:45:17,460 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55603; # active connections: 2
2016-01-16 21:45:17,462 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55603 because read count=-1. Number of active connections: 2
2016-01-16 21:45:47,428 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55732; # active connections: 2
2016-01-16 21:45:47,429 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55732 because read count=-1. Number of active connections: 2
2016-01-16 21:46:17,347 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55868; # active connections: 2
2016-01-16 21:46:17,347 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55868 because read count=-1. Number of active connections: 2
2016-01-16 21:46:47,232 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56001; # active connections: 2
2016-01-16 21:46:47,242 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56001 because read count=-1. Number of active connections: 2
2016-01-16 21:47:17,235 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56129; # active connections: 2
2016-01-16 21:47:17,246 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56129 because read count=-1. Number of active connections: 2
2016-01-16 21:47:47,135 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56258; # active connections: 2
2016-01-16 21:47:47,136 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56258 because read count=-1. Number of active connections: 2
2016-01-16 21:47:59,472 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:47:59,493 DEBUG [htable-pool34-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:47:59,493 DEBUG [htable-pool34-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:48:17,252 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56403; # active connections: 2
2016-01-16 21:48:17,256 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56403 because read count=-1. Number of active connections: 2
2016-01-16 21:48:21,806 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1452976657923.1452976666375
2016-01-16 21:48:21,904 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1452976657923.1452976671594.meta
2016-01-16 21:48:47,199 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56538; # active connections: 2
2016-01-16 21:48:47,199 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56538 because read count=-1. Number of active connections: 2
2016-01-16 21:49:17,199 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56675; # active connections: 2
2016-01-16 21:49:17,199 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56675 because read count=-1. Number of active connections: 2
2016-01-16 21:49:47,179 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56800; # active connections: 2
2016-01-16 21:49:47,180 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56800 because read count=-1. Number of active connections: 2
2016-01-16 21:50:17,348 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56945; # active connections: 2
2016-01-16 21:50:17,348 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56945 because read count=-1. Number of active connections: 2
2016-01-16 21:50:47,170 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57080; # active connections: 2
2016-01-16 21:50:47,170 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57080 because read count=-1. Number of active connections: 2
2016-01-16 21:51:17,297 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57232; # active connections: 2
2016-01-16 21:51:17,297 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57232 because read count=-1. Number of active connections: 2
2016-01-16 21:51:47,215 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57363; # active connections: 2
2016-01-16 21:51:47,216 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57363 because read count=-1. Number of active connections: 2
2016-01-16 21:52:17,222 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57512; # active connections: 2
2016-01-16 21:52:17,222 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57512 because read count=-1. Number of active connections: 2
2016-01-16 21:52:47,241 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57654; # active connections: 2
2016-01-16 21:52:47,241 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57654 because read count=-1. Number of active connections: 2
2016-01-16 21:52:59,474 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:52:59,486 DEBUG [htable-pool35-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:52:59,486 DEBUG [htable-pool35-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:53:17,295 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57793; # active connections: 2
2016-01-16 21:53:17,295 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57793 because read count=-1. Number of active connections: 2
2016-01-16 21:53:47,161 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57941; # active connections: 2
2016-01-16 21:53:47,162 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57941 because read count=-1. Number of active connections: 2
2016-01-16 21:54:17,379 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58111; # active connections: 2
2016-01-16 21:54:17,389 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58111 because read count=-1. Number of active connections: 2
2016-01-16 21:54:47,473 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58269; # active connections: 2
2016-01-16 21:54:47,473 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58269 because read count=-1. Number of active connections: 2
2016-01-16 21:55:17,382 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58427; # active connections: 2
2016-01-16 21:55:17,384 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58427 because read count=-1. Number of active connections: 2
2016-01-16 21:55:47,286 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58562; # active connections: 2
2016-01-16 21:55:47,286 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58562 because read count=-1. Number of active connections: 2
2016-01-16 21:56:17,323 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58705; # active connections: 2
2016-01-16 21:56:17,323 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58705 because read count=-1. Number of active connections: 2
2016-01-16 21:56:47,291 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58852; # active connections: 2
2016-01-16 21:56:47,291 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58852 because read count=-1. Number of active connections: 2
2016-01-16 21:57:17,432 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58985; # active connections: 2
2016-01-16 21:57:17,447 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58985 because read count=-1. Number of active connections: 2
2016-01-16 21:57:47,287 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59133; # active connections: 2
2016-01-16 21:57:47,288 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59133 because read count=-1. Number of active connections: 2
2016-01-16 21:57:59,478 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 21:57:59,487 DEBUG [htable-pool36-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 21:57:59,488 DEBUG [htable-pool36-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 21:58:17,384 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59275; # active connections: 2
2016-01-16 21:58:17,385 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59275 because read count=-1. Number of active connections: 2
2016-01-16 21:58:47,328 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59411; # active connections: 2
2016-01-16 21:58:47,329 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59411 because read count=-1. Number of active connections: 2
2016-01-16 21:59:17,339 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59547; # active connections: 2
2016-01-16 21:59:17,344 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59547 because read count=-1. Number of active connections: 2
2016-01-16 21:59:47,118 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59684; # active connections: 2
2016-01-16 21:59:47,122 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59684 because read count=-1. Number of active connections: 2
2016-01-16 22:00:17,208 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59827; # active connections: 2
2016-01-16 22:00:17,211 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59827 because read count=-1. Number of active connections: 2
2016-01-16 22:00:44,852 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59963; # active connections: 2
2016-01-16 22:00:44,912 INFO  [FifoRpcScheduler.handler1-thread-10] master.HMaster: Client=thenson//10.0.0.4 create 'tester1', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 22:00:45,042 DEBUG [FifoRpcScheduler.handler1-thread-10] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000000
2016-01-16 22:00:45,052 DEBUG [htable-pool37-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 22:00:45,052 DEBUG [htable-pool37-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:00:45,123 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table tester1
2016-01-16 22:00:45,275 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/.tabledesc/.tableinfo.0000000001
2016-01-16 22:00:45,280 INFO  [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: creating HRegion tester1 HTD == 'tester1', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == tester1
2016-01-16 22:00:45,432 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Instantiated tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.
2016-01-16 22:00:45,432 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Closing tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.: disabling compactions & flushes
2016-01-16 22:00:45,432 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Updates disabled for region tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.
2016-01-16 22:00:45,432 INFO  [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Closed tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.
2016-01-16 22:00:45,487 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 22:00:45,521 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:00:45,521 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 5b287cac0d55249b5f511065e5dd62ce with OFFLINE state
2016-01-16 22:00:45,542 DEBUG [main-EventThread] master.OfflineCallback: rs={5b287cac0d55249b5f511065e5dd62ce state=OFFLINE, ts=1452981645488, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:00:45,543 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={5b287cac0d55249b5f511065e5dd62ce state=OFFLINE, ts=1452981645488, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:00:45,549 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 22:00:45,550 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {5b287cac0d55249b5f511065e5dd62ce state=OFFLINE, ts=1452981645521, server=null} to {5b287cac0d55249b5f511065e5dd62ce state=PENDING_OPEN, ts=1452981645550, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,550 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 22:00:45,550 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:00:45,575 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:00:45,619 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000000
2016-01-16 22:00:45,619 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, tester1, creation successful
2016-01-16 22:00:45,661 DEBUG [AM.ZK.Worker-pool2-t36] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=5b287cac0d55249b5f511065e5dd62ce, current_state={5b287cac0d55249b5f511065e5dd62ce state=PENDING_OPEN, ts=1452981645550, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,662 INFO  [AM.ZK.Worker-pool2-t36] master.RegionStates: Transitioned {5b287cac0d55249b5f511065e5dd62ce state=PENDING_OPEN, ts=1452981645550, server=sandbox.hortonworks.com,60020,1452976657923} to {5b287cac0d55249b5f511065e5dd62ce state=OPENING, ts=1452981645662, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,861 DEBUG [AM.ZK.Worker-pool2-t37] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=5b287cac0d55249b5f511065e5dd62ce, current_state={5b287cac0d55249b5f511065e5dd62ce state=OPENING, ts=1452981645662, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,862 INFO  [AM.ZK.Worker-pool2-t37] master.RegionStates: Transitioned {5b287cac0d55249b5f511065e5dd62ce state=OPENING, ts=1452981645662, server=sandbox.hortonworks.com,60020,1452976657923} to {5b287cac0d55249b5f511065e5dd62ce state=OPEN, ts=1452981645862, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,862 DEBUG [AM.ZK.Worker-pool2-t37] handler.OpenedRegionHandler: Handling OPENED of 5b287cac0d55249b5f511065e5dd62ce from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 22:00:45,885 DEBUG [AM.ZK.Worker-pool2-t37] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 5b287cac0d55249b5f511065e5dd62ce in expected state RS_ZK_REGION_OPENED
2016-01-16 22:00:45,886 DEBUG [AM.ZK.Worker-pool2-t39] master.AssignmentManager: Znode tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce. deleted, state: {5b287cac0d55249b5f511065e5dd62ce state=OPEN, ts=1452981645862, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:00:45,886 INFO  [AM.ZK.Worker-pool2-t39] master.RegionStates: Onlined 5b287cac0d55249b5f511065e5dd62ce on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 5b287cac0d55249b5f511065e5dd62ce, NAME => 'tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:00:47,141 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59973; # active connections: 3
2016-01-16 22:00:47,142 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59973 because read count=-1. Number of active connections: 3
2016-01-16 22:01:15,920 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.003 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 22:01:15,920 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=12, outLogs=12, dropped=0
2016-01-16 22:01:17,164 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60119; # active connections: 3
2016-01-16 22:01:17,164 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60119 because read count=-1. Number of active connections: 3
2016-01-16 22:01:22,279 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 22:01:22,279 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=12, outLogs=12, dropped=0
2016-01-16 22:01:47,241 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60259; # active connections: 3
2016-01-16 22:01:47,241 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60259 because read count=-1. Number of active connections: 3
2016-01-16 22:02:17,396 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60429; # active connections: 3
2016-01-16 22:02:17,396 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60429 because read count=-1. Number of active connections: 3
2016-01-16 22:02:23,492 INFO  [FifoRpcScheduler.handler1-thread-45] master.HMaster: Client=thenson//10.0.0.4 disable tester
2016-01-16 22:02:23,532 DEBUG [FifoRpcScheduler.handler1-thread-45] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000001
2016-01-16 22:02:23,589 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table tester
2016-01-16 22:02:23,618 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-16 22:02:23,629 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of tester,,1452979492406.b45660a842120591786e0cb82bc427d7. (offlining), current state: {b45660a842120591786e0cb82bc427d7 state=OPEN, ts=1452979493326, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:23,629 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node b45660a842120591786e0cb82bc427d7 in a CLOSING state
2016-01-16 22:02:23,669 INFO  [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {b45660a842120591786e0cb82bc427d7 state=OPEN, ts=1452979493326, server=sandbox.hortonworks.com,60020,1452976657923} to {b45660a842120591786e0cb82bc427d7 state=PENDING_CLOSE, ts=1452981743669, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:23,693 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1452976657923 for region tester,,1452979492406.b45660a842120591786e0cb82bc427d7.
2016-01-16 22:02:24,629 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; [{ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:02:25,632 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 298998 ms remaining; [{ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:02:26,638 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 297995 ms remaining; [{ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:02:27,143 DEBUG [AM.ZK.Worker-pool2-t41] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1452976657923, region=b45660a842120591786e0cb82bc427d7, current_state={b45660a842120591786e0cb82bc427d7 state=PENDING_CLOSE, ts=1452981743669, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:27,143 DEBUG [AM.ZK.Worker-pool2-t41] handler.ClosedRegionHandler: Handling CLOSED event for b45660a842120591786e0cb82bc427d7
2016-01-16 22:02:27,143 DEBUG [AM.ZK.Worker-pool2-t41] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tester,,1452979492406.b45660a842120591786e0cb82bc427d7.
2016-01-16 22:02:27,200 DEBUG [AM.ZK.Worker-pool2-t41] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node b45660a842120591786e0cb82bc427d7 in expected state RS_ZK_REGION_CLOSED
2016-01-16 22:02:27,200 DEBUG [AM.ZK.Worker-pool2-t41] master.AssignmentManager: Removing region from replicasToClose {ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:02:27,200 INFO  [AM.ZK.Worker-pool2-t41] master.RegionStates: Transitioned {b45660a842120591786e0cb82bc427d7 state=PENDING_CLOSE, ts=1452981743669, server=sandbox.hortonworks.com,60020,1452976657923} to {b45660a842120591786e0cb82bc427d7 state=OFFLINE, ts=1452981747200, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:27,200 INFO  [AM.ZK.Worker-pool2-t41] master.RegionStates: Offlined b45660a842120591786e0cb82bc427d7 from sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:02:27,640 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 296989 ms remaining; []
2016-01-16 22:02:27,666 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, tester, is done=true
2016-01-16 22:02:27,680 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000001
2016-01-16 22:02:34,133 INFO  [FifoRpcScheduler.handler1-thread-51] master.HMaster: Client=thenson//10.0.0.4 delete tester
2016-01-16 22:02:34,356 DEBUG [FifoRpcScheduler.handler1-thread-51] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000002
2016-01-16 22:02:34,400 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table tester
2016-01-16 22:02:34,437 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-16 22:02:34,456 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => b45660a842120591786e0cb82bc427d7, NAME => 'tester,,1452979492406.b45660a842120591786e0cb82bc427d7.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:02:34,481 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region tester,,1452979492406.b45660a842120591786e0cb82bc427d7. from FS
2016-01-16 22:02:34,481 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7
2016-01-16 22:02:34,502 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7/info, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7/recovered.edits]
2016-01-16 22:02:34,653 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7/info/631a1d020ed14d14861ccf50b40d7e15, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester/b45660a842120591786e0cb82bc427d7/info/631a1d020ed14d14861ccf50b40d7e15
2016-01-16 22:02:34,790 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7/recovered.edits/17_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester/b45660a842120591786e0cb82bc427d7/recovered.edits/17_seqid
2016-01-16 22:02:34,812 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/b45660a842120591786e0cb82bc427d7
2016-01-16 22:02:34,844 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'tester' from region states.
2016-01-16 22:02:34,844 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'tester' as deleted.
2016-01-16 22:02:34,900 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000002
2016-01-16 22:02:42,186 INFO  [FifoRpcScheduler.handler1-thread-59] master.HMaster: Client=thenson//10.0.0.4 create 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 22:02:42,279 DEBUG [FifoRpcScheduler.handler1-thread-59] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 22:02:42,352 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table tester
2016-01-16 22:02:42,915 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/.tabledesc/.tableinfo.0000000001
2016-01-16 22:02:42,919 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: creating HRegion tester HTD == 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == tester
2016-01-16 22:02:43,040 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Instantiated tester,,1452981762185.42bbba91c5392324751d7583f9615196.
2016-01-16 22:02:43,040 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closing tester,,1452981762185.42bbba91c5392324751d7583f9615196.: disabling compactions & flushes
2016-01-16 22:02:43,041 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Updates disabled for region tester,,1452981762185.42bbba91c5392324751d7583f9615196.
2016-01-16 22:02:43,041 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closed tester,,1452981762185.42bbba91c5392324751d7583f9615196.
2016-01-16 22:02:43,088 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 22:02:43,116 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:02:43,117 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 42bbba91c5392324751d7583f9615196 with OFFLINE state
2016-01-16 22:02:43,153 DEBUG [main-EventThread] master.OfflineCallback: rs={42bbba91c5392324751d7583f9615196 state=OFFLINE, ts=1452981763088, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:02:43,154 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={42bbba91c5392324751d7583f9615196 state=OFFLINE, ts=1452981763088, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:02:43,160 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 22:02:43,161 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {42bbba91c5392324751d7583f9615196 state=OFFLINE, ts=1452981763117, server=null} to {42bbba91c5392324751d7583f9615196 state=PENDING_OPEN, ts=1452981763161, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,195 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:02:43,258 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 22:02:43,258 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, tester, creation successful
2016-01-16 22:02:43,259 DEBUG [AM.ZK.Worker-pool2-t45] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=42bbba91c5392324751d7583f9615196, current_state={42bbba91c5392324751d7583f9615196 state=PENDING_OPEN, ts=1452981763161, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,259 INFO  [AM.ZK.Worker-pool2-t45] master.RegionStates: Transitioned {42bbba91c5392324751d7583f9615196 state=PENDING_OPEN, ts=1452981763161, server=sandbox.hortonworks.com,60020,1452976657923} to {42bbba91c5392324751d7583f9615196 state=OPENING, ts=1452981763259, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,456 DEBUG [AM.ZK.Worker-pool2-t46] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=42bbba91c5392324751d7583f9615196, current_state={42bbba91c5392324751d7583f9615196 state=OPENING, ts=1452981763259, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,456 INFO  [AM.ZK.Worker-pool2-t46] master.RegionStates: Transitioned {42bbba91c5392324751d7583f9615196 state=OPENING, ts=1452981763259, server=sandbox.hortonworks.com,60020,1452976657923} to {42bbba91c5392324751d7583f9615196 state=OPEN, ts=1452981763456, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,456 DEBUG [AM.ZK.Worker-pool2-t46] handler.OpenedRegionHandler: Handling OPENED of 42bbba91c5392324751d7583f9615196 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 22:02:43,483 DEBUG [AM.ZK.Worker-pool2-t46] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 42bbba91c5392324751d7583f9615196 in expected state RS_ZK_REGION_OPENED
2016-01-16 22:02:43,512 DEBUG [AM.ZK.Worker-pool2-t48] master.AssignmentManager: Znode tester,,1452981762185.42bbba91c5392324751d7583f9615196. deleted, state: {42bbba91c5392324751d7583f9615196 state=OPEN, ts=1452981763456, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:02:43,512 INFO  [AM.ZK.Worker-pool2-t48] master.RegionStates: Onlined 42bbba91c5392324751d7583f9615196 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 42bbba91c5392324751d7583f9615196, NAME => 'tester,,1452981762185.42bbba91c5392324751d7583f9615196.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:02:47,317 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60607; # active connections: 3
2016-01-16 22:02:47,317 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60607 because read count=-1. Number of active connections: 3
2016-01-16 22:02:59,480 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 22:03:15,924 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.002 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 22:03:15,924 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=17, outLogs=17, dropped=0
2016-01-16 22:03:17,407 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60768; # active connections: 3
2016-01-16 22:03:17,422 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60768 because read count=-1. Number of active connections: 3
2016-01-16 22:03:22,283 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 22:03:22,283 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=17, outLogs=17, dropped=0
2016-01-16 22:03:47,300 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60902; # active connections: 3
2016-01-16 22:03:47,304 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60902 because read count=-1. Number of active connections: 3
2016-01-16 22:04:17,526 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:32816; # active connections: 3
2016-01-16 22:04:17,527 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:32816 because read count=-1. Number of active connections: 3
2016-01-16 22:04:42,686 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59963 because read count=-1. Number of active connections: 2
2016-01-16 22:04:47,346 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:32953; # active connections: 2
2016-01-16 22:04:47,347 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:32953 because read count=-1. Number of active connections: 2
2016-01-16 22:05:17,382 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33074; # active connections: 2
2016-01-16 22:05:17,382 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33074 because read count=-1. Number of active connections: 2
2016-01-16 22:05:47,217 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33255; # active connections: 2
2016-01-16 22:05:47,225 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33255 because read count=-1. Number of active connections: 2
2016-01-16 22:06:17,265 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33425; # active connections: 2
2016-01-16 22:06:17,267 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33425 because read count=-1. Number of active connections: 2
2016-01-16 22:06:47,133 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33597; # active connections: 2
2016-01-16 22:06:47,139 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33597 because read count=-1. Number of active connections: 2
2016-01-16 22:07:17,168 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33727; # active connections: 2
2016-01-16 22:07:17,183 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33727 because read count=-1. Number of active connections: 2
2016-01-16 22:07:47,316 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33873; # active connections: 2
2016-01-16 22:07:47,317 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33873 because read count=-1. Number of active connections: 2
2016-01-16 22:07:59,481 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 22:07:59,491 DEBUG [htable-pool46-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 22:07:59,491 DEBUG [htable-pool46-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:08:17,377 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34012; # active connections: 2
2016-01-16 22:08:17,381 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34012 because read count=-1. Number of active connections: 2
2016-01-16 22:08:47,374 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34143; # active connections: 2
2016-01-16 22:08:47,377 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34143 because read count=-1. Number of active connections: 2
2016-01-16 22:09:17,482 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34280; # active connections: 2
2016-01-16 22:09:17,489 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34280 because read count=-1. Number of active connections: 2
2016-01-16 22:09:47,266 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34410; # active connections: 2
2016-01-16 22:09:47,266 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34410 because read count=-1. Number of active connections: 2
2016-01-16 22:10:17,333 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34550; # active connections: 2
2016-01-16 22:10:17,334 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34550 because read count=-1. Number of active connections: 2
2016-01-16 22:10:47,255 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34677; # active connections: 2
2016-01-16 22:10:47,255 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34677 because read count=-1. Number of active connections: 2
2016-01-16 22:11:17,272 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34809; # active connections: 2
2016-01-16 22:11:17,272 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34809 because read count=-1. Number of active connections: 2
2016-01-16 22:11:35,936 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34906; # active connections: 2
2016-01-16 22:11:35,945 INFO  [FifoRpcScheduler.handler1-thread-59] master.HMaster: Client=thenson//10.0.0.4 disable tester1
2016-01-16 22:11:35,979 DEBUG [FifoRpcScheduler.handler1-thread-59] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000001
2016-01-16 22:11:35,981 DEBUG [htable-pool47-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 22:11:35,981 DEBUG [htable-pool47-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:11:36,025 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table tester1
2016-01-16 22:11:36,025 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:20.082 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 22:11:36,026 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=18, outLogs=18, dropped=0
2016-01-16 22:11:36,058 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-16 22:11:36,061 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce. (offlining), current state: {5b287cac0d55249b5f511065e5dd62ce state=OPEN, ts=1452981645886, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:11:36,061 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 5b287cac0d55249b5f511065e5dd62ce in a CLOSING state
2016-01-16 22:11:36,121 INFO  [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {5b287cac0d55249b5f511065e5dd62ce state=OPEN, ts=1452981645886, server=sandbox.hortonworks.com,60020,1452976657923} to {5b287cac0d55249b5f511065e5dd62ce state=PENDING_CLOSE, ts=1452982296121, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:11:36,121 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 22:11:36,122 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:11:36,132 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1452976657923 for region tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.
2016-01-16 22:11:36,980 DEBUG [AM.ZK.Worker-pool2-t50] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1452976657923, region=5b287cac0d55249b5f511065e5dd62ce, current_state={5b287cac0d55249b5f511065e5dd62ce state=PENDING_CLOSE, ts=1452982296121, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:11:36,980 DEBUG [AM.ZK.Worker-pool2-t50] handler.ClosedRegionHandler: Handling CLOSED event for 5b287cac0d55249b5f511065e5dd62ce
2016-01-16 22:11:36,980 DEBUG [AM.ZK.Worker-pool2-t50] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.
2016-01-16 22:11:37,060 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; [{ENCODED => 5b287cac0d55249b5f511065e5dd62ce, NAME => 'tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:11:37,066 DEBUG [AM.ZK.Worker-pool2-t50] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 5b287cac0d55249b5f511065e5dd62ce in expected state RS_ZK_REGION_CLOSED
2016-01-16 22:11:37,067 DEBUG [AM.ZK.Worker-pool2-t50] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 5b287cac0d55249b5f511065e5dd62ce, NAME => 'tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:11:37,067 INFO  [AM.ZK.Worker-pool2-t50] master.RegionStates: Transitioned {5b287cac0d55249b5f511065e5dd62ce state=PENDING_CLOSE, ts=1452982296121, server=sandbox.hortonworks.com,60020,1452976657923} to {5b287cac0d55249b5f511065e5dd62ce state=OFFLINE, ts=1452982297067, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:11:37,067 INFO  [AM.ZK.Worker-pool2-t50] master.RegionStates: Offlined 5b287cac0d55249b5f511065e5dd62ce from sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:11:38,064 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 298998 ms remaining; []
2016-01-16 22:11:38,105 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, tester1, is done=true
2016-01-16 22:11:38,135 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000001
2016-01-16 22:11:44,190 INFO  [FifoRpcScheduler.handler1-thread-4] master.HMaster: Client=thenson//10.0.0.4 delete tester1
2016-01-16 22:11:44,220 DEBUG [FifoRpcScheduler.handler1-thread-4] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000002
2016-01-16 22:11:44,270 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table tester1
2016-01-16 22:11:44,287 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-16 22:11:44,314 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 5b287cac0d55249b5f511065e5dd62ce, NAME => 'tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:11:44,374 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region tester1,,1452981644905.5b287cac0d55249b5f511065e5dd62ce. from FS
2016-01-16 22:11:44,374 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce
2016-01-16 22:11:44,417 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/info, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/recovered.edits]
2016-01-16 22:11:44,558 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/info/6af8bf52a0d54ef88dae763845c75f83, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/info/6af8bf52a0d54ef88dae763845c75f83
2016-01-16 22:11:44,687 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/recovered.edits/12_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce/recovered.edits/12_seqid
2016-01-16 22:11:44,716 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/5b287cac0d55249b5f511065e5dd62ce
2016-01-16 22:11:44,785 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'tester1' from region states.
2016-01-16 22:11:44,785 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'tester1' as deleted.
2016-01-16 22:11:44,841 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000002
2016-01-16 22:11:47,283 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34985; # active connections: 3
2016-01-16 22:11:47,283 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34985 because read count=-1. Number of active connections: 3
2016-01-16 22:12:17,382 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35134; # active connections: 3
2016-01-16 22:12:17,382 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35134 because read count=-1. Number of active connections: 3
2016-01-16 22:12:22,303 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 22:12:22,303 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=22, outLogs=22, dropped=0
2016-01-16 22:12:26,455 INFO  [FifoRpcScheduler.handler1-thread-26] master.HMaster: Client=thenson//10.0.0.4 create 'tester1', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 22:12:27,370 DEBUG [FifoRpcScheduler.handler1-thread-26] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000000
2016-01-16 22:12:27,415 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table tester1
2016-01-16 22:12:27,601 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/.tabledesc/.tableinfo.0000000001
2016-01-16 22:12:27,605 INFO  [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: creating HRegion tester1 HTD == 'tester1', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == tester1
2016-01-16 22:12:27,776 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Instantiated tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.
2016-01-16 22:12:27,776 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Closing tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.: disabling compactions & flushes
2016-01-16 22:12:27,776 DEBUG [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Updates disabled for region tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.
2016-01-16 22:12:27,776 INFO  [RegionOpenAndInitThread-tester1-1] regionserver.HRegion: Closed tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.
2016-01-16 22:12:27,811 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 22:12:27,845 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:12:27,845 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node a1abc6352f6e6010b61cd89061575d15 with OFFLINE state
2016-01-16 22:12:27,871 DEBUG [main-EventThread] master.OfflineCallback: rs={a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1452982347812, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:12:27,875 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1452982347812, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:12:27,879 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 22:12:27,880 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1452982347845, server=null} to {a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1452982347880, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:27,905 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:12:27,960 DEBUG [AM.ZK.Worker-pool2-t54] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=a1abc6352f6e6010b61cd89061575d15, current_state={a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1452982347880, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:27,960 INFO  [AM.ZK.Worker-pool2-t54] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1452982347880, server=sandbox.hortonworks.com,60020,1452976657923} to {a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1452982347960, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:27,976 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000000
2016-01-16 22:12:27,976 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, tester1, creation successful
2016-01-16 22:12:28,071 DEBUG [AM.ZK.Worker-pool2-t55] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=a1abc6352f6e6010b61cd89061575d15, current_state={a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1452982347960, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:28,071 INFO  [AM.ZK.Worker-pool2-t55] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1452982347960, server=sandbox.hortonworks.com,60020,1452976657923} to {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1452982348071, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:28,071 DEBUG [AM.ZK.Worker-pool2-t55] handler.OpenedRegionHandler: Handling OPENED of a1abc6352f6e6010b61cd89061575d15 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 22:12:28,087 DEBUG [AM.ZK.Worker-pool2-t55] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node a1abc6352f6e6010b61cd89061575d15 in expected state RS_ZK_REGION_OPENED
2016-01-16 22:12:28,088 DEBUG [AM.ZK.Worker-pool2-t57] master.AssignmentManager: Znode tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15. deleted, state: {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1452982348071, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:12:28,088 INFO  [AM.ZK.Worker-pool2-t57] master.RegionStates: Onlined a1abc6352f6e6010b61cd89061575d15 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => a1abc6352f6e6010b61cd89061575d15, NAME => 'tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:12:36,730 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.703 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-16 22:12:36,730 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=23, outLogs=23, dropped=0
2016-01-16 22:12:47,091 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35292; # active connections: 3
2016-01-16 22:12:47,091 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35292 because read count=-1. Number of active connections: 3
2016-01-16 22:12:59,483 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 22:13:17,270 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35429; # active connections: 3
2016-01-16 22:13:17,274 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35429 because read count=-1. Number of active connections: 3
2016-01-16 22:13:22,305 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 22:13:22,305 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=23, outLogs=23, dropped=0
2016-01-16 22:13:47,303 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35557; # active connections: 3
2016-01-16 22:13:47,311 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35557 because read count=-1. Number of active connections: 3
2016-01-16 22:14:17,380 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35695; # active connections: 3
2016-01-16 22:14:17,384 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35695 because read count=-1. Number of active connections: 3
2016-01-16 22:14:27,632 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34906 because read count=-1. Number of active connections: 2
2016-01-16 22:14:47,253 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35826; # active connections: 2
2016-01-16 22:14:47,253 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35826 because read count=-1. Number of active connections: 2
2016-01-16 22:15:11,397 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35954; # active connections: 2
2016-01-16 22:15:11,421 INFO  [FifoRpcScheduler.handler1-thread-23] master.HMaster: Client=thenson//10.0.0.4 disable tester
2016-01-16 22:15:11,448 DEBUG [FifoRpcScheduler.handler1-thread-23] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000001
2016-01-16 22:15:11,456 DEBUG [htable-pool54-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 22:15:11,456 DEBUG [htable-pool54-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:15:11,523 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table tester
2016-01-16 22:15:12,506 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-16 22:15:12,508 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of tester,,1452981762185.42bbba91c5392324751d7583f9615196. (offlining), current state: {42bbba91c5392324751d7583f9615196 state=OPEN, ts=1452981763512, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:12,508 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 42bbba91c5392324751d7583f9615196 in a CLOSING state
2016-01-16 22:15:12,601 INFO  [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {42bbba91c5392324751d7583f9615196 state=OPEN, ts=1452981763512, server=sandbox.hortonworks.com,60020,1452976657923} to {42bbba91c5392324751d7583f9615196 state=PENDING_CLOSE, ts=1452982512601, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:12,602 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-16 22:15:12,602 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:15:12,607 DEBUG [sandbox.hortonworks.com,60000,1452976622547-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1452976657923 for region tester,,1452981762185.42bbba91c5392324751d7583f9615196.
2016-01-16 22:15:12,977 DEBUG [AM.ZK.Worker-pool2-t59] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1452976657923, region=42bbba91c5392324751d7583f9615196, current_state={42bbba91c5392324751d7583f9615196 state=PENDING_CLOSE, ts=1452982512601, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:12,977 DEBUG [AM.ZK.Worker-pool2-t59] handler.ClosedRegionHandler: Handling CLOSED event for 42bbba91c5392324751d7583f9615196
2016-01-16 22:15:12,977 DEBUG [AM.ZK.Worker-pool2-t59] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tester,,1452981762185.42bbba91c5392324751d7583f9615196.
2016-01-16 22:15:13,010 DEBUG [AM.ZK.Worker-pool2-t59] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 42bbba91c5392324751d7583f9615196 in expected state RS_ZK_REGION_CLOSED
2016-01-16 22:15:13,011 DEBUG [AM.ZK.Worker-pool2-t59] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 42bbba91c5392324751d7583f9615196, NAME => 'tester,,1452981762185.42bbba91c5392324751d7583f9615196.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:15:13,011 INFO  [AM.ZK.Worker-pool2-t59] master.RegionStates: Transitioned {42bbba91c5392324751d7583f9615196 state=PENDING_CLOSE, ts=1452982512601, server=sandbox.hortonworks.com,60020,1452976657923} to {42bbba91c5392324751d7583f9615196 state=OFFLINE, ts=1452982513011, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:13,011 INFO  [AM.ZK.Worker-pool2-t59] master.RegionStates: Offlined 42bbba91c5392324751d7583f9615196 from sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:15:13,509 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-16 22:15:13,538 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, tester, is done=true
2016-01-16 22:15:13,553 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000001
2016-01-16 22:15:17,334 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35975; # active connections: 3
2016-01-16 22:15:17,335 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35975 because read count=-1. Number of active connections: 3
2016-01-16 22:15:17,639 INFO  [FifoRpcScheduler.handler1-thread-27] master.HMaster: Client=thenson//10.0.0.4 delete tester
2016-01-16 22:15:17,668 DEBUG [FifoRpcScheduler.handler1-thread-27] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000002
2016-01-16 22:15:17,701 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table tester
2016-01-16 22:15:17,748 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-16 22:15:17,759 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 42bbba91c5392324751d7583f9615196, NAME => 'tester,,1452981762185.42bbba91c5392324751d7583f9615196.', STARTKEY => '', ENDKEY => ''}]
2016-01-16 22:15:18,351 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region tester,,1452981762185.42bbba91c5392324751d7583f9615196. from FS
2016-01-16 22:15:18,351 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196
2016-01-16 22:15:18,398 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196/info, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196/recovered.edits]
2016-01-16 22:15:18,573 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196/info/af3346bc92904914a80c8172f375c591, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester/42bbba91c5392324751d7583f9615196/info/af3346bc92904914a80c8172f375c591
2016-01-16 22:15:18,680 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196/recovered.edits/8_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester/42bbba91c5392324751d7583f9615196/recovered.edits/8_seqid
2016-01-16 22:15:18,710 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/42bbba91c5392324751d7583f9615196
2016-01-16 22:15:18,728 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'tester' from region states.
2016-01-16 22:15:18,728 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'tester' as deleted.
2016-01-16 22:15:18,772 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000002
2016-01-16 22:15:22,312 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.003 minutes: inLogs=6, outLogs=6, dropped=0, currentQueueSize=0
2016-01-16 22:15:22,313 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=29, outLogs=29, dropped=0
2016-01-16 22:15:25,010 INFO  [FifoRpcScheduler.handler1-thread-38] master.HMaster: Client=thenson//10.0.0.4 create 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-16 22:15:25,087 DEBUG [FifoRpcScheduler.handler1-thread-38] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 22:15:25,133 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table tester
2016-01-16 22:15:25,250 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester/.tabledesc/.tableinfo.0000000001
2016-01-16 22:15:25,269 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: creating HRegion tester HTD == 'tester', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == tester
2016-01-16 22:15:25,430 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Instantiated tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.
2016-01-16 22:15:25,430 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closing tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.: disabling compactions & flushes
2016-01-16 22:15:25,430 DEBUG [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Updates disabled for region tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.
2016-01-16 22:15:25,430 INFO  [RegionOpenAndInitThread-tester-1] regionserver.HRegion: Closed tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.
2016-01-16 22:15:25,492 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-16 22:15:25,524 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:15:25,524 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 61a91320bb285054243d16e6dedd4a76 with OFFLINE state
2016-01-16 22:15:25,554 DEBUG [main-EventThread] master.OfflineCallback: rs={61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1452982525493, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:15:25,556 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1452982525493, server=null}, server=sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:15:25,559 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1452976657923 unassigned znodes=1 of total=1
2016-01-16 22:15:25,559 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1452982525524, server=null} to {61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1452982525559, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,583 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1452976657923
2016-01-16 22:15:25,610 DEBUG [AM.ZK.Worker-pool2-t63] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1452976657923, region=61a91320bb285054243d16e6dedd4a76, current_state={61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1452982525559, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,614 INFO  [AM.ZK.Worker-pool2-t63] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1452982525559, server=sandbox.hortonworks.com,60020,1452976657923} to {61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1452982525614, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,647 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester/write-master:600000000000000
2016-01-16 22:15:25,648 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, tester, creation successful
2016-01-16 22:15:25,743 DEBUG [AM.ZK.Worker-pool2-t64] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1452976657923, region=61a91320bb285054243d16e6dedd4a76, current_state={61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1452982525614, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,743 INFO  [AM.ZK.Worker-pool2-t64] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1452982525614, server=sandbox.hortonworks.com,60020,1452976657923} to {61a91320bb285054243d16e6dedd4a76 state=OPEN, ts=1452982525743, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,743 DEBUG [AM.ZK.Worker-pool2-t64] handler.OpenedRegionHandler: Handling OPENED of 61a91320bb285054243d16e6dedd4a76 from sandbox.hortonworks.com,60020,1452976657923; deleting unassigned node
2016-01-16 22:15:25,773 DEBUG [AM.ZK.Worker-pool2-t64] zookeeper.ZKAssign: master:60000-0x1524c1e05200002, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 61a91320bb285054243d16e6dedd4a76 in expected state RS_ZK_REGION_OPENED
2016-01-16 22:15:25,774 DEBUG [AM.ZK.Worker-pool2-t66] master.AssignmentManager: Znode tester,,1452982525007.61a91320bb285054243d16e6dedd4a76. deleted, state: {61a91320bb285054243d16e6dedd4a76 state=OPEN, ts=1452982525743, server=sandbox.hortonworks.com,60020,1452976657923}
2016-01-16 22:15:25,774 INFO  [AM.ZK.Worker-pool2-t66] master.RegionStates: Onlined 61a91320bb285054243d16e6dedd4a76 on sandbox.hortonworks.com,60020,1452976657923 {ENCODED => 61a91320bb285054243d16e6dedd4a76, NAME => 'tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.', STARTKEY => '', ENDKEY => ''}
2016-01-16 22:15:42,542 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:05.808 minutes: inLogs=7, outLogs=7, dropped=0, currentQueueSize=0
2016-01-16 22:15:42,542 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=30, outLogs=30, dropped=0
2016-01-16 22:15:47,333 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36117; # active connections: 3
2016-01-16 22:15:47,333 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36117 because read count=-1. Number of active connections: 3
2016-01-16 22:16:17,270 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36292; # active connections: 3
2016-01-16 22:16:17,271 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36292 because read count=-1. Number of active connections: 3
2016-01-16 22:16:47,427 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36448; # active connections: 3
2016-01-16 22:16:47,434 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36448 because read count=-1. Number of active connections: 3
2016-01-16 22:17:17,238 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36596; # active connections: 3
2016-01-16 22:17:17,245 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36596 because read count=-1. Number of active connections: 3
2016-01-16 22:17:22,316 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 02:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-16 22:17:22,316 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=30, outLogs=30, dropped=0
2016-01-16 22:17:25,497 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35954 because read count=-1. Number of active connections: 2
2016-01-16 22:17:47,171 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36744; # active connections: 2
2016-01-16 22:17:47,175 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36744 because read count=-1. Number of active connections: 2
2016-01-16 22:17:59,484 DEBUG [sandbox.hortonworks.com,60000,1452976622547-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-16 22:17:59,494 DEBUG [htable-pool60-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-16 22:17:59,495 DEBUG [htable-pool60-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-16 22:18:17,166 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36883; # active connections: 2
2016-01-16 22:18:17,176 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36883 because read count=-1. Number of active connections: 2
2016-01-16 22:18:47,366 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37014; # active connections: 2
2016-01-16 22:18:47,366 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37014 because read count=-1. Number of active connections: 2
2016-01-16 22:19:17,444 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37174; # active connections: 2
2016-01-16 22:19:17,449 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37174 because read count=-1. Number of active connections: 2
2016-01-16 22:19:47,160 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37330; # active connections: 2
2016-01-16 22:19:47,160 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37330 because read count=-1. Number of active connections: 2
2016-01-16 22:20:17,241 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37480; # active connections: 2
2016-01-16 22:20:17,242 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37480 because read count=-1. Number of active connections: 2
2016-01-16 22:20:47,141 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37619; # active connections: 2
2016-01-16 22:20:47,145 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37619 because read count=-1. Number of active connections: 2
2016-01-16 22:21:17,190 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37750; # active connections: 2
2016-01-16 22:21:17,191 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37750 because read count=-1. Number of active connections: 2
2016-01-16 22:21:47,112 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37843; # active connections: 2
2016-01-16 22:21:47,112 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37843 because read count=-1. Number of active connections: 2
2016-01-16 22:22:02,028 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception, retry in 4227ms
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2016-01-16 22:22:05,251 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1088191_1] for 30 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "sandbox.hortonworks.com/10.0.0.4"; destination host is: "sandbox.hortonworks.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor115.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor115.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 21 more
2016-01-16 22:22:06,254 WARN  [LeaseRenewer:hbase@sandbox.hortonworks.com:8020] hdfs.LeaseRenewer: Failed to renew lease for [DFSClient_NONMAPREDUCE_-1088191_1] for 31 seconds.  Will retry shortly ...
java.io.IOException: Failed on local exception: java.net.SocketException: Network is unreachable; Host Details : local host is: "sandbox.hortonworks.com/10.0.0.4"; destination host is: "sandbox.hortonworks.com":8020; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:772)
	at org.apache.hadoop.ipc.Client.call(Client.java:1472)
	at org.apache.hadoop.ipc.Client.call(Client.java:1399)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy13.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.renewLease(ClientNamenodeProtocolTranslatorPB.java:571)
	at sun.reflect.GeneratedMethodAccessor115.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy14.renewLease(Unknown Source)
	at sun.reflect.GeneratedMethodAccessor115.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:294)
	at com.sun.proxy.$Proxy16.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient.renewLease(DFSClient.java:879)
	at org.apache.hadoop.hdfs.LeaseRenewer.renew(LeaseRenewer.java:417)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:442)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:298)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Network is unreachable
	at sun.nio.ch.Net.connect0(Native Method)
	at sun.nio.ch.Net.connect(Net.java:465)
	at sun.nio.ch.Net.connect(Net.java:457)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:670)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:607)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:705)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:368)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1521)
	at org.apache.hadoop.ipc.Client.call(Client.java:1438)
	... 21 more
2016-01-16 22:22:06,270 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception and over retry limit, suppressing further error messages
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2016-01-16 22:22:06,413 INFO  [Thread-20] provider.DbAuditProvider: DbAuditProvider.waitToComplete()
Sun Jan 17 17:53:09 UTC 2016 Starting master on sandbox.hortonworks.com
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 55707
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 1024
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
2016-01-17 17:53:14,822 INFO  [main] util.VersionInfo: HBase 0.98.4.2.2.0.0-2041-hadoop2
2016-01-17 17:53:14,955 INFO  [main] util.VersionInfo: Subversion git://ip-10-0-0-5.ec2.internal/grid/0/jenkins/workspace/HDP-champlain-centos6/bigtop/build/hbase/rpm/BUILD/hbase-0.98.4.2.2.0.0 -r 18e3e58ae6ca5ef5e9c60e3129a1089a8656f91d
2016-01-17 17:53:14,955 INFO  [main] util.VersionInfo: Compiled by jenkins on Wed Nov 19 15:10:28 EST 2014
2016-01-17 17:53:15,995 INFO  [main] util.ServerCommandLine: env:TERM=linux
2016-01-17 17:53:15,995 INFO  [main] util.ServerCommandLine: env:JAVA_HOME=/usr/lib/jvm/java-1.7.0-openjdk.x86_64
2016-01-17 17:53:15,995 INFO  [main] util.ServerCommandLine: env:HBASE_HOME=/usr/hdp/current/hbase-client/bin/..
2016-01-17 17:53:15,995 INFO  [main] util.ServerCommandLine: env:HBASE_ENV_INIT=true
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:MAIL=/var/spool/mail/hbase
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HOSTNAME=sandbox.hortonworks.com
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:PWD=/home/hbase
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HBASE_ZNODE_FILE=/var/run/hbase/hbase-hbase-master.znode
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HBASE_MASTER_OPTS= -Xmx1024m
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:CVS_RSH=ssh
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HBASE_MANAGES_ZK=false
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:G_BROKEN_FILENAMES=1
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HBASE_NICENESS=0
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat
2016-01-17 17:53:15,996 INFO  [main] util.ServerCommandLine: env:HBASE_REST_OPTS=
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:ZOOKEEPER_HOME=/usr/hdp/2.2.0.0-2041/zookeeper
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:HBASE_PID_DIR=/var/run/hbase
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVER_OPTS= -Xmn200m -XX:CMSInitiatingOccupancyFraction=70  -Xms1024m -Xmx1024m
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:HISTSIZE=1000
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:PATH=/usr/lib64/qt-3.3/bin:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/usr/hdp/current/falcon-client/bin:/usr/hdp/current/hadoop-mapreduce-historyserver/bin:/usr/hdp/current/oozie-client/bin:/usr/hdp/current/falcon-server/bin:/usr/hdp/current/hadoop-yarn-client/bin:/usr/hdp/current/oozie-server/bin:/usr/hdp/current/flume-client/bin:/usr/hdp/current/hadoop-yarn-nodemanager/bin:/usr/hdp/current/pig-client/bin:/usr/hdp/current/flume-server/bin:/usr/hdp/current/hadoop-yarn-resourcemanager/bin:/usr/hdp/current/slider-client/bin:/usr/hdp/current/hadoop-client/bin:/usr/hdp/current/hadoop-yarn-timelineserver/bin:/usr/hdp/current/sqoop-client/bin:/usr/hdp/current/hadoop-hdfs-client/bin:/usr/hdp/current/hbase-client/bin:/usr/hdp/current/sqoop-server/bin:/usr/hdp/current/hadoop-hdfs-datanode/bin:/usr/hdp/current/hbase-master/bin:/usr/hdp/current/storm-client/bin:/usr/hdp/current/hadoop-hdfs-journalnode/bin:/usr/hdp/current/hbase-regionserver/bin:/usr/hdp/current/storm-nimbus/bin:/usr/hdp/current/hadoop-hdfs-namenode/bin:/usr/hdp/current/hive-client/bin:/usr/hdp/current/storm-supervisor/bin:/usr/hdp/current/hadoop-hdfs-nfs3/bin:/usr/hdp/current/hive-metastore/bin:/usr/hdp/current/zookeeper-client/bin:/usr/hdp/current/hadoop-hdfs-portmap/bin:/usr/hdp/current/hive-server2/bin:/usr/hdp/current/zookeeper-server/bin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/bin:/usr/hdp/current/hive-webhcat/bin:/usr/hdp/current/hadoop-mapreduce-client/bin:/usr/hdp/current/knox-server/bin:/usr/hdp/current/hadoop-client/sbin:/usr/hdp/current/hadoop-hdfs-nfs3/sbin:/usr/hdp/current/hadoop-yarn-client/sbin:/usr/hdp/current/hadoop-hdfs-client/sbin:/usr/hdp/current/hadoop-hdfs-portmap/sbin:/usr/hdp/current/hadoop-yarn-nodemanager/sbin:/usr/hdp/current/hadoop-hdfs-datanode/sbin:/usr/hdp/current/hadoop-hdfs-secondarynamenode/sbin:/usr/hdp/current/hadoop-yarn-resourcemanager/sbin:/usr/hdp/current/hadoop-hdfs-journalnode/sbin:/usr/hdp/current/hadoop-mapreduce-client/sbin:/usr/hdp/current/hadoop-yarn-timelineserver/sbin:/usr/hdp/current/hadoop-hdfs-namenode/sbin:/usr/hdp/current/hadoop-mapreduce-historyserver/sbin:/usr/hdp/current/hive-webhcat/sbin:/home/hbase/bin
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:HADOOP_CONF=/usr/hdp/2.2.0.0-2041/hadoop/conf
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:HDP_VERSION=2.2.0.0-2041
2016-01-17 17:53:15,997 INFO  [main] util.ServerCommandLine: env:QTLIB=/usr/lib64/qt-3.3/lib
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_REGIONSERVERS=/etc/hbase/conf/regionservers
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_SECURITY_LOGGER=INFO,RFAS
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_START_FILE=/var/run/hbase/hbase-hbase-master.autorestart
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:SERVER_GC_OPTS=-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201601171753
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_LOGFILE=hbase-hbase-master-sandbox.hortonworks.com.log
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:SHLVL=3
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_DIR=/var/log/hbase
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:HBASE_OPTS=-Dhdp.version=2.2.0.0-2041  -XX:+UseConcMarkSweepGC -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/var/log/hbase/gc.log-201601171753  -Xmx1024m -Dhbase.log.dir=/var/log/hbase -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.. -Dhbase.id.str=hbase -Dhbase.root.logger=INFO,RFA -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native -Dhbase.security.logger=INFO,RFAS
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt
2016-01-17 17:53:15,998 INFO  [main] util.ServerCommandLine: env:LOGNAME=hbase
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:HBASE_CONF_DIR=/etc/hbase/conf
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:QTDIR=/usr/lib64/qt-3.3
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:HADOOP_HOME=/usr/hdp/2.2.0.0-2041/hadoop
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:MALLOC_ARENA_MAX=4
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:LD_LIBRARY_PATH=::/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:SHELL=/bin/bash
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:HBASE_ROOT_LOGGER=INFO,RFA
2016-01-17 17:53:15,999 INFO  [main] util.ServerCommandLine: env:CLASSPATH=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/hadoop/.//*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//*::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/*:/usr/hdp/current/tez-client/*:/usr/hdp/current/tez-client/lib/*:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/*:/usr/hdp/2.2.0.0-2041/tez/lib/*:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2016-01-17 17:53:16,000 INFO  [main] util.ServerCommandLine: env:HBASE_THRIFT_OPTS=
2016-01-17 17:53:16,000 INFO  [main] util.ServerCommandLine: env:QTINC=/usr/lib64/qt-3.3/include
2016-01-17 17:53:16,000 INFO  [main] util.ServerCommandLine: env:USER=hbase
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:HBASE_CLASSPATH=/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/*:/usr/hdp/2.2.0.0-2041/hadoop/lib/*:/usr/hdp/2.2.0.0-2041/zookeeper/*:/usr/hdp/2.2.0.0-2041/zookeeper/lib/*:
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:HOME=/home/hbase
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:HISTCONTROL=ignoredups
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:LESSOPEN=||/usr/bin/lesspipe.sh %s
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:HBASE_LOG_PREFIX=hbase-hbase-master-sandbox.hortonworks.com
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:LANG=en_US.UTF-8
2016-01-17 17:53:16,001 INFO  [main] util.ServerCommandLine: env:HBASE_IDENT_STRING=hbase
2016-01-17 17:53:16,008 INFO  [main] util.ServerCommandLine: vmName=OpenJDK 64-Bit Server VM, vmVendor=Oracle Corporation, vmVersion=24.65-b04
2016-01-17 17:53:16,008 INFO  [main] util.ServerCommandLine: vmInputArguments=[-Dproc_master, -XX:OnOutOfMemoryError=kill -9 %p, -Xmx1000m, -Dhdp.version=2.2.0.0-2041, -XX:+UseConcMarkSweepGC, -XX:ErrorFile=/var/log/hbase/hs_err_pid%p.log, -verbose:gc, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -Xloggc:/var/log/hbase/gc.log-201601171753, -Xmx1024m, -Dhbase.log.dir=/var/log/hbase, -Dhbase.log.file=hbase-hbase-master-sandbox.hortonworks.com.log, -Dhbase.home.dir=/usr/hdp/current/hbase-client/bin/.., -Dhbase.id.str=hbase, -Dhbase.root.logger=INFO,RFA, -Djava.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native, -Dhbase.security.logger=INFO,RFAS]
2016-01-17 17:53:16,155 DEBUG [main] master.HMaster: master/sandbox.hortonworks.com/10.0.0.4:60000 HConnection server-to-server retries=350
2016-01-17 17:53:16,892 INFO  [main] ipc.RpcServer: master/sandbox.hortonworks.com/10.0.0.4:60000: started 10 reader(s).
2016-01-17 17:53:17,247 INFO  [main] impl.MetricsConfig: loaded properties from hadoop-metrics2-hbase.properties
2016-01-17 17:53:17,568 INFO  [main] impl.MetricsSinkAdapter: Sink ganglia started
2016-01-17 17:53:17,864 INFO  [main] impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2016-01-17 17:53:17,864 INFO  [main] impl.MetricsSystemImpl: HBase metrics system started
2016-01-17 17:53:21,753 INFO  [main] master.HMaster: hbase.rootdir=hdfs://sandbox.hortonworks.com:8020/apps/hbase/data, hbase.cluster.distributed=true
2016-01-17 17:53:21,792 INFO  [main] Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-2041--1, built on 11/19/2014 19:24 GMT
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=sandbox.hortonworks.com
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-1.7.0-openjdk-1.7.0.71.x86_64/jre
2016-01-17 17:53:21,959 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase/conf:/usr/lib/jvm/java-1.7.0-openjdk.x86_64/lib/tools.jar:/usr/hdp/current/hbase-client/bin/..:/usr/hdp/current/hbase-client/bin/../lib/activation-1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/aopalliance-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hbase-client/bin/../lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/api-util-1.0.0-M20.jar:/usr/hdp/current/hbase-client/bin/../lib/asm-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/avro-1.7.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-1.7.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-cli-1.2.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-codec-1.7.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-collections-3.2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-compress-1.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-configuration-1.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-daemon-1.0.13.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-digester-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-el-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-httpclient-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-io-2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-lang-2.6.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-logging-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math-2.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-math3-3.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/commons-net-3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-client-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-framework-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/curator-recipes-2.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/eclipselink-2.5.2-M1.jar:/usr/hdp/current/hbase-client/bin/../lib/findbugs-annotations-1.3.9-1.jar:/usr/hdp/current/hbase-client/bin/../lib/gson-2.2.4.jar:/usr/hdp/current/hbase-client/bin/../lib/guava-12.0.1.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/guice-servlet-3.0.jar:/usr/hdp/current/hbase-client/bin/../lib/hamcrest-core-1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-client.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-common.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-examples.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop2-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-hadoop-compat.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-it.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-prefix-tree.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-protocol.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server-0.98.4.2.2.0.0-2041-hadoop2-tests.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-server.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-shell.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-testing-util.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift-0.98.4.2.2.0.0-2041-hadoop2.jar:/usr/hdp/current/hbase-client/bin/../lib/hbase-thrift.jar:/usr/hdp/current/hbase-client/bin/../lib/high-scale-lib-1.1.1.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-2.04.jar:/usr/hdp/current/hbase-client/bin/../lib/htrace-core-3.0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/httpclient-4.2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/httpcore-4.1.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-2.2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jackson-xc-1.9.13.jar:/usr/hdp/current/hbase-client/bin/../lib/jamon-runtime-2.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-compiler-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/jasper-runtime-5.5.23.jar:/usr/hdp/current/hbase-client/bin/../lib/javax.inject-1.jar:/usr/hdp/current/hbase-client/bin/../lib/java-xmlbuilder-0.4.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-api-2.2.2.jar:/usr/hdp/current/hbase-client/bin/../lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-client-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-core-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-guice-1.9.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-json-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jersey-server-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jets3t-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/jettison-1.3.1.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-sslengine-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jetty-util-6.1.26.jar:/usr/hdp/current/hbase-client/bin/../lib/jruby-complete-1.6.8.jar:/usr/hdp/current/hbase-client/bin/../lib/jsch-0.1.42.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsp-api-2.1-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/jsr305-1.3.9.jar:/usr/hdp/current/hbase-client/bin/../lib/junit-4.11.jar:/usr/hdp/current/hbase-client/bin/../lib/leveldbjni-all-1.8.jar:/usr/hdp/current/hbase-client/bin/../lib/libthrift-0.9.0.jar:/usr/hdp/current/hbase-client/bin/../lib/log4j-1.2.17.jar:/usr/hdp/current/hbase-client/bin/../lib/metrics-core-2.2.0.jar:/usr/hdp/current/hbase-client/bin/../lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hbase-client/bin/../lib/mysql-connector-java.jar:/usr/hdp/current/hbase-client/bin/../lib/netty-3.6.6.Final.jar:/usr/hdp/current/hbase-client/bin/../lib/ojdbc6.jar:/usr/hdp/current/hbase-client/bin/../lib/paranamer-2.3.jar:/usr/hdp/current/hbase-client/bin/../lib/protobuf-java-2.5.0.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-hbase-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5-6.1.14.jar:/usr/hdp/current/hbase-client/bin/../lib/servlet-api-2.5.jar:/usr/hdp/current/hbase-client/bin/../lib/slf4j-api-1.6.4.jar:/usr/hdp/current/hbase-client/bin/../lib/snappy-java-1.0.4.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xercesImpl-2.9.1.jar:/usr/hdp/current/hbase-client/bin/../lib/xml-apis-1.3.04.jar:/usr/hdp/current/hbase-client/bin/../lib/xmlenc-0.52.jar:/usr/hdp/current/hbase-client/bin/../lib/xz-1.0.jar:/usr/hdp/current/hbase-client/bin/../lib/zookeeper.jar:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/.//hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/./:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xercesImpl-2.9.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/commons-daemon-1.0.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xml-apis-1.3.04.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop-hdfs/.//hadoop-hdfs-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-client-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-distributedshell-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-resourcemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-web-proxy-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-applicationhistoryservice.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-registry-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-tests-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-api-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-server-nodemanager-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-yarn/.//hadoop-yarn-client.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/aopalliance-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/leveldbjni-all-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-guice-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/guice-servlet-3.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/javax.inject-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-sls.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//metrics-core-3.0.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//joda-time-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//aws-java-sdk-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-annotations-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-databind-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-datajoin.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-distcp.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-ant.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-streaming.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-rumen.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-shuffle.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/.//hadoop-openstack.jar::/usr/share/java/mysql-connector-java-5.1.17.jar:/usr/share/java/mysql-connector-java.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-io-2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/mockito-all-1.8.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-impl-2.2.3-1.jar:/usr/hdp/current/hadoop-mapreduce-client/activation-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-logging-1.1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-compress-1.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-collections-3.2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/gson-2.2.4.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-core-1.8.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-sls.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-beanutils-1.7.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-asn1-api-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-configuration-1.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-codec-1.4.jar:/usr/hdp/current/hadoop-mapreduce-client/jettison-1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/metrics-core-3.0.1.jar:/usr/hdp/current/hadoop-mapreduce-client/servlet-api-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-cli-1.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-gridmix-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-compiler-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/joda-time-2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/log4j-1.2.17.jar:/usr/hdp/current/hadoop-mapreduce-client/aws-java-sdk-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jasper-runtime-5.5.23.jar:/usr/hdp/current/hadoop-mapreduce-client/snappy-java-1.0.4.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jsp-api-2.1.jar:/usr/hdp/current/hadoop-mapreduce-client/stax-api-1.0-2.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-server-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-el-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-math3-3.1.1.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-httpclient-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-json-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-recipes-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-lang-2.6.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-client-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-digester-1.8.jar:/usr/hdp/current/hadoop-mapreduce-client/curator-framework-2.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-aws-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/junit-4.11.jar:/usr/hdp/current/hadoop-mapreduce-client/jaxb-api-2.2.2.jar:/usr/hdp/current/hadoop-mapreduce-client/zookeeper-3.4.6.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-annotations-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/commons-net-3.1.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-mapper-asl-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/jsch-0.1.42.jar:/usr/hdp/current/hadoop-mapreduce-client/netty-3.6.2.Final.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-jaxrs-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-app-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-databind-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xz-1.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-datajoin.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-distcp.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-ant.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar:/usr/hdp/current/hadoop-mapreduce-client/httpcore-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jets3t-0.9.0.jar:/usr/hdp/current/hadoop-mapreduce-client/asm-3.2.jar:/usr/hdp/current/hadoop-mapreduce-client/paranamer-2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/jersey-core-1.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-extras-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-core-2.2.3.jar:/usr/hdp/current/hadoop-mapreduce-client/protobuf-java-2.5.0.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/avro-1.7.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/current/hadoop-mapreduce-client/java-xmlbuilder-0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-rumen.jar:/usr/hdp/current/hadoop-mapreduce-client/httpclient-4.2.5.jar:/usr/hdp/current/hadoop-mapreduce-client/jsr305-1.3.9.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-examples-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/api-util-1.0.0-M20.jar:/usr/hdp/current/hadoop-mapreduce-client/jackson-xc-1.9.13.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/guava-11.0.2.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-archives-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-shuffle.jar:/usr/hdp/current/hadoop-mapreduce-client/jetty-util-6.1.26.hwx.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-hs-plugins-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/htrace-core-3.0.4.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/hadoop-mapreduce-client/hamcrest-core-1.3.jar:/usr/hdp/current/hadoop-mapreduce-client/xmlenc-0.52.jar:/usr/hdp/current/hadoop-mapreduce-client/hadoop-openstack.jar:/usr/hdp/current/tez-client/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/commons-io-2.4.jar:/usr/hdp/current/tez-client/lib/commons-collections4-4.0.jar:/usr/hdp/current/tez-client/lib/commons-logging-1.1.3.jar:/usr/hdp/current/tez-client/lib/commons-collections-3.2.1.jar:/usr/hdp/current/tez-client/lib/commons-codec-1.4.jar:/usr/hdp/current/tez-client/lib/commons-cli-1.2.jar:/usr/hdp/current/tez-client/lib/log4j-1.2.17.jar:/usr/hdp/current/tez-client/lib/jettison-1.3.4.jar:/usr/hdp/current/tez-client/lib/commons-math3-3.1.1.jar:/usr/hdp/current/tez-client/lib/commons-lang-2.6.jar:/usr/hdp/current/tez-client/lib/jsr305-2.0.3.jar:/usr/hdp/current/tez-client/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/protobuf-java-2.5.0.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/current/tez-client/lib/guava-11.0.2.jar:/usr/hdp/current/tez-client/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf/:/usr/hdp/2.2.0.0-2041/tez/tez-tests-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-yarn-timeline-history-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-api-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-dag-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-internals-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-common-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mbeans-resource-calculator-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-runtime-library-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-mapreduce-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/tez-examples-0.5.2.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections4-4.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jettison-1.3.4.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/tez/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/tez/lib/jsr305-2.0.3.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/tez/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/tez/lib/hadoop-mapreduce-client-core-2.6.0.2.2.0.0-2041.jar:/etc/tez/conf:/usr/hdp/2.2.0.0-2041/hadoop/conf:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-annotations-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-nfs-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-auth-2.6.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common.jar:/usr/hdp/2.2.0.0-2041/hadoop/hadoop-common-2.6.0.2.2.0.0-2041-tests.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-io-2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mockito-all-1.8.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-impl-2.2.3-1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/activation-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/eclipselink-2.5.2-M1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-logging-1.1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-compress-1.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-collections-3.2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/gson-2.2.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-core-1.8.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-beanutils-1.7.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-asn1-api-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-configuration-1.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-codec-1.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jettison-1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/servlet-api-2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-cli-1.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-compiler-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/log4j-1.2.17.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jasper-runtime-5.5.23.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/snappy-java-1.0.4.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsp-api-2.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/stax-api-1.0-2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-server-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-el-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-math3-3.1.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-httpclient-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-json-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-cred-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ojdbc6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-recipes-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-lang-2.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-client-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-digester-1.8.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/curator-framework-2.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-common-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/junit-4.11.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-hdfs-plugin-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jaxb-api-2.2.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/zookeeper-3.4.6.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/commons-net-3.1.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-mapper-asl-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsch-0.1.42.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/netty-3.6.2.Final.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-jaxrs-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xz-1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-audit-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/mysql-connector-java.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpcore-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jets3t-0.9.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/asm-3.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/paranamer-2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jersey-core-1.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-core-2.2.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/protobuf-java-2.5.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/avro-1.7.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/java-xmlbuilder-0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-api-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/ranger-plugins-impl-0.4.0.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/javax.persistence-2.1.0.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/httpclient-4.2.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jsr305-1.3.9.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/apacheds-i18n-2.0.0-M15.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/api-util-1.0.0-M20.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jackson-xc-1.9.13.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/guava-11.0.2.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/jetty-util-6.1.26.hwx.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/slf4j-log4j12-1.7.5.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/htrace-core-3.0.4.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/hamcrest-core-1.3.jar:/usr/hdp/2.2.0.0-2041/hadoop/lib/xmlenc-0.52.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper-3.4.6.2.2.0.0-2041.jar:/usr/hdp/2.2.0.0-2041/zookeeper/zookeeper.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-interpolation-1.11.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-io-2.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-log4j12-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jsoup-1.7.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/slf4j-api-1.6.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-logging-1.1.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-profile-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-lightweight-1.0-beta-6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-settings-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-launcher-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-ant-tasks-2.1.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/commons-codec-1.6.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-error-diagnostics-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/log4j-1.2.16.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/ant-1.8.0.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-utils-3.0.8.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-http-shared4-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-provider-api-2.4.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/backport-util-concurrent-3.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/netty-3.7.0.Final.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/jline-0.9.94.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpcore-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/nekohtml-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-model-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-repository-metadata-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-plugin-registry-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/plexus-container-default-1.0-alpha-9-stable-1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-artifact-manager-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/classworlds-1.1-alpha-2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/httpclient-4.2.3.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/maven-project-2.2.1.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/xercesMinimal-1.9.6.2.jar:/usr/hdp/2.2.0.0-2041/zookeeper/lib/wagon-file-1.0-beta-6.jar:
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=:/usr/hdp/2.2.0.0-2041/hadoop/lib/native/Linux-amd64-64:/usr/hdp/2.2.0.0-2041/hadoop/lib/native
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=2.6.32-504.3.3.el6.x86_64
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=hbase
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/home/hbase
2016-01-17 17:53:21,960 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/home/hbase
2016-01-17 17:53:21,965 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=master:60000, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-17 17:53:22,040 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:60000 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-17 17:53:22,049 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-17 17:53:22,068 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-17 17:53:22,124 INFO  [main-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x15250a3fca40006, negotiated timeout = 30000
2016-01-17 17:53:22,163 INFO  [main] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure already exists and this is not a retry
2016-01-17 17:53:22,229 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
2016-01-17 17:53:22,240 INFO  [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: starting
2016-01-17 17:53:22,301 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39392; # active connections: 1
2016-01-17 17:53:22,307 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39392 because read count=-1. Number of active connections: 1
2016-01-17 17:53:22,557 INFO  [master:sandbox:60000] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2016-01-17 17:53:23,174 INFO  [master:sandbox:60000] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
2016-01-17 17:53:23,184 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
2016-01-17 17:53:23,184 INFO  [master:sandbox:60000] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2016-01-17 17:53:23,245 INFO  [master:sandbox:60000] http.HttpServer: Jetty bound to port 60010
2016-01-17 17:53:23,245 INFO  [master:sandbox:60000] mortbay.log: jetty-6.1.26
2016-01-17 17:53:24,640 INFO  [master:sandbox:60000] mortbay.log: Started HttpServer$SelectChannelConnectorWithSafeStartup@0.0.0.0:60010
2016-01-17 17:53:24,980 DEBUG [main-EventThread] master.ActiveMasterManager: A master is now available
2016-01-17 17:53:24,987 INFO  [master:sandbox:60000] master.ActiveMasterManager: Registered Active Master=sandbox.hortonworks.com,60000,1453053198477
2016-01-17 17:53:25,029 INFO  [master:sandbox:60000] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-01-17 17:53:26,318 DEBUG [master:sandbox:60000] hbase.HRegionInfo: 1588230740
2016-01-17 17:53:26,533 INFO  [master:sandbox:60000] Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
2016-01-17 17:53:27,065 DEBUG [master:sandbox:60000] util.FSTableDescriptors: Current tableInfoPath = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/data/hbase/meta/.tabledesc/.tableinfo.0000000001
2016-01-17 17:53:27,145 DEBUG [master:sandbox:60000] util.FSTableDescriptors: TableInfo already exists.. Skipping creation
2016-01-17 17:53:27,509 INFO  [master:sandbox:60000] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
2016-01-17 17:53:27,529 DEBUG [master:sandbox:60000] master.SplitLogManager: Distributed log replay=false, hfile.format.version=2
2016-01-17 17:53:27,545 INFO  [master:sandbox:60000] master.SplitLogManager: Timeout=120000, unassigned timeout=180000, distributedLogReplay=false
2016-01-17 17:53:27,551 INFO  [master:sandbox:60000] master.SplitLogManager: Found 0 orphan tasks and 0 rescan nodes
2016-01-17 17:53:28,153 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=hconnection-0x6e2bf880, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-17 17:53:28,159 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6e2bf880 connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-17 17:53:28,158 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-17 17:53:28,195 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-17 17:53:28,260 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x15250a3fca40007, negotiated timeout = 30000
2016-01-17 17:53:28,288 DEBUG [master:sandbox:60000] ipc.RpcClient: Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@2fa45d6, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
2016-01-17 17:53:28,331 DEBUG [master:sandbox:60000] catalog.CatalogTracker: Starting catalog tracker org.apache.hadoop.hbase.catalog.CatalogTracker@1ef30741
2016-01-17 17:53:28,507 INFO  [master:sandbox:60000] master.HMaster: Server active/primary master=sandbox.hortonworks.com,60000,1453053198477, sessionid=0x15250a3fca40006, setting cluster-up flag (Was=true)
2016-01-17 17:53:28,619 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/online-snapshot/acquired already exists and this is not a retry
2016-01-17 17:53:28,622 INFO  [master:sandbox:60000] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase-unsecure/online-snapshot/acquired /hbase-unsecure/online-snapshot/reached /hbase-unsecure/online-snapshot/abort
2016-01-17 17:53:28,626 DEBUG [master:sandbox:60000] procedure.ZKProcedureCoordinatorRpcs: Starting the controller for procedure member:sandbox.hortonworks.com,60000,1453053198477
2016-01-17 17:53:28,890 INFO  [master:sandbox:60000] config.PolicyRefresher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval: 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2016-01-17 17:53:28,905 INFO  [master:sandbox:60000] config.ConfigWatcher: Creating PolicyRefreshser with url: http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase, refreshInterval(milliSeconds): 5000, sslConfigFileName: /etc/hbase/conf/xasecure-policymgr-ssl.xml, lastStoredFileName: /etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2016-01-17 17:53:31,725 INFO  [master:sandbox:60000] config.ConfigWatcher: URL: [http://sandbox.hortonworks.com:6080/service/assets/policyList/sandbox_hbase], isModified: true, lastModifiedTime:1419866686000
2016-01-17 17:53:31,779 INFO  [master:sandbox:60000] hbase.HBaseAccessControllerFactory: Created a new instance of class: [com.xasecure.pdp.hbase.XASecureAuthorizer] for HBase Access verification.
2016-01-17 17:53:32,097 DEBUG [master:sandbox:60000] master.HMaster: Registered master coprocessor service: service=AccessControlService
2016-01-17 17:53:32,137 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: creating..
2016-01-17 17:53:32,139 INFO  [master:sandbox:60000] provider.AuditProviderFactory: AuditProviderFactory: initializing..
2016-01-17 17:53:32,159 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: creating..
2016-01-17 17:53:32,168 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-17 17:53:32,168 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider): creating..
2016-01-17 17:53:32,168 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.DbAuditProvider)
2016-01-17 17:53:32,178 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-17 17:53:32,178 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider): creating..
2016-01-17 17:53:32,181 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.hdfs.HdfsAuditProvider)
2016-01-17 17:53:32,182 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider: creating..
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.addAuditProvider(providerType=com.xasecure.audit.provider.AsyncAuditProvider)
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(DbAuditProvider).init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.init()
2016-01-17 17:53:32,185 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-17 17:53:32,479 INFO  [master:sandbox:60000] provider.AsyncAuditProvider: AsyncAuditProvider(HdfsAuditProvider).init()
2016-01-17 17:53:32,479 INFO  [master:sandbox:60000] provider.MultiDestAuditProvider: MultiDestAuditProvider.init()
2016-01-17 17:53:32,479 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-17 17:53:32,479 INFO  [master:sandbox:60000] hdfs.HdfsAuditProvider: HdfsAuditProvider.init()
2016-01-17 17:53:32,480 INFO  [master:sandbox:60000] provider.BaseAuditProvider: BaseAuditProvider.init()
2016-01-17 17:53:32,510 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider.start()
2016-01-17 17:53:32,510 INFO  [master:sandbox:60000] provider.DbAuditProvider: DbAuditProvider: init()
2016-01-17 17:53:32,512 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2016-01-17 17:53:37,093 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: ==> AsyncAuditProvider.run()
2016-01-17 17:53:37,093 INFO  [master:sandbox:60000] hbase.XaSecureAuthorizationCoprocessor: Start() - Adding Super User(hbase)
2016-01-17 17:53:37,094 INFO  [master:sandbox:60000] coprocessor.CoprocessorHost: System coprocessor com.xasecure.authorization.hbase.XaSecureAuthorizationCoprocessor was loaded successfully with priority (536870911).
2016-01-17 17:53:37,113 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_OPEN_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-17 17:53:37,113 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_CLOSE_REGION-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-17 17:53:37,113 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-17 17:53:37,114 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_META_SERVER_OPERATIONS-sandbox:60000, corePoolSize=5, maxPoolSize=5
2016-01-17 17:53:37,114 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=M_LOG_REPLAY_OPS-sandbox:60000, corePoolSize=10, maxPoolSize=10
2016-01-17 17:53:37,114 DEBUG [master:sandbox:60000] executor.ExecutorService: Starting executor service name=MASTER_TABLE_OPERATIONS-sandbox:60000, corePoolSize=1, maxPoolSize=1
2016-01-17 17:53:37,180 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner
2016-01-17 17:53:37,213 INFO  [master:sandbox:60000] zookeeper.ZooKeeper: Initiating client connection, connectString=sandbox.hortonworks.com:2181 sessionTimeout=30000 watcher=replicationLogCleaner, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure
2016-01-17 17:53:37,232 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=sandbox.hortonworks.com:2181
2016-01-17 17:53:37,263 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Opening socket connection to server sandbox.hortonworks.com/10.0.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2016-01-17 17:53:37,264 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Socket connection established to sandbox.hortonworks.com/10.0.0.4:2181, initiating session
2016-01-17 17:53:37,293 INFO  [master:sandbox:60000-SendThread(sandbox.hortonworks.com:2181)] zookeeper.ClientCnxn: Session establishment complete on server sandbox.hortonworks.com/10.0.0.4:2181, sessionid = 0x15250a3fca40008, negotiated timeout = 30000
2016-01-17 17:53:37,419 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/replication/rs already exists and this is not a retry
2016-01-17 17:53:37,419 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.replication.master.ReplicationLogCleaner
2016-01-17 17:53:37,447 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotLogCleaner
2016-01-17 17:53:37,471 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.HFileLinkCleaner
2016-01-17 17:53:37,490 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.snapshot.SnapshotHFileCleaner
2016-01-17 17:53:37,491 DEBUG [master:sandbox:60000] cleaner.CleanerChore: initialize cleaner=org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner
2016-01-17 17:53:37,499 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:37,546 INFO  [DestinationDispatcherThread-1453053217093] hdfs.HdfsAuditProvider: HdfsLogDestination.openFile(): opening file for write hdfs://sandbox.hortonworks.com:8020/ranger/audit/hbaseMaster/20160117/sandbox.hortonworks.com-audit.log
2016-01-17 17:53:39,038 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1539 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:40,542 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 3043 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:42,074 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 4575 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:43,611 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 6112 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:45,160 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 7661 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:46,688 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 9189 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:48,206 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 10706 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:49,747 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 12248 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:50,292 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39532; # active connections: 1
2016-01-17 17:53:50,292 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39532 because read count=-1. Number of active connections: 1
2016-01-17 17:53:51,274 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 13774 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:52,810 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 15311 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:54,341 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 16842 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:54,918 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56966; # active connections: 1
2016-01-17 17:53:55,109 INFO  [FifoRpcScheduler.handler1-thread-1] master.ServerManager: Registering server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:53:55,117 INFO  [master:sandbox:60000] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 17617 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
2016-01-17 17:53:55,117 INFO  [FifoRpcScheduler.handler1-thread-1] Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
2016-01-17 17:53:55,208 DEBUG [main-EventThread] zookeeper.RegionServerTracker: RS node: /hbase-unsecure/rs/sandbox.hortonworks.com,60020,1453053229927 data: PBUF
2016-01-17 17:53:56,619 INFO  [master:sandbox:60000] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 19119 ms, expecting minimum of 1, maximum of 2147483647, master is running.
2016-01-17 17:53:56,627 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923 doesn't belong to a known region server, splitting
2016-01-17 17:53:56,627 INFO  [master:sandbox:60000] master.MasterFileSystem: Log folder hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1453053229927 belongs to an existing region server
2016-01-17 17:53:56,707 DEBUG [master:sandbox:60000] master.MasterFileSystem: Renamed region directory: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting
2016-01-17 17:53:56,707 INFO  [master:sandbox:60000] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1452976657923]
2016-01-17 17:53:56,718 DEBUG [master:sandbox:60000] master.SplitLogManager: Scheduling batch of logs to split
2016-01-17 17:53:56,720 INFO  [master:sandbox:60000] master.SplitLogManager: started splitting 1 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting]
2016-01-17 17:53:56,779 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta
2016-01-17 17:53:56,787 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta ver = 0
2016-01-17 17:53:57,172 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta acquired by sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:53:57,606 INFO  [sandbox.hortonworks.com,60000,1453053198477.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta=last_update = 1453053237403 last_version = 2 cur_worker_name = sandbox.hortonworks.com,60020,1453053229927 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2016-01-17 17:54:02,373 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta entered state: DONE sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:02,465 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting/sandbox.hortonworks.com%2C60020%2C1452976657923.1452980272207.meta to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/oldWALs/sandbox.hortonworks.com%2C60020%2C1452976657923.1452980272207.meta
2016-01-17 17:54:02,469 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta
2016-01-17 17:54:02,498 WARN  [master:sandbox:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting
2016-01-17 17:54:02,499 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980272207.meta
2016-01-17 17:54:02,502 INFO  [master:sandbox:60000] master.SplitLogManager: finished splitting (more than or equal to) 83 bytes in 1 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting] in 5778ms
2016-01-17 17:54:02,640 DEBUG [master:sandbox:60000] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 17:54:02,650 DEBUG [master:sandbox:60000] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 17:54:02,735 INFO  [master:sandbox:60000] catalog.CatalogTracker: Failed verification of hbase:meta,,1 at address=sandbox.hortonworks.com,60020,1452976657923, exception=org.apache.hadoop.hbase.NotServingRegionException: org.apache.hadoop.hbase.NotServingRegionException: Region hbase:meta,,1 is not online on sandbox.hortonworks.com,60020,1453053229927
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionByEncodedName(HRegionServer.java:2774)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegion(HRegionServer.java:4257)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.getRegionInfo(HRegionServer.java:3599)
	at org.apache.hadoop.hbase.protobuf.generated.AdminProtos$AdminService$2.callBlockingMethod(AdminProtos.java:20370)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:114)
	at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:94)
	at java.lang.Thread.run(Thread.java:745)

2016-01-17 17:54:02,764 INFO  [master:sandbox:60000] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1452976657923]
2016-01-17 17:54:02,773 INFO  [master:sandbox:60000] master.SplitLogManager: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting is empty dir, no logs to split
2016-01-17 17:54:02,773 DEBUG [master:sandbox:60000] master.SplitLogManager: Scheduling batch of logs to split
2016-01-17 17:54:02,773 INFO  [master:sandbox:60000] master.SplitLogManager: started splitting 0 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting]
2016-01-17 17:54:02,790 WARN  [master:sandbox:60000] master.SplitLogManager: returning success without actually splitting and deleting all the log files in path hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting
2016-01-17 17:54:02,790 INFO  [master:sandbox:60000] master.SplitLogManager: finished splitting (more than or equal to) 0 bytes in 0 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting] in 17ms
2016-01-17 17:54:02,790 INFO  [master:sandbox:60000] zookeeper.ZooKeeperNodeTracker: Unsetting hbase:meta region location in ZooKeeper
2016-01-17 17:54:02,918 DEBUG [master:sandbox:60000] master.AssignmentManager: No previous transition plan found (or ignoring an existing plan) for hbase:meta,,1.1588230740; generated random plan=hri=hbase:meta,,1.1588230740, src=, dest=sandbox.hortonworks.com,60020,1453053229927; 1 (online=1, available=1) available servers, forceNewPlan=false
2016-01-17 17:54:02,918 DEBUG [master:sandbox:60000] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating (or updating) unassigned node 1588230740 with OFFLINE state
2016-01-17 17:54:03,010 INFO  [master:sandbox:60000] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:03,010 INFO  [master:sandbox:60000] master.RegionStates: Transitioned {1588230740 state=OFFLINE, ts=1453053242918, server=null} to {1588230740 state=PENDING_OPEN, ts=1453053243010, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:03,010 DEBUG [master:sandbox:60000] master.ServerManager: New admin connection to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:04,180 INFO  [master:sandbox:60000] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
2016-01-17 17:54:04,322 DEBUG [AM.ZK.Worker-pool2-t1] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=1588230740, current_state={1588230740 state=PENDING_OPEN, ts=1453053243010, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:04,323 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transitioned {1588230740 state=PENDING_OPEN, ts=1453053243010, server=sandbox.hortonworks.com,60020,1453053229927} to {1588230740 state=OPENING, ts=1453053244323, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:14,287 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=1588230740, current_state={1588230740 state=OPENING, ts=1453053244323, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:14,287 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {1588230740 state=OPENING, ts=1453053244323, server=sandbox.hortonworks.com,60020,1453053229927} to {1588230740 state=OPEN, ts=1453053254287, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:14,296 INFO  [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of 1588230740 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:14,357 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 1588230740 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:14,367 DEBUG [AM.ZK.Worker-pool2-t3] master.AssignmentManager: Znode hbase:meta,,1.1588230740 deleted, state: {1588230740 state=OPEN, ts=1453053254287, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:14,368 INFO  [AM.ZK.Worker-pool2-t3] master.RegionStates: Onlined 1588230740 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:14,375 INFO  [master:sandbox:60000] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:14,529 DEBUG [htable-pool3-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 17:54:14,537 DEBUG [htable-pool3-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 17:54:14,811 INFO  [master:sandbox:60000] catalog.MetaMigrationConvertingToPB: META already up-to date with PB serialization
2016-01-17 17:54:14,939 INFO  [master:sandbox:60000] master.AssignmentManager: Found regions out on cluster or in RIT; presuming failover
2016-01-17 17:54:15,033 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Splitting logs for sandbox.hortonworks.com,60020,1452976657923 before assignment.
2016-01-17 17:54:15,071 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: dead splitlog workers [sandbox.hortonworks.com,60020,1452976657923]
2016-01-17 17:54:15,082 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: Scheduling batch of logs to split
2016-01-17 17:54:15,082 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: started splitting 1 logs in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting]
2016-01-17 17:54:15,199 DEBUG [main-EventThread] master.SplitLogManager: put up splitlog task at znode /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241
2016-01-17 17:54:15,201 DEBUG [main-EventThread] master.SplitLogManager: task not yet acquired /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241 ver = 0
2016-01-17 17:54:15,235 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241 acquired by sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:15,655 INFO  [sandbox.hortonworks.com,60000,1453053198477.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241=last_update = 1453053255489 last_version = 2 cur_worker_name = sandbox.hortonworks.com,60020,1453053229927 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2016-01-17 17:54:20,292 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39675; # active connections: 2
2016-01-17 17:54:20,293 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39675 because read count=-1. Number of active connections: 2
2016-01-17 17:54:20,663 INFO  [sandbox.hortonworks.com,60000,1453053198477.splitLogManagerTimeoutMonitor] master.SplitLogManager: total tasks = 1 unassigned = 0 tasks={/hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241=last_update = 1453053255489 last_version = 2 cur_worker_name = sandbox.hortonworks.com,60020,1453053229927 status = in_progress incarnation = 0 resubmits = 0 batch = installed = 1 done = 0 error = 0}
2016-01-17 17:54:22,251 INFO  [main-EventThread] master.SplitLogManager: task /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241 entered state: DONE sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:22,327 DEBUG [main-EventThread] wal.HLogSplitter: Archived processed log hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting/sandbox.hortonworks.com%2C60020%2C1452976657923.1452980268241 to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/oldWALs/sandbox.hortonworks.com%2C60020%2C1452976657923.1452980268241
2016-01-17 17:54:22,334 INFO  [main-EventThread] master.SplitLogManager: Done splitting /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241
2016-01-17 17:54:22,356 DEBUG [main-EventThread] master.SplitLogManager$DeleteAsyncCallback: deleted /hbase-unsecure/splitWAL/WALs%2Fsandbox.hortonworks.com%2C60020%2C1452976657923-splitting%2Fsandbox.hortonworks.com%252C60020%252C1452976657923.1452980268241
2016-01-17 17:54:22,387 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.SplitLogManager: finished splitting (more than or equal to) 83 bytes in 1 log files in [hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/WALs/sandbox.hortonworks.com,60020,1452976657923-splitting] in 7305ms
2016-01-17 17:54:22,389 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Reassigning 6 region(s) that sandbox.hortonworks.com,60020,1452976657923 was carrying (and 0 regions(s) that were opening on this server)
2016-01-17 17:54:23,114 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 6 region(s) to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,118 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node a1abc6352f6e6010b61cd89061575d15 with OFFLINE state
2016-01-17 17:54:23,119 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 61a91320bb285054243d16e6dedd4a76 with OFFLINE state
2016-01-17 17:54:23,120 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 3b4c25a80758728ef4f550bbd330f05b with OFFLINE state
2016-01-17 17:54:23,121 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 with OFFLINE state
2016-01-17 17:54:23,122 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node bf93a1f8a3cdac77590e5033ba6ae70f with OFFLINE state
2016-01-17 17:54:23,123 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node db8d9fe8d0471c86ef90518de99b1581 with OFFLINE state
2016-01-17 17:54:23,154 DEBUG [main-EventThread] master.OfflineCallback: rs={a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1453053254934, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,184 DEBUG [main-EventThread] master.OfflineCallback: rs={61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1453053254933, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,184 DEBUG [main-EventThread] master.OfflineCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1453053254924, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,184 DEBUG [main-EventThread] master.OfflineCallback: rs={9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1453053254932, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,185 DEBUG [main-EventThread] master.OfflineCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1453053254930, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,185 DEBUG [main-EventThread] master.OfflineCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1453053254925, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,186 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1453053254934, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,186 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1453053254933, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,186 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=2 of total=6
2016-01-17 17:54:23,186 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1453053254924, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,186 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1453053254932, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,187 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1453053254930, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,187 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1453053254925, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,192 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=6 of total=6
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1453053263118, server=null} to {a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=OFFLINE, ts=1453053263119, server=null} to {61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OFFLINE, ts=1453053263120, server=null} to {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1453053263121, server=null} to {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OFFLINE, ts=1453053263122, server=null} to {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,193 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OFFLINE, ts=1453053263123, server=null} to {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,265 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=a1abc6352f6e6010b61cd89061575d15, current_state={a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,362 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=61a91320bb285054243d16e6dedd4a76, current_state={61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,406 DEBUG [AM.ZK.Worker-pool2-t7] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,487 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:54:23,487 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,487 DEBUG [MASTER_SERVER_OPERATIONS-sandbox:60000-0] master.DeadServer: Finished processing sandbox.hortonworks.com,60020,1452976657923
2016-01-17 17:54:23,487 INFO  [MASTER_SERVER_OPERATIONS-sandbox:60000-0] handler.ServerShutdownHandler: Finished processing of shutdown of sandbox.hortonworks.com,60020,1452976657923
2016-01-17 17:54:23,487 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,488 INFO  [AM.ZK.Worker-pool2-t7] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1453053263488, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,937 DEBUG [AM.ZK.Worker-pool2-t8] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=61a91320bb285054243d16e6dedd4a76, current_state={61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,937 INFO  [AM.ZK.Worker-pool2-t8] master.RegionStates: Transitioned {61a91320bb285054243d16e6dedd4a76 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927} to {61a91320bb285054243d16e6dedd4a76 state=OPEN, ts=1453053263937, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,939 DEBUG [AM.ZK.Worker-pool2-t9] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=3b4c25a80758728ef4f550bbd330f05b, current_state={3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1453053263488, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,940 INFO  [AM.ZK.Worker-pool2-t9] master.RegionStates: Transitioned {3b4c25a80758728ef4f550bbd330f05b state=OPENING, ts=1453053263488, server=sandbox.hortonworks.com,60020,1453053229927} to {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1453053263939, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:23,940 DEBUG [AM.ZK.Worker-pool2-t9] handler.OpenedRegionHandler: Handling OPENED of 3b4c25a80758728ef4f550bbd330f05b from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:23,937 DEBUG [AM.ZK.Worker-pool2-t8] handler.OpenedRegionHandler: Handling OPENED of 61a91320bb285054243d16e6dedd4a76 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:24,016 DEBUG [AM.ZK.Worker-pool2-t8] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 61a91320bb285054243d16e6dedd4a76 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,018 DEBUG [AM.ZK.Worker-pool2-t9] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 3b4c25a80758728ef4f550bbd330f05b in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,018 DEBUG [AM.ZK.Worker-pool2-t10] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=9b0335280e0a412ba7e69b46f0cf2a77, current_state={9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,018 INFO  [AM.ZK.Worker-pool2-t10] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1453053264018, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,023 DEBUG [AM.ZK.Worker-pool2-t12] master.AssignmentManager: Znode tester,,1452982525007.61a91320bb285054243d16e6dedd4a76. deleted, state: {61a91320bb285054243d16e6dedd4a76 state=OPEN, ts=1453053263937, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,024 INFO  [AM.ZK.Worker-pool2-t12] master.RegionStates: Onlined 61a91320bb285054243d16e6dedd4a76 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 61a91320bb285054243d16e6dedd4a76, NAME => 'tester,,1452982525007.61a91320bb285054243d16e6dedd4a76.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,028 DEBUG [AM.ZK.Worker-pool2-t13] master.AssignmentManager: Znode hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b. deleted, state: {3b4c25a80758728ef4f550bbd330f05b state=OPEN, ts=1453053263939, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,028 INFO  [AM.ZK.Worker-pool2-t13] master.RegionStates: Onlined 3b4c25a80758728ef4f550bbd330f05b on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 3b4c25a80758728ef4f550bbd330f05b, NAME => 'hbase:acl,,1419866651429.3b4c25a80758728ef4f550bbd330f05b.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,060 DEBUG [AM.ZK.Worker-pool2-t14] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,061 INFO  [AM.ZK.Worker-pool2-t14] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1453053264061, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,262 DEBUG [AM.ZK.Worker-pool2-t15] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=a1abc6352f6e6010b61cd89061575d15, current_state={a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,263 INFO  [AM.ZK.Worker-pool2-t15] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=OPENING, ts=1453053263487, server=sandbox.hortonworks.com,60020,1453053229927} to {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1453053264263, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,263 DEBUG [AM.ZK.Worker-pool2-t16] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,263 DEBUG [AM.ZK.Worker-pool2-t15] handler.OpenedRegionHandler: Handling OPENED of a1abc6352f6e6010b61cd89061575d15 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:24,263 INFO  [AM.ZK.Worker-pool2-t16] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=PENDING_OPEN, ts=1453053263193, server=sandbox.hortonworks.com,60020,1453053229927} to {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1453053264263, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,295 DEBUG [AM.ZK.Worker-pool2-t15] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node a1abc6352f6e6010b61cd89061575d15 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,297 DEBUG [AM.ZK.Worker-pool2-t18] master.AssignmentManager: Znode tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15. deleted, state: {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1453053264263, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,298 INFO  [AM.ZK.Worker-pool2-t18] master.RegionStates: Onlined a1abc6352f6e6010b61cd89061575d15 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => a1abc6352f6e6010b61cd89061575d15, NAME => 'tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,452 DEBUG [AM.ZK.Worker-pool2-t19] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=9b0335280e0a412ba7e69b46f0cf2a77, current_state={9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1453053264018, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,452 INFO  [AM.ZK.Worker-pool2-t19] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=OPENING, ts=1453053264018, server=sandbox.hortonworks.com,60020,1453053229927} to {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1453053264452, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,452 DEBUG [AM.ZK.Worker-pool2-t19] handler.OpenedRegionHandler: Handling OPENED of 9b0335280e0a412ba7e69b46f0cf2a77 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:24,496 DEBUG [AM.ZK.Worker-pool2-t19] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,497 DEBUG [AM.ZK.Worker-pool2-t19] master.AssignmentManager: Znode stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77. deleted, state: {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1453053264452, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,497 INFO  [AM.ZK.Worker-pool2-t19] master.RegionStates: Onlined 9b0335280e0a412ba7e69b46f0cf2a77 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 9b0335280e0a412ba7e69b46f0cf2a77, NAME => 'stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,576 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=db8d9fe8d0471c86ef90518de99b1581, current_state={db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1453053264263, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,576 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transitioned {db8d9fe8d0471c86ef90518de99b1581 state=OPENING, ts=1453053264263, server=sandbox.hortonworks.com,60020,1453053229927} to {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1453053264576, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,576 DEBUG [AM.ZK.Worker-pool2-t2] handler.OpenedRegionHandler: Handling OPENED of db8d9fe8d0471c86ef90518de99b1581 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:24,605 DEBUG [AM.ZK.Worker-pool2-t2] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node db8d9fe8d0471c86ef90518de99b1581 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,605 DEBUG [AM.ZK.Worker-pool2-t2] master.AssignmentManager: Znode hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581. deleted, state: {db8d9fe8d0471c86ef90518de99b1581 state=OPEN, ts=1453053264576, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,605 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Onlined db8d9fe8d0471c86ef90518de99b1581 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => db8d9fe8d0471c86ef90518de99b1581, NAME => 'hbase:namespace,,1419863731224.db8d9fe8d0471c86ef90518de99b1581.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,640 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node default with data: \x0A\x07default
2016-01-17 17:54:24,642 DEBUG [AM.ZK.Worker-pool2-t5] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=bf93a1f8a3cdac77590e5033ba6ae70f, current_state={bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1453053264061, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,642 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transitioned {bf93a1f8a3cdac77590e5033ba6ae70f state=OPENING, ts=1453053264061, server=sandbox.hortonworks.com,60020,1453053229927} to {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1453053264642, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,642 DEBUG [AM.ZK.Worker-pool2-t5] handler.OpenedRegionHandler: Handling OPENED of bf93a1f8a3cdac77590e5033ba6ae70f from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:54:24,644 DEBUG [master:sandbox:60000] hbase.ZKNamespaceManager: Updating namespace cache from node hbase with data: \x0A\x05hbase
2016-01-17 17:54:24,671 DEBUG [AM.ZK.Worker-pool2-t5] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node bf93a1f8a3cdac77590e5033ba6ae70f in expected state RS_ZK_REGION_OPENED
2016-01-17 17:54:24,674 DEBUG [AM.ZK.Worker-pool2-t6] master.AssignmentManager: Znode iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f. deleted, state: {bf93a1f8a3cdac77590e5033ba6ae70f state=OPEN, ts=1453053264642, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:54:24,674 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Onlined bf93a1f8a3cdac77590e5033ba6ae70f on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => bf93a1f8a3cdac77590e5033ba6ae70f, NAME => 'iemployee,,1419866921107.bf93a1f8a3cdac77590e5033ba6ae70f.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:54:24,918 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/default already exists and this is not a retry
2016-01-17 17:54:24,982 INFO  [master:sandbox:60000] zookeeper.RecoverableZooKeeper: Node /hbase-unsecure/namespace/hbase already exists and this is not a retry
2016-01-17 17:54:24,997 INFO  [master:sandbox:60000] master.HMaster: Master has completed initialization
2016-01-17 17:54:25,024 INFO  [master:sandbox:60000] master.HMaster: Client=null/null create 'hbase:acl', {NAME => 'l', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'NONE', VERSIONS => '10', TTL => 'FOREVER', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '8192', IN_MEMORY => 'true', BLOCKCACHE => 'true'}
2016-01-17 17:54:25,266 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000003
2016-01-17 17:54:25,309 DEBUG [master:sandbox:60000] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/hbase:acl/write-master:600000000000003
2016-01-17 17:54:50,292 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39819; # active connections: 2
2016-01-17 17:54:50,292 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39819 because read count=-1. Number of active connections: 2
2016-01-17 17:55:20,203 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39956; # active connections: 2
2016-01-17 17:55:20,204 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39956 because read count=-1. Number of active connections: 2
2016-01-17 17:55:47,117 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40092; # active connections: 2
2016-01-17 17:55:50,299 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40114; # active connections: 3
2016-01-17 17:55:50,300 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40114 because read count=-1. Number of active connections: 3
2016-01-17 17:56:20,290 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40248; # active connections: 3
2016-01-17 17:56:20,290 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40248 because read count=-1. Number of active connections: 3
2016-01-17 17:56:44,252 INFO  [FifoRpcScheduler.handler1-thread-7] master.HMaster: Client=thenson//10.0.0.4 create 'user', {NAME => 'device', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'username', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-17 17:56:44,358 DEBUG [FifoRpcScheduler.handler1-thread-7] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000000
2016-01-17 17:56:44,360 DEBUG [htable-pool11-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 17:56:44,361 DEBUG [htable-pool11-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 17:56:44,419 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table user
2016-01-17 17:56:44,747 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/.tabledesc/.tableinfo.0000000001
2016-01-17 17:56:44,763 INFO  [RegionOpenAndInitThread-user-1] regionserver.HRegion: creating HRegion user HTD == 'user', {NAME => 'device', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}, {NAME => 'username', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == user
2016-01-17 17:56:45,152 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Instantiated user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.
2016-01-17 17:56:45,152 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Closing user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.: disabling compactions & flushes
2016-01-17 17:56:45,152 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Updates disabled for region user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.
2016-01-17 17:56:45,152 INFO  [RegionOpenAndInitThread-user-1] regionserver.HRegion: Closed user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.
2016-01-17 17:56:45,834 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-17 17:56:45,860 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:56:45,861 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 06e754c1f1a04f880566e57589e6fd23 with OFFLINE state
2016-01-17 17:56:45,997 DEBUG [main-EventThread] master.OfflineCallback: rs={06e754c1f1a04f880566e57589e6fd23 state=OFFLINE, ts=1453053405835, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:56:45,999 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={06e754c1f1a04f880566e57589e6fd23 state=OFFLINE, ts=1453053405835, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:56:46,001 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=1 of total=1
2016-01-17 17:56:46,001 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {06e754c1f1a04f880566e57589e6fd23 state=OFFLINE, ts=1453053405861, server=null} to {06e754c1f1a04f880566e57589e6fd23 state=PENDING_OPEN, ts=1453053406001, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,001 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 17:56:46,002 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 17:56:46,022 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1453053229927
2016-01-17 17:56:46,060 DEBUG [AM.ZK.Worker-pool2-t22] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=06e754c1f1a04f880566e57589e6fd23, current_state={06e754c1f1a04f880566e57589e6fd23 state=PENDING_OPEN, ts=1453053406001, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,060 INFO  [AM.ZK.Worker-pool2-t22] master.RegionStates: Transitioned {06e754c1f1a04f880566e57589e6fd23 state=PENDING_OPEN, ts=1453053406001, server=sandbox.hortonworks.com,60020,1453053229927} to {06e754c1f1a04f880566e57589e6fd23 state=OPENING, ts=1453053406060, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,075 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000000
2016-01-17 17:56:46,075 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, user, creation successful
2016-01-17 17:56:46,233 DEBUG [AM.ZK.Worker-pool2-t23] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=06e754c1f1a04f880566e57589e6fd23, current_state={06e754c1f1a04f880566e57589e6fd23 state=OPENING, ts=1453053406060, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,233 INFO  [AM.ZK.Worker-pool2-t23] master.RegionStates: Transitioned {06e754c1f1a04f880566e57589e6fd23 state=OPENING, ts=1453053406060, server=sandbox.hortonworks.com,60020,1453053229927} to {06e754c1f1a04f880566e57589e6fd23 state=OPEN, ts=1453053406233, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,233 DEBUG [AM.ZK.Worker-pool2-t23] handler.OpenedRegionHandler: Handling OPENED of 06e754c1f1a04f880566e57589e6fd23 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 17:56:46,265 DEBUG [AM.ZK.Worker-pool2-t23] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 06e754c1f1a04f880566e57589e6fd23 in expected state RS_ZK_REGION_OPENED
2016-01-17 17:56:46,266 DEBUG [AM.ZK.Worker-pool2-t25] master.AssignmentManager: Znode user,,1453053404248.06e754c1f1a04f880566e57589e6fd23. deleted, state: {06e754c1f1a04f880566e57589e6fd23 state=OPEN, ts=1453053406233, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 17:56:46,266 INFO  [AM.ZK.Worker-pool2-t25] master.RegionStates: Onlined 06e754c1f1a04f880566e57589e6fd23 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 06e754c1f1a04f880566e57589e6fd23, NAME => 'user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.', STARTKEY => '', ENDKEY => ''}
2016-01-17 17:56:50,297 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40396; # active connections: 3
2016-01-17 17:56:50,298 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40396 because read count=-1. Number of active connections: 3
2016-01-17 17:57:20,087 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40537; # active connections: 3
2016-01-17 17:57:20,087 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40537 because read count=-1. Number of active connections: 3
2016-01-17 17:57:32,176 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 17:57:32,176 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2016-01-17 17:57:32,186 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 17:57:32,186 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=1, outLogs=1, dropped=0
2016-01-17 17:57:50,082 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40677; # active connections: 3
2016-01-17 17:57:50,082 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40677 because read count=-1. Number of active connections: 3
2016-01-17 17:58:20,093 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40814; # active connections: 3
2016-01-17 17:58:20,094 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40814 because read count=-1. Number of active connections: 3
2016-01-17 17:58:44,647 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40092 because read count=-1. Number of active connections: 2
2016-01-17 17:58:50,105 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40962; # active connections: 2
2016-01-17 17:58:50,106 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40962 because read count=-1. Number of active connections: 2
2016-01-17 17:59:15,003 DEBUG [htable-pool13-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 17:59:15,003 DEBUG [htable-pool13-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 17:59:15,006 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 17:59:20,131 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41092; # active connections: 2
2016-01-17 17:59:20,132 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41092 because read count=-1. Number of active connections: 2
2016-01-17 17:59:50,104 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41240; # active connections: 2
2016-01-17 17:59:50,104 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41240 because read count=-1. Number of active connections: 2
2016-01-17 18:00:20,176 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41378; # active connections: 2
2016-01-17 18:00:20,176 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41378 because read count=-1. Number of active connections: 2
2016-01-17 18:00:50,174 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41538; # active connections: 2
2016-01-17 18:00:50,175 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41538 because read count=-1. Number of active connections: 2
2016-01-17 18:01:07,519 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41607; # active connections: 2
2016-01-17 18:01:20,265 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41670; # active connections: 3
2016-01-17 18:01:20,265 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41670 because read count=-1. Number of active connections: 3
2016-01-17 18:01:50,258 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41809; # active connections: 3
2016-01-17 18:01:50,258 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41809 because read count=-1. Number of active connections: 3
2016-01-17 18:02:08,123 INFO  [FifoRpcScheduler.handler1-thread-59] master.HMaster: Client=thenson//10.0.0.4 create 'user', {NAME => 'username', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-17 18:02:08,162 DEBUG [FifoRpcScheduler.handler1-thread-59] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000001
2016-01-17 18:02:08,168 DEBUG [htable-pool14-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:02:08,168 DEBUG [htable-pool14-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:02:08,237 DEBUG [FifoRpcScheduler.handler1-thread-59] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000001
2016-01-17 18:02:08,238 DEBUG [FifoRpcScheduler.handler1-thread-59] ipc.RpcServer: FifoRpcScheduler.handler1-thread-59: callId: 3 service: MasterService methodName: CreateTable size: 307 connection: 10.0.0.4:41607
org.apache.hadoop.hbase.TableExistsException: user
	at org.apache.hadoop.hbase.master.handler.CreateTableHandler.prepare(CreateTableHandler.java:124)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1790)
	at org.apache.hadoop.hbase.master.HMaster.createTable(HMaster.java:1911)
	at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:40470)
	at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2078)
	at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:108)
	at org.apache.hadoop.hbase.ipc.FifoRpcScheduler$1.run(FifoRpcScheduler.java:74)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
2016-01-17 18:02:20,252 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41952; # active connections: 3
2016-01-17 18:02:20,253 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41952 because read count=-1. Number of active connections: 3
2016-01-17 18:02:32,854 INFO  [FifoRpcScheduler.handler1-thread-9] master.HMaster: Client=thenson//10.0.0.4 disable user
2016-01-17 18:02:32,879 DEBUG [FifoRpcScheduler.handler1-thread-9] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000002
2016-01-17 18:02:32,924 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table user
2016-01-17 18:02:32,952 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-17 18:02:32,956 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of user,,1453053404248.06e754c1f1a04f880566e57589e6fd23. (offlining), current state: {06e754c1f1a04f880566e57589e6fd23 state=OPEN, ts=1453053406266, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:02:32,956 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 06e754c1f1a04f880566e57589e6fd23 in a CLOSING state
2016-01-17 18:02:33,017 INFO  [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {06e754c1f1a04f880566e57589e6fd23 state=OPEN, ts=1453053406266, server=sandbox.hortonworks.com,60020,1453053229927} to {06e754c1f1a04f880566e57589e6fd23 state=PENDING_CLOSE, ts=1453053753017, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:02:33,027 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 18:02:33,027 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:02:33,043 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1453053229927 for region user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.
2016-01-17 18:02:33,217 DEBUG [AM.ZK.Worker-pool2-t27] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1453053229927, region=06e754c1f1a04f880566e57589e6fd23, current_state={06e754c1f1a04f880566e57589e6fd23 state=PENDING_CLOSE, ts=1453053753017, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:02:33,219 DEBUG [AM.ZK.Worker-pool2-t27] handler.ClosedRegionHandler: Handling CLOSED event for 06e754c1f1a04f880566e57589e6fd23
2016-01-17 18:02:33,219 DEBUG [AM.ZK.Worker-pool2-t27] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.
2016-01-17 18:02:33,249 DEBUG [AM.ZK.Worker-pool2-t27] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 06e754c1f1a04f880566e57589e6fd23 in expected state RS_ZK_REGION_CLOSED
2016-01-17 18:02:33,250 DEBUG [AM.ZK.Worker-pool2-t27] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 06e754c1f1a04f880566e57589e6fd23, NAME => 'user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.', STARTKEY => '', ENDKEY => ''}
2016-01-17 18:02:33,250 INFO  [AM.ZK.Worker-pool2-t27] master.RegionStates: Transitioned {06e754c1f1a04f880566e57589e6fd23 state=PENDING_CLOSE, ts=1453053753017, server=sandbox.hortonworks.com,60020,1453053229927} to {06e754c1f1a04f880566e57589e6fd23 state=OFFLINE, ts=1453053753250, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:02:33,250 INFO  [AM.ZK.Worker-pool2-t27] master.RegionStates: Offlined 06e754c1f1a04f880566e57589e6fd23 from sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:02:33,959 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-17 18:02:34,062 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, user, is done=true
2016-01-17 18:02:34,098 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000002
2016-01-17 18:02:38,439 INFO  [FifoRpcScheduler.handler1-thread-13] master.HMaster: Client=thenson//10.0.0.4 delete user
2016-01-17 18:02:38,472 DEBUG [FifoRpcScheduler.handler1-thread-13] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000003
2016-01-17 18:02:38,508 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table user
2016-01-17 18:02:38,540 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-17 18:02:38,748 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 06e754c1f1a04f880566e57589e6fd23, NAME => 'user,,1453053404248.06e754c1f1a04f880566e57589e6fd23.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 18:02:38,781 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region user,,1453053404248.06e754c1f1a04f880566e57589e6fd23. from FS
2016-01-17 18:02:38,786 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23
2016-01-17 18:02:38,835 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23/device, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23/recovered.edits, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23/username]
2016-01-17 18:02:39,171 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23/recovered.edits/4_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/user/06e754c1f1a04f880566e57589e6fd23/recovered.edits/4_seqid
2016-01-17 18:02:39,219 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/06e754c1f1a04f880566e57589e6fd23
2016-01-17 18:02:39,256 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'user' from region states.
2016-01-17 18:02:39,256 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'user' as deleted.
2016-01-17 18:02:39,296 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000003
2016-01-17 18:02:41,900 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41607 because read count=-1. Number of active connections: 2
2016-01-17 18:02:50,270 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42103; # active connections: 2
2016-01-17 18:02:50,271 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42103 because read count=-1. Number of active connections: 2
2016-01-17 18:03:20,085 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42230; # active connections: 2
2016-01-17 18:03:20,086 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42230 because read count=-1. Number of active connections: 2
2016-01-17 18:03:32,188 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.003 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-17 18:03:32,188 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=6, outLogs=6, dropped=0
2016-01-17 18:03:32,201 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.004 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-17 18:03:32,201 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=6, outLogs=6, dropped=0
2016-01-17 18:03:50,127 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42380; # active connections: 2
2016-01-17 18:03:50,127 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42380 because read count=-1. Number of active connections: 2
2016-01-17 18:03:55,983 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42397; # active connections: 2
2016-01-17 18:04:15,004 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:04:20,139 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42517; # active connections: 3
2016-01-17 18:04:20,139 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42517 because read count=-1. Number of active connections: 3
2016-01-17 18:04:37,482 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1452976657923.1452980268241
2016-01-17 18:04:37,523 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1452976657923.1452980272207.meta
2016-01-17 18:04:38,633 INFO  [FifoRpcScheduler.handler1-thread-3] master.HMaster: Client=thenson//10.0.0.4 create 'user', {NAME => 'username', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-17 18:04:38,728 DEBUG [FifoRpcScheduler.handler1-thread-3] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000000
2016-01-17 18:04:38,802 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table user
2016-01-17 18:04:39,100 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/.tabledesc/.tableinfo.0000000001
2016-01-17 18:04:39,122 INFO  [RegionOpenAndInitThread-user-1] regionserver.HRegion: creating HRegion user HTD == 'user', {NAME => 'username', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == user
2016-01-17 18:04:39,272 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Instantiated user,,1453053878625.63dd123fba2f611d9352d28f81a93599.
2016-01-17 18:04:39,272 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Closing user,,1453053878625.63dd123fba2f611d9352d28f81a93599.: disabling compactions & flushes
2016-01-17 18:04:39,272 DEBUG [RegionOpenAndInitThread-user-1] regionserver.HRegion: Updates disabled for region user,,1453053878625.63dd123fba2f611d9352d28f81a93599.
2016-01-17 18:04:39,272 INFO  [RegionOpenAndInitThread-user-1] regionserver.HRegion: Closed user,,1453053878625.63dd123fba2f611d9352d28f81a93599.
2016-01-17 18:04:39,327 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-17 18:04:39,366 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:04:39,366 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 63dd123fba2f611d9352d28f81a93599 with OFFLINE state
2016-01-17 18:04:39,398 DEBUG [main-EventThread] master.OfflineCallback: rs={63dd123fba2f611d9352d28f81a93599 state=OFFLINE, ts=1453053879331, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:04:39,400 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={63dd123fba2f611d9352d28f81a93599 state=OFFLINE, ts=1453053879331, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:04:39,404 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=1 of total=1
2016-01-17 18:04:39,404 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {63dd123fba2f611d9352d28f81a93599 state=OFFLINE, ts=1453053879366, server=null} to {63dd123fba2f611d9352d28f81a93599 state=PENDING_OPEN, ts=1453053879404, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,404 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 18:04:39,405 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:04:39,459 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:04:39,521 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000000
2016-01-17 18:04:39,521 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, user, creation successful
2016-01-17 18:04:39,537 DEBUG [AM.ZK.Worker-pool2-t31] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=63dd123fba2f611d9352d28f81a93599, current_state={63dd123fba2f611d9352d28f81a93599 state=PENDING_OPEN, ts=1453053879404, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,537 INFO  [AM.ZK.Worker-pool2-t31] master.RegionStates: Transitioned {63dd123fba2f611d9352d28f81a93599 state=PENDING_OPEN, ts=1453053879404, server=sandbox.hortonworks.com,60020,1453053229927} to {63dd123fba2f611d9352d28f81a93599 state=OPENING, ts=1453053879537, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,724 DEBUG [AM.ZK.Worker-pool2-t32] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=63dd123fba2f611d9352d28f81a93599, current_state={63dd123fba2f611d9352d28f81a93599 state=OPENING, ts=1453053879537, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,725 INFO  [AM.ZK.Worker-pool2-t32] master.RegionStates: Transitioned {63dd123fba2f611d9352d28f81a93599 state=OPENING, ts=1453053879537, server=sandbox.hortonworks.com,60020,1453053229927} to {63dd123fba2f611d9352d28f81a93599 state=OPEN, ts=1453053879725, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,725 DEBUG [AM.ZK.Worker-pool2-t32] handler.OpenedRegionHandler: Handling OPENED of 63dd123fba2f611d9352d28f81a93599 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 18:04:39,754 DEBUG [AM.ZK.Worker-pool2-t32] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 63dd123fba2f611d9352d28f81a93599 in expected state RS_ZK_REGION_OPENED
2016-01-17 18:04:39,755 DEBUG [AM.ZK.Worker-pool2-t34] master.AssignmentManager: Znode user,,1453053878625.63dd123fba2f611d9352d28f81a93599. deleted, state: {63dd123fba2f611d9352d28f81a93599 state=OPEN, ts=1453053879725, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:04:39,755 INFO  [AM.ZK.Worker-pool2-t34] master.RegionStates: Onlined 63dd123fba2f611d9352d28f81a93599 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 63dd123fba2f611d9352d28f81a93599, NAME => 'user,,1453053878625.63dd123fba2f611d9352d28f81a93599.', STARTKEY => '', ENDKEY => ''}
2016-01-17 18:04:50,130 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42666; # active connections: 3
2016-01-17 18:04:50,131 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42666 because read count=-1. Number of active connections: 3
2016-01-17 18:05:20,172 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42806; # active connections: 3
2016-01-17 18:05:20,173 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42806 because read count=-1. Number of active connections: 3
2016-01-17 18:05:32,195 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.004 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 18:05:32,195 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=7, outLogs=7, dropped=0
2016-01-17 18:05:32,205 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 18:05:32,205 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=7, outLogs=7, dropped=0
2016-01-17 18:05:50,173 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:42948; # active connections: 3
2016-01-17 18:05:50,174 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42948 because read count=-1. Number of active connections: 3
2016-01-17 18:06:20,180 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43082; # active connections: 3
2016-01-17 18:06:20,180 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43082 because read count=-1. Number of active connections: 3
2016-01-17 18:06:39,047 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:42397 because read count=-1. Number of active connections: 2
2016-01-17 18:06:50,193 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43235; # active connections: 2
2016-01-17 18:06:50,193 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43235 because read count=-1. Number of active connections: 2
2016-01-17 18:07:20,183 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43369; # active connections: 2
2016-01-17 18:07:20,183 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43369 because read count=-1. Number of active connections: 2
2016-01-17 18:07:50,174 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43510; # active connections: 2
2016-01-17 18:07:50,174 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43510 because read count=-1. Number of active connections: 2
2016-01-17 18:08:20,186 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43648; # active connections: 2
2016-01-17 18:08:20,187 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43648 because read count=-1. Number of active connections: 2
2016-01-17 18:08:23,691 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43659; # active connections: 2
2016-01-17 18:08:23,706 INFO  [FifoRpcScheduler.handler1-thread-20] master.HMaster: Client=thenson//10.0.0.4 disable user
2016-01-17 18:08:23,734 DEBUG [FifoRpcScheduler.handler1-thread-20] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000001
2016-01-17 18:08:23,737 DEBUG [htable-pool22-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:08:23,737 DEBUG [htable-pool22-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:08:23,779 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table user
2016-01-17 18:08:23,834 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-17 18:08:23,837 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of user,,1453053878625.63dd123fba2f611d9352d28f81a93599. (offlining), current state: {63dd123fba2f611d9352d28f81a93599 state=OPEN, ts=1453053879755, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:08:23,837 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 63dd123fba2f611d9352d28f81a93599 in a CLOSING state
2016-01-17 18:08:23,875 INFO  [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {63dd123fba2f611d9352d28f81a93599 state=OPEN, ts=1453053879755, server=sandbox.hortonworks.com,60020,1453053229927} to {63dd123fba2f611d9352d28f81a93599 state=PENDING_CLOSE, ts=1453054103875, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:08:23,875 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 18:08:23,876 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:08:23,880 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1453053229927 for region user,,1453053878625.63dd123fba2f611d9352d28f81a93599.
2016-01-17 18:08:24,267 DEBUG [AM.ZK.Worker-pool2-t36] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1453053229927, region=63dd123fba2f611d9352d28f81a93599, current_state={63dd123fba2f611d9352d28f81a93599 state=PENDING_CLOSE, ts=1453054103875, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:08:24,268 DEBUG [AM.ZK.Worker-pool2-t36] handler.ClosedRegionHandler: Handling CLOSED event for 63dd123fba2f611d9352d28f81a93599
2016-01-17 18:08:24,268 DEBUG [AM.ZK.Worker-pool2-t36] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region user,,1453053878625.63dd123fba2f611d9352d28f81a93599.
2016-01-17 18:08:24,295 DEBUG [AM.ZK.Worker-pool2-t36] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 63dd123fba2f611d9352d28f81a93599 in expected state RS_ZK_REGION_CLOSED
2016-01-17 18:08:24,295 DEBUG [AM.ZK.Worker-pool2-t36] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 63dd123fba2f611d9352d28f81a93599, NAME => 'user,,1453053878625.63dd123fba2f611d9352d28f81a93599.', STARTKEY => '', ENDKEY => ''}
2016-01-17 18:08:24,295 INFO  [AM.ZK.Worker-pool2-t36] master.RegionStates: Transitioned {63dd123fba2f611d9352d28f81a93599 state=PENDING_CLOSE, ts=1453054103875, server=sandbox.hortonworks.com,60020,1453053229927} to {63dd123fba2f611d9352d28f81a93599 state=OFFLINE, ts=1453054104295, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:08:24,295 INFO  [AM.ZK.Worker-pool2-t36] master.RegionStates: Offlined 63dd123fba2f611d9352d28f81a93599 from sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:08:24,838 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-17 18:08:24,857 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, user, is done=true
2016-01-17 18:08:24,888 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000001
2016-01-17 18:08:30,358 INFO  [FifoRpcScheduler.handler1-thread-24] master.HMaster: Client=thenson//10.0.0.4 delete user
2016-01-17 18:08:30,376 DEBUG [FifoRpcScheduler.handler1-thread-24] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/user/write-master:600000000000002
2016-01-17 18:08:30,395 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table user
2016-01-17 18:08:30,413 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-17 18:08:30,447 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 63dd123fba2f611d9352d28f81a93599, NAME => 'user,,1453053878625.63dd123fba2f611d9352d28f81a93599.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 18:08:30,500 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region user,,1453053878625.63dd123fba2f611d9352d28f81a93599. from FS
2016-01-17 18:08:30,500 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599
2016-01-17 18:08:30,518 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599/recovered.edits, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599/username]
2016-01-17 18:08:30,640 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599/recovered.edits/9_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/user/63dd123fba2f611d9352d28f81a93599/recovered.edits/9_seqid
2016-01-17 18:08:30,734 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599/username/ba13965d0ee74a0e88c335fcb12bf52c, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/user/63dd123fba2f611d9352d28f81a93599/username/ba13965d0ee74a0e88c335fcb12bf52c
2016-01-17 18:08:30,766 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/user/63dd123fba2f611d9352d28f81a93599
2016-01-17 18:08:30,802 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'user' from region states.
2016-01-17 18:08:30,802 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'user' as deleted.
2016-01-17 18:08:30,860 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/user/write-master:600000000000002
2016-01-17 18:08:32,211 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=4, outLogs=4, dropped=0, currentQueueSize=0
2016-01-17 18:08:32,211 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=11, outLogs=11, dropped=0
2016-01-17 18:08:50,192 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43803; # active connections: 3
2016-01-17 18:08:50,192 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43803 because read count=-1. Number of active connections: 3
2016-01-17 18:08:53,874 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:21.676 minutes: inLogs=4, outLogs=4, dropped=0, currentQueueSize=0
2016-01-17 18:08:53,874 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=11, outLogs=11, dropped=0
2016-01-17 18:09:15,007 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:09:20,179 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:43935; # active connections: 3
2016-01-17 18:09:20,180 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43935 because read count=-1. Number of active connections: 3
2016-01-17 18:09:50,299 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44085; # active connections: 3
2016-01-17 18:09:50,306 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44085 because read count=-1. Number of active connections: 3
2016-01-17 18:10:20,191 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44213; # active connections: 3
2016-01-17 18:10:20,192 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44213 because read count=-1. Number of active connections: 3
2016-01-17 18:10:48,963 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:43659 because read count=-1. Number of active connections: 2
2016-01-17 18:10:50,176 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44356; # active connections: 2
2016-01-17 18:10:50,176 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44356 because read count=-1. Number of active connections: 2
2016-01-17 18:11:20,185 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44498; # active connections: 2
2016-01-17 18:11:20,186 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44498 because read count=-1. Number of active connections: 2
2016-01-17 18:11:50,173 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44639; # active connections: 2
2016-01-17 18:11:50,173 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44639 because read count=-1. Number of active connections: 2
2016-01-17 18:12:20,187 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44775; # active connections: 2
2016-01-17 18:12:20,187 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44775 because read count=-1. Number of active connections: 2
2016-01-17 18:12:50,145 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:44922; # active connections: 2
2016-01-17 18:12:50,146 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:44922 because read count=-1. Number of active connections: 2
2016-01-17 18:13:20,185 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45054; # active connections: 2
2016-01-17 18:13:20,185 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45054 because read count=-1. Number of active connections: 2
2016-01-17 18:13:50,164 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45205; # active connections: 2
2016-01-17 18:13:50,164 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45205 because read count=-1. Number of active connections: 2
2016-01-17 18:14:15,008 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:14:15,009 DEBUG [htable-pool27-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:14:15,009 DEBUG [htable-pool27-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:14:20,163 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45338; # active connections: 2
2016-01-17 18:14:20,163 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45338 because read count=-1. Number of active connections: 2
2016-01-17 18:14:50,154 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45480; # active connections: 2
2016-01-17 18:14:50,154 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45480 because read count=-1. Number of active connections: 2
2016-01-17 18:15:20,188 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45624; # active connections: 2
2016-01-17 18:15:20,188 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45624 because read count=-1. Number of active connections: 2
2016-01-17 18:15:50,148 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45762; # active connections: 2
2016-01-17 18:15:50,148 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45762 because read count=-1. Number of active connections: 2
2016-01-17 18:16:20,149 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:45897; # active connections: 2
2016-01-17 18:16:20,151 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:45897 because read count=-1. Number of active connections: 2
2016-01-17 18:16:50,123 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46045; # active connections: 2
2016-01-17 18:16:50,123 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46045 because read count=-1. Number of active connections: 2
2016-01-17 18:17:20,129 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46176; # active connections: 2
2016-01-17 18:17:20,130 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46176 because read count=-1. Number of active connections: 2
2016-01-17 18:17:50,115 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46320; # active connections: 2
2016-01-17 18:17:50,115 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46320 because read count=-1. Number of active connections: 2
2016-01-17 18:18:20,085 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46459; # active connections: 2
2016-01-17 18:18:20,086 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46459 because read count=-1. Number of active connections: 2
2016-01-17 18:18:50,074 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46606; # active connections: 2
2016-01-17 18:18:50,085 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46606 because read count=-1. Number of active connections: 2
2016-01-17 18:19:15,012 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:19:15,012 DEBUG [htable-pool28-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:19:15,013 DEBUG [htable-pool28-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:19:20,119 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46746; # active connections: 2
2016-01-17 18:19:20,120 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46746 because read count=-1. Number of active connections: 2
2016-01-17 18:19:50,096 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:46892; # active connections: 2
2016-01-17 18:19:50,097 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:46892 because read count=-1. Number of active connections: 2
2016-01-17 18:20:20,092 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47034; # active connections: 2
2016-01-17 18:20:20,092 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47034 because read count=-1. Number of active connections: 2
2016-01-17 18:20:50,565 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47184; # active connections: 2
2016-01-17 18:20:50,565 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47184 because read count=-1. Number of active connections: 2
2016-01-17 18:21:20,059 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47317; # active connections: 2
2016-01-17 18:21:20,059 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47317 because read count=-1. Number of active connections: 2
2016-01-17 18:21:50,288 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47461; # active connections: 2
2016-01-17 18:21:50,288 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47461 because read count=-1. Number of active connections: 2
2016-01-17 18:22:20,268 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47603; # active connections: 2
2016-01-17 18:22:20,268 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47603 because read count=-1. Number of active connections: 2
2016-01-17 18:22:50,233 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47745; # active connections: 2
2016-01-17 18:22:50,233 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47745 because read count=-1. Number of active connections: 2
2016-01-17 18:23:20,223 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:47875; # active connections: 2
2016-01-17 18:23:20,224 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:47875 because read count=-1. Number of active connections: 2
2016-01-17 18:23:50,236 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48030; # active connections: 2
2016-01-17 18:23:50,236 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48030 because read count=-1. Number of active connections: 2
2016-01-17 18:24:15,014 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:24:15,017 DEBUG [htable-pool29-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:24:15,018 DEBUG [htable-pool29-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:24:20,225 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48165; # active connections: 2
2016-01-17 18:24:20,226 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48165 because read count=-1. Number of active connections: 2
2016-01-17 18:24:50,246 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48316; # active connections: 2
2016-01-17 18:24:50,247 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48316 because read count=-1. Number of active connections: 2
2016-01-17 18:25:20,260 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48453; # active connections: 2
2016-01-17 18:25:20,261 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48453 because read count=-1. Number of active connections: 2
2016-01-17 18:25:50,210 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48600; # active connections: 2
2016-01-17 18:25:50,210 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48600 because read count=-1. Number of active connections: 2
2016-01-17 18:26:20,207 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48733; # active connections: 2
2016-01-17 18:26:20,208 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48733 because read count=-1. Number of active connections: 2
2016-01-17 18:26:50,194 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:48879; # active connections: 2
2016-01-17 18:26:50,194 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:48879 because read count=-1. Number of active connections: 2
2016-01-17 18:27:20,185 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49015; # active connections: 2
2016-01-17 18:27:20,186 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49015 because read count=-1. Number of active connections: 2
2016-01-17 18:27:50,180 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49158; # active connections: 2
2016-01-17 18:27:50,180 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49158 because read count=-1. Number of active connections: 2
2016-01-17 18:28:20,171 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49299; # active connections: 2
2016-01-17 18:28:20,171 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49299 because read count=-1. Number of active connections: 2
2016-01-17 18:28:50,159 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49443; # active connections: 2
2016-01-17 18:28:50,159 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49443 because read count=-1. Number of active connections: 2
2016-01-17 18:29:15,016 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:29:15,016 DEBUG [htable-pool30-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:29:15,016 DEBUG [htable-pool30-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:29:20,161 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49573; # active connections: 2
2016-01-17 18:29:20,161 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49573 because read count=-1. Number of active connections: 2
2016-01-17 18:29:50,173 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49719; # active connections: 2
2016-01-17 18:29:50,173 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49719 because read count=-1. Number of active connections: 2
2016-01-17 18:30:20,177 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:49853; # active connections: 2
2016-01-17 18:30:20,178 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:49853 because read count=-1. Number of active connections: 2
2016-01-17 18:30:50,168 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50007; # active connections: 2
2016-01-17 18:30:50,168 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50007 because read count=-1. Number of active connections: 2
2016-01-17 18:31:20,181 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50140; # active connections: 2
2016-01-17 18:31:20,181 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50140 because read count=-1. Number of active connections: 2
2016-01-17 18:31:50,169 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50279; # active connections: 2
2016-01-17 18:31:50,169 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50279 because read count=-1. Number of active connections: 2
2016-01-17 18:32:20,169 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50421; # active connections: 2
2016-01-17 18:32:20,169 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50421 because read count=-1. Number of active connections: 2
2016-01-17 18:32:50,183 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50559; # active connections: 2
2016-01-17 18:32:50,183 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50559 because read count=-1. Number of active connections: 2
2016-01-17 18:33:20,195 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50694; # active connections: 2
2016-01-17 18:33:20,195 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50694 because read count=-1. Number of active connections: 2
2016-01-17 18:33:50,212 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50850; # active connections: 2
2016-01-17 18:33:50,212 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50850 because read count=-1. Number of active connections: 2
2016-01-17 18:34:15,017 DEBUG [htable-pool31-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:34:15,018 DEBUG [htable-pool31-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:34:15,018 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:34:20,111 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:50983; # active connections: 2
2016-01-17 18:34:20,111 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:50983 because read count=-1. Number of active connections: 2
2016-01-17 18:34:50,100 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51123; # active connections: 2
2016-01-17 18:34:50,100 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51123 because read count=-1. Number of active connections: 2
2016-01-17 18:35:20,122 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51265; # active connections: 2
2016-01-17 18:35:20,122 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51265 because read count=-1. Number of active connections: 2
2016-01-17 18:35:50,116 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51408; # active connections: 2
2016-01-17 18:35:50,116 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51408 because read count=-1. Number of active connections: 2
2016-01-17 18:36:20,112 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51539; # active connections: 2
2016-01-17 18:36:20,112 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51539 because read count=-1. Number of active connections: 2
2016-01-17 18:36:50,087 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51690; # active connections: 2
2016-01-17 18:36:50,087 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51690 because read count=-1. Number of active connections: 2
2016-01-17 18:37:20,089 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51824; # active connections: 2
2016-01-17 18:37:20,090 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51824 because read count=-1. Number of active connections: 2
2016-01-17 18:37:50,079 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:51963; # active connections: 2
2016-01-17 18:37:50,080 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:51963 because read count=-1. Number of active connections: 2
2016-01-17 18:38:20,097 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52106; # active connections: 2
2016-01-17 18:38:20,097 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52106 because read count=-1. Number of active connections: 2
2016-01-17 18:38:50,303 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52241; # active connections: 2
2016-01-17 18:38:50,303 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52241 because read count=-1. Number of active connections: 2
2016-01-17 18:39:15,019 DEBUG [htable-pool32-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:39:15,019 DEBUG [htable-pool32-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:39:15,019 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:39:20,289 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52376; # active connections: 2
2016-01-17 18:39:20,289 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52376 because read count=-1. Number of active connections: 2
2016-01-17 18:39:50,262 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52521; # active connections: 2
2016-01-17 18:39:50,265 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52521 because read count=-1. Number of active connections: 2
2016-01-17 18:40:20,284 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52655; # active connections: 2
2016-01-17 18:40:20,285 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52655 because read count=-1. Number of active connections: 2
2016-01-17 18:40:50,242 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52798; # active connections: 2
2016-01-17 18:40:50,242 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52798 because read count=-1. Number of active connections: 2
2016-01-17 18:41:20,227 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:52941; # active connections: 2
2016-01-17 18:41:20,228 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:52941 because read count=-1. Number of active connections: 2
2016-01-17 18:41:50,230 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53085; # active connections: 2
2016-01-17 18:41:50,231 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53085 because read count=-1. Number of active connections: 2
2016-01-17 18:42:20,227 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53218; # active connections: 2
2016-01-17 18:42:20,228 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53218 because read count=-1. Number of active connections: 2
2016-01-17 18:42:50,202 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53369; # active connections: 2
2016-01-17 18:42:50,203 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53369 because read count=-1. Number of active connections: 2
2016-01-17 18:43:20,289 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53500; # active connections: 2
2016-01-17 18:43:20,290 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53500 because read count=-1. Number of active connections: 2
2016-01-17 18:43:50,293 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53644; # active connections: 2
2016-01-17 18:43:50,293 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53644 because read count=-1. Number of active connections: 2
2016-01-17 18:44:15,020 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:44:15,021 DEBUG [htable-pool33-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:44:15,021 DEBUG [htable-pool33-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:44:20,073 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53786; # active connections: 2
2016-01-17 18:44:20,074 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53786 because read count=-1. Number of active connections: 2
2016-01-17 18:44:50,187 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:53930; # active connections: 2
2016-01-17 18:44:50,188 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:53930 because read count=-1. Number of active connections: 2
2016-01-17 18:45:20,214 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54067; # active connections: 2
2016-01-17 18:45:20,215 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54067 because read count=-1. Number of active connections: 2
2016-01-17 18:45:50,203 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54217; # active connections: 2
2016-01-17 18:45:50,203 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54217 because read count=-1. Number of active connections: 2
2016-01-17 18:46:20,212 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54354; # active connections: 2
2016-01-17 18:46:20,212 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54354 because read count=-1. Number of active connections: 2
2016-01-17 18:46:50,213 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54496; # active connections: 2
2016-01-17 18:46:50,213 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54496 because read count=-1. Number of active connections: 2
2016-01-17 18:47:20,225 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54633; # active connections: 2
2016-01-17 18:47:20,225 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54633 because read count=-1. Number of active connections: 2
2016-01-17 18:47:50,215 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54775; # active connections: 2
2016-01-17 18:47:50,215 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54775 because read count=-1. Number of active connections: 2
2016-01-17 18:48:20,197 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:54904; # active connections: 2
2016-01-17 18:48:20,197 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:54904 because read count=-1. Number of active connections: 2
2016-01-17 18:48:50,212 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55058; # active connections: 2
2016-01-17 18:48:50,212 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55058 because read count=-1. Number of active connections: 2
2016-01-17 18:49:15,021 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:49:15,022 DEBUG [htable-pool34-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:49:15,022 DEBUG [htable-pool34-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:49:20,229 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55191; # active connections: 2
2016-01-17 18:49:20,229 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55191 because read count=-1. Number of active connections: 2
2016-01-17 18:49:50,263 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55331; # active connections: 2
2016-01-17 18:49:50,263 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55331 because read count=-1. Number of active connections: 2
2016-01-17 18:50:20,272 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55478; # active connections: 2
2016-01-17 18:50:20,275 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55478 because read count=-1. Number of active connections: 2
2016-01-17 18:50:50,079 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55623; # active connections: 2
2016-01-17 18:50:50,080 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55623 because read count=-1. Number of active connections: 2
2016-01-17 18:51:20,271 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55764; # active connections: 2
2016-01-17 18:51:20,271 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55764 because read count=-1. Number of active connections: 2
2016-01-17 18:51:50,285 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:55905; # active connections: 2
2016-01-17 18:51:50,285 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:55905 because read count=-1. Number of active connections: 2
2016-01-17 18:52:20,289 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56037; # active connections: 2
2016-01-17 18:52:20,289 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56037 because read count=-1. Number of active connections: 2
2016-01-17 18:52:50,261 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56181; # active connections: 2
2016-01-17 18:52:50,262 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56181 because read count=-1. Number of active connections: 2
2016-01-17 18:53:20,268 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56314; # active connections: 2
2016-01-17 18:53:20,269 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56314 because read count=-1. Number of active connections: 2
2016-01-17 18:53:50,255 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56458; # active connections: 2
2016-01-17 18:53:50,255 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56458 because read count=-1. Number of active connections: 2
2016-01-17 18:54:15,025 DEBUG [htable-pool35-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:54:15,025 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:54:15,026 DEBUG [htable-pool35-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:54:20,282 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56601; # active connections: 2
2016-01-17 18:54:20,283 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56601 because read count=-1. Number of active connections: 2
2016-01-17 18:54:50,063 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56743; # active connections: 2
2016-01-17 18:54:50,063 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56743 because read count=-1. Number of active connections: 2
2016-01-17 18:55:20,354 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:56872; # active connections: 2
2016-01-17 18:55:20,354 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:56872 because read count=-1. Number of active connections: 2
2016-01-17 18:55:50,269 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57027; # active connections: 2
2016-01-17 18:55:50,269 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57027 because read count=-1. Number of active connections: 2
2016-01-17 18:56:20,266 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57160; # active connections: 2
2016-01-17 18:56:20,266 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57160 because read count=-1. Number of active connections: 2
2016-01-17 18:56:50,269 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57310; # active connections: 2
2016-01-17 18:56:50,270 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57310 because read count=-1. Number of active connections: 2
2016-01-17 18:57:20,250 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57441; # active connections: 2
2016-01-17 18:57:20,251 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57441 because read count=-1. Number of active connections: 2
2016-01-17 18:57:50,298 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57586; # active connections: 2
2016-01-17 18:57:50,298 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57586 because read count=-1. Number of active connections: 2
2016-01-17 18:58:02,437 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57647; # active connections: 2
2016-01-17 18:58:13,857 INFO  [FifoRpcScheduler.handler1-thread-6] master.HMaster: Client=thenson//10.0.0.4 disable tester1
2016-01-17 18:58:13,875 DEBUG [FifoRpcScheduler.handler1-thread-6] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000001
2016-01-17 18:58:13,877 DEBUG [htable-pool36-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 18:58:13,877 DEBUG [htable-pool36-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:58:13,918 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table tester1
2016-01-17 18:58:13,953 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-17 18:58:13,987 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15. (offlining), current state: {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1453053264298, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:13,987 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node a1abc6352f6e6010b61cd89061575d15 in a CLOSING state
2016-01-17 18:58:14,032 INFO  [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=OPEN, ts=1453053264298, server=sandbox.hortonworks.com,60020,1453053229927} to {a1abc6352f6e6010b61cd89061575d15 state=PENDING_CLOSE, ts=1453057094032, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:14,041 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 18:58:14,041 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 18:58:14,067 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1453053229927 for region tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.
2016-01-17 18:58:14,363 DEBUG [AM.ZK.Worker-pool2-t40] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1453053229927, region=a1abc6352f6e6010b61cd89061575d15, current_state={a1abc6352f6e6010b61cd89061575d15 state=PENDING_CLOSE, ts=1453057094032, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:14,367 DEBUG [AM.ZK.Worker-pool2-t40] handler.ClosedRegionHandler: Handling CLOSED event for a1abc6352f6e6010b61cd89061575d15
2016-01-17 18:58:14,367 DEBUG [AM.ZK.Worker-pool2-t40] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.
2016-01-17 18:58:14,407 DEBUG [AM.ZK.Worker-pool2-t40] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node a1abc6352f6e6010b61cd89061575d15 in expected state RS_ZK_REGION_CLOSED
2016-01-17 18:58:14,407 DEBUG [AM.ZK.Worker-pool2-t40] master.AssignmentManager: Removing region from replicasToClose {ENCODED => a1abc6352f6e6010b61cd89061575d15, NAME => 'tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.', STARTKEY => '', ENDKEY => ''}
2016-01-17 18:58:14,407 INFO  [AM.ZK.Worker-pool2-t40] master.RegionStates: Transitioned {a1abc6352f6e6010b61cd89061575d15 state=PENDING_CLOSE, ts=1453057094032, server=sandbox.hortonworks.com,60020,1453053229927} to {a1abc6352f6e6010b61cd89061575d15 state=OFFLINE, ts=1453057094407, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:14,407 INFO  [AM.ZK.Worker-pool2-t40] master.RegionStates: Offlined a1abc6352f6e6010b61cd89061575d15 from sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:58:14,984 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-17 18:58:15,012 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, tester1, is done=true
2016-01-17 18:58:15,105 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000001
2016-01-17 18:58:20,270 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57741; # active connections: 3
2016-01-17 18:58:20,271 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57741 because read count=-1. Number of active connections: 3
2016-01-17 18:58:20,568 INFO  [FifoRpcScheduler.handler1-thread-11] master.HMaster: Client=thenson//10.0.0.4 delete tester1
2016-01-17 18:58:20,596 DEBUG [FifoRpcScheduler.handler1-thread-11] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/tester1/write-master:600000000000002
2016-01-17 18:58:20,611 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table tester1
2016-01-17 18:58:20,628 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-17 18:58:20,645 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => a1abc6352f6e6010b61cd89061575d15, NAME => 'tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 18:58:20,686 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region tester1,,1452982346454.a1abc6352f6e6010b61cd89061575d15. from FS
2016-01-17 18:58:20,686 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15
2016-01-17 18:58:20,700 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/info, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/recovered.edits]
2016-01-17 18:58:20,811 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/info/13c9fae4e9f443de8040cce4e3df0361, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/info/13c9fae4e9f443de8040cce4e3df0361
2016-01-17 18:58:20,873 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/recovered.edits/8_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/tester1/a1abc6352f6e6010b61cd89061575d15/recovered.edits/8_seqid
2016-01-17 18:58:20,905 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/tester1/a1abc6352f6e6010b61cd89061575d15
2016-01-17 18:58:20,923 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'tester1' from region states.
2016-01-17 18:58:20,923 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'tester1' as deleted.
2016-01-17 18:58:20,983 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/tester1/write-master:600000000000002
2016-01-17 18:58:32,315 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.001 minutes: inLogs=4, outLogs=4, dropped=0, currentQueueSize=0
2016-01-17 18:58:32,315 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=15, outLogs=15, dropped=0
2016-01-17 18:58:34,461 INFO  [FifoRpcScheduler.handler1-thread-21] master.HMaster: Client=thenson//10.0.0.4 disable stock
2016-01-17 18:58:34,491 DEBUG [FifoRpcScheduler.handler1-thread-21] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/stock/write-master:600000000000001
2016-01-17 18:58:34,551 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table stock
2016-01-17 18:58:34,583 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-17 18:58:34,584 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77. (offlining), current state: {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1453053264497, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:34,584 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 in a CLOSING state
2016-01-17 18:58:34,629 INFO  [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=OPEN, ts=1453053264497, server=sandbox.hortonworks.com,60020,1453053229927} to {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_CLOSE, ts=1453057114629, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:34,632 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1453053229927 for region stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.
2016-01-17 18:58:34,772 DEBUG [AM.ZK.Worker-pool2-t44] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1453053229927, region=9b0335280e0a412ba7e69b46f0cf2a77, current_state={9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_CLOSE, ts=1453057114629, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:34,772 DEBUG [AM.ZK.Worker-pool2-t44] handler.ClosedRegionHandler: Handling CLOSED event for 9b0335280e0a412ba7e69b46f0cf2a77
2016-01-17 18:58:34,772 DEBUG [AM.ZK.Worker-pool2-t44] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.
2016-01-17 18:58:34,801 DEBUG [AM.ZK.Worker-pool2-t44] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 9b0335280e0a412ba7e69b46f0cf2a77 in expected state RS_ZK_REGION_CLOSED
2016-01-17 18:58:34,801 DEBUG [AM.ZK.Worker-pool2-t44] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 9b0335280e0a412ba7e69b46f0cf2a77, NAME => 'stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.', STARTKEY => '', ENDKEY => ''}
2016-01-17 18:58:34,801 INFO  [AM.ZK.Worker-pool2-t44] master.RegionStates: Transitioned {9b0335280e0a412ba7e69b46f0cf2a77 state=PENDING_CLOSE, ts=1453057114629, server=sandbox.hortonworks.com,60020,1453053229927} to {9b0335280e0a412ba7e69b46f0cf2a77 state=OFFLINE, ts=1453057114801, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 18:58:34,801 INFO  [AM.ZK.Worker-pool2-t44] master.RegionStates: Offlined 9b0335280e0a412ba7e69b46f0cf2a77 from sandbox.hortonworks.com,60020,1453053229927
2016-01-17 18:58:35,585 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; []
2016-01-17 18:58:35,613 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, stock, is done=true
2016-01-17 18:58:35,644 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/stock/write-master:600000000000001
2016-01-17 18:58:38,497 INFO  [FifoRpcScheduler.handler1-thread-25] master.HMaster: Client=thenson//10.0.0.4 delete stock
2016-01-17 18:58:38,525 DEBUG [FifoRpcScheduler.handler1-thread-25] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/stock/write-master:600000000000002
2016-01-17 18:58:38,572 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table stock
2016-01-17 18:58:38,620 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-17 18:58:38,637 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 9b0335280e0a412ba7e69b46f0cf2a77, NAME => 'stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 18:58:38,681 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region stock,,1452978655510.9b0335280e0a412ba7e69b46f0cf2a77. from FS
2016-01-17 18:58:38,681 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77
2016-01-17 18:58:38,783 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/adj_close, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/close, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/date, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/high, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/low, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/open, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/recovered.edits, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/volume]
2016-01-17 18:58:39,020 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/recovered.edits/5_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77/recovered.edits/5_seqid
2016-01-17 18:58:39,068 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/stock/9b0335280e0a412ba7e69b46f0cf2a77
2016-01-17 18:58:39,102 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'stock' from region states.
2016-01-17 18:58:39,102 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'stock' as deleted.
2016-01-17 18:58:39,161 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/stock/write-master:600000000000002
2016-01-17 18:58:46,665 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57647 because read count=-1. Number of active connections: 2
2016-01-17 18:58:50,274 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:57885; # active connections: 2
2016-01-17 18:58:50,274 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:57885 because read count=-1. Number of active connections: 2
2016-01-17 18:58:53,962 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.002 minutes: inLogs=9, outLogs=9, dropped=0, currentQueueSize=0
2016-01-17 18:58:53,962 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=20, outLogs=20, dropped=0
2016-01-17 18:59:15,027 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 18:59:20,099 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58019; # active connections: 2
2016-01-17 18:59:20,099 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58019 because read count=-1. Number of active connections: 2
2016-01-17 18:59:32,317 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=5, outLogs=5, dropped=0, currentQueueSize=0
2016-01-17 18:59:32,317 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=20, outLogs=20, dropped=0
2016-01-17 18:59:50,117 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58172; # active connections: 2
2016-01-17 18:59:50,117 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58172 because read count=-1. Number of active connections: 2
2016-01-17 19:00:20,119 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58307; # active connections: 2
2016-01-17 19:00:20,120 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58307 because read count=-1. Number of active connections: 2
2016-01-17 19:00:50,168 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58447; # active connections: 2
2016-01-17 19:00:50,168 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58447 because read count=-1. Number of active connections: 2
2016-01-17 19:01:20,120 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58588; # active connections: 2
2016-01-17 19:01:20,121 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58588 because read count=-1. Number of active connections: 2
2016-01-17 19:01:50,121 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58734; # active connections: 2
2016-01-17 19:01:50,121 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58734 because read count=-1. Number of active connections: 2
2016-01-17 19:02:20,108 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:58864; # active connections: 2
2016-01-17 19:02:20,108 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:58864 because read count=-1. Number of active connections: 2
2016-01-17 19:02:50,099 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59006; # active connections: 2
2016-01-17 19:02:50,099 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59006 because read count=-1. Number of active connections: 2
2016-01-17 19:03:20,096 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59136; # active connections: 2
2016-01-17 19:03:20,096 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59136 because read count=-1. Number of active connections: 2
2016-01-17 19:03:50,113 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59287; # active connections: 2
2016-01-17 19:03:50,114 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59287 because read count=-1. Number of active connections: 2
2016-01-17 19:04:15,028 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:04:15,032 DEBUG [htable-pool45-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:04:15,032 DEBUG [htable-pool45-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:04:20,100 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59421; # active connections: 2
2016-01-17 19:04:20,100 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59421 because read count=-1. Number of active connections: 2
2016-01-17 19:04:37,607 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1453053229927.1453053235737
2016-01-17 19:04:37,669 DEBUG [master:sandbox:60000.oldLogCleaner] master.ReplicationLogCleaner: Didn't find this log in ZK, deleting: sandbox.hortonworks.com%2C60020%2C1453053229927.1453053244299.meta
2016-01-17 19:04:50,088 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59566; # active connections: 2
2016-01-17 19:04:50,088 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59566 because read count=-1. Number of active connections: 2
2016-01-17 19:05:20,102 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59711; # active connections: 2
2016-01-17 19:05:20,102 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59711 because read count=-1. Number of active connections: 2
2016-01-17 19:05:50,072 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59852; # active connections: 2
2016-01-17 19:05:50,072 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59852 because read count=-1. Number of active connections: 2
2016-01-17 19:06:20,076 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:59980; # active connections: 2
2016-01-17 19:06:20,076 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:59980 because read count=-1. Number of active connections: 2
2016-01-17 19:06:50,295 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60130; # active connections: 2
2016-01-17 19:06:50,296 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60130 because read count=-1. Number of active connections: 2
2016-01-17 19:07:20,295 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60265; # active connections: 2
2016-01-17 19:07:20,295 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60265 because read count=-1. Number of active connections: 2
2016-01-17 19:07:50,308 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60403; # active connections: 2
2016-01-17 19:07:50,308 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60403 because read count=-1. Number of active connections: 2
2016-01-17 19:08:20,267 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60544; # active connections: 2
2016-01-17 19:08:20,267 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60544 because read count=-1. Number of active connections: 2
2016-01-17 19:08:50,287 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60684; # active connections: 2
2016-01-17 19:08:50,287 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60684 because read count=-1. Number of active connections: 2
2016-01-17 19:09:15,029 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:09:15,037 DEBUG [htable-pool46-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:09:15,037 DEBUG [htable-pool46-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:09:20,154 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60813; # active connections: 2
2016-01-17 19:09:20,163 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60813 because read count=-1. Number of active connections: 2
2016-01-17 19:09:50,110 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:60965; # active connections: 2
2016-01-17 19:09:50,110 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:60965 because read count=-1. Number of active connections: 2
2016-01-17 19:10:14,117 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:32843; # active connections: 2
2016-01-17 19:10:14,224 INFO  [FifoRpcScheduler.handler1-thread-26] master.HMaster: Client=thenson//10.0.0.4 create 'app_stock', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-17 19:10:14,345 DEBUG [FifoRpcScheduler.handler1-thread-26] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/app_stock/write-master:600000000000000
2016-01-17 19:10:14,390 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table app_stock
2016-01-17 19:10:14,391 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:20.411 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 19:10:14,391 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=21, outLogs=21, dropped=0
2016-01-17 19:10:14,578 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/.tabledesc/.tableinfo.0000000001
2016-01-17 19:10:14,590 INFO  [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: creating HRegion app_stock HTD == 'app_stock', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == app_stock
2016-01-17 19:10:14,719 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Instantiated app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.
2016-01-17 19:10:14,719 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Closing app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.: disabling compactions & flushes
2016-01-17 19:10:14,719 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Updates disabled for region app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.
2016-01-17 19:10:14,719 INFO  [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Closed app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.
2016-01-17 19:10:14,757 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-17 19:10:14,780 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:10:14,780 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 741a6380c4d039d50dd29da62ef45751 with OFFLINE state
2016-01-17 19:10:14,812 DEBUG [main-EventThread] master.OfflineCallback: rs={741a6380c4d039d50dd29da62ef45751 state=OFFLINE, ts=1453057814761, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:10:14,813 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={741a6380c4d039d50dd29da62ef45751 state=OFFLINE, ts=1453057814761, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:10:14,816 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=1 of total=1
2016-01-17 19:10:14,816 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {741a6380c4d039d50dd29da62ef45751 state=OFFLINE, ts=1453057814780, server=null} to {741a6380c4d039d50dd29da62ef45751 state=PENDING_OPEN, ts=1453057814816, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:14,817 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 19:10:14,817 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:10:14,832 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:10:14,874 DEBUG [AM.ZK.Worker-pool2-t48] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=741a6380c4d039d50dd29da62ef45751, current_state={741a6380c4d039d50dd29da62ef45751 state=PENDING_OPEN, ts=1453057814816, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:14,875 INFO  [AM.ZK.Worker-pool2-t48] master.RegionStates: Transitioned {741a6380c4d039d50dd29da62ef45751 state=PENDING_OPEN, ts=1453057814816, server=sandbox.hortonworks.com,60020,1453053229927} to {741a6380c4d039d50dd29da62ef45751 state=OPENING, ts=1453057814875, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:14,890 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/app_stock/write-master:600000000000000
2016-01-17 19:10:14,890 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, app_stock, creation successful
2016-01-17 19:10:15,001 DEBUG [AM.ZK.Worker-pool2-t49] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=741a6380c4d039d50dd29da62ef45751, current_state={741a6380c4d039d50dd29da62ef45751 state=OPENING, ts=1453057814875, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:15,001 INFO  [AM.ZK.Worker-pool2-t49] master.RegionStates: Transitioned {741a6380c4d039d50dd29da62ef45751 state=OPENING, ts=1453057814875, server=sandbox.hortonworks.com,60020,1453053229927} to {741a6380c4d039d50dd29da62ef45751 state=OPEN, ts=1453057815001, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:15,002 DEBUG [AM.ZK.Worker-pool2-t49] handler.OpenedRegionHandler: Handling OPENED of 741a6380c4d039d50dd29da62ef45751 from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 19:10:15,031 DEBUG [AM.ZK.Worker-pool2-t49] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 741a6380c4d039d50dd29da62ef45751 in expected state RS_ZK_REGION_OPENED
2016-01-17 19:10:15,068 DEBUG [AM.ZK.Worker-pool2-t51] master.AssignmentManager: Znode app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751. deleted, state: {741a6380c4d039d50dd29da62ef45751 state=OPEN, ts=1453057815001, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:10:15,068 INFO  [AM.ZK.Worker-pool2-t51] master.RegionStates: Onlined 741a6380c4d039d50dd29da62ef45751 on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 741a6380c4d039d50dd29da62ef45751, NAME => 'app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.', STARTKEY => '', ENDKEY => ''}
2016-01-17 19:10:20,175 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:32875; # active connections: 3
2016-01-17 19:10:20,175 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:32875 because read count=-1. Number of active connections: 3
2016-01-17 19:10:27,561 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:32843 because read count=-1. Number of active connections: 2
2016-01-17 19:10:32,337 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 19:10:32,337 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=21, outLogs=21, dropped=0
2016-01-17 19:10:50,194 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33028; # active connections: 2
2016-01-17 19:10:50,195 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33028 because read count=-1. Number of active connections: 2
2016-01-17 19:11:20,192 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33175; # active connections: 2
2016-01-17 19:11:20,193 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33175 because read count=-1. Number of active connections: 2
2016-01-17 19:11:50,286 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33314; # active connections: 2
2016-01-17 19:11:50,287 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33314 because read count=-1. Number of active connections: 2
2016-01-17 19:12:20,200 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33461; # active connections: 2
2016-01-17 19:12:20,204 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33461 because read count=-1. Number of active connections: 2
2016-01-17 19:12:50,167 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33619; # active connections: 2
2016-01-17 19:12:50,167 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33619 because read count=-1. Number of active connections: 2
2016-01-17 19:13:20,209 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33746; # active connections: 2
2016-01-17 19:13:20,210 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33746 because read count=-1. Number of active connections: 2
2016-01-17 19:13:50,298 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:33923; # active connections: 2
2016-01-17 19:13:50,299 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:33923 because read count=-1. Number of active connections: 2
2016-01-17 19:14:15,030 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:14:15,037 DEBUG [htable-pool49-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:14:15,037 DEBUG [htable-pool49-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:14:20,203 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34061; # active connections: 2
2016-01-17 19:14:20,203 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34061 because read count=-1. Number of active connections: 2
2016-01-17 19:14:50,147 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34206; # active connections: 2
2016-01-17 19:14:50,147 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34206 because read count=-1. Number of active connections: 2
2016-01-17 19:15:20,929 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34345; # active connections: 2
2016-01-17 19:15:20,934 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34345 because read count=-1. Number of active connections: 2
2016-01-17 19:15:41,500 INFO  [JvmPauseMonitor] util.JvmPauseMonitor: Detected pause in JVM or host machine (eg GC): pause of approximately 1670ms
GC pool 'ParNew' had collection(s): count=1 time=14ms
2016-01-17 19:15:50,438 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34472; # active connections: 2
2016-01-17 19:15:50,438 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34472 because read count=-1. Number of active connections: 2
2016-01-17 19:16:20,488 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34624; # active connections: 2
2016-01-17 19:16:20,505 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34624 because read count=-1. Number of active connections: 2
2016-01-17 19:16:50,447 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34775; # active connections: 2
2016-01-17 19:16:50,453 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34775 because read count=-1. Number of active connections: 2
2016-01-17 19:17:20,201 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:34907; # active connections: 2
2016-01-17 19:17:20,201 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:34907 because read count=-1. Number of active connections: 2
2016-01-17 19:17:50,422 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35053; # active connections: 2
2016-01-17 19:17:50,423 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35053 because read count=-1. Number of active connections: 2
2016-01-17 19:18:20,378 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35191; # active connections: 2
2016-01-17 19:18:20,378 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35191 because read count=-1. Number of active connections: 2
2016-01-17 19:18:36,178 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35274; # active connections: 2
2016-01-17 19:18:36,201 INFO  [FifoRpcScheduler.handler1-thread-15] master.HMaster: Client=thenson//10.0.0.4 disable app_stock
2016-01-17 19:18:36,232 DEBUG [FifoRpcScheduler.handler1-thread-15] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/app_stock/write-master:600000000000001
2016-01-17 19:18:36,237 DEBUG [htable-pool50-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:18:36,237 DEBUG [htable-pool50-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:18:36,292 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Attempting to disable table app_stock
2016-01-17 19:18:36,324 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Offlining 1 regions.
2016-01-17 19:18:36,334 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Starting unassign of app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751. (offlining), current state: {741a6380c4d039d50dd29da62ef45751 state=OPEN, ts=1453057815068, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:18:36,334 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Creating unassigned node 741a6380c4d039d50dd29da62ef45751 in a CLOSING state
2016-01-17 19:18:36,372 INFO  [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.RegionStates: Transitioned {741a6380c4d039d50dd29da62ef45751 state=OPEN, ts=1453057815068, server=sandbox.hortonworks.com,60020,1453053229927} to {741a6380c4d039d50dd29da62ef45751 state=PENDING_CLOSE, ts=1453058316372, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:18:36,372 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 19:18:36,372 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:18:36,376 DEBUG [sandbox.hortonworks.com,60000,1453053198477-org.apache.hadoop.hbase.master.handler.DisableTableHandler$BulkDisabler-0] master.AssignmentManager: Sent CLOSE to sandbox.hortonworks.com,60020,1453053229927 for region app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.
2016-01-17 19:18:37,336 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 300000 ms remaining; [{ENCODED => 741a6380c4d039d50dd29da62ef45751, NAME => 'app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 19:18:37,677 DEBUG [AM.ZK.Worker-pool2-t53] master.AssignmentManager: Handling RS_ZK_REGION_CLOSED, server=sandbox.hortonworks.com,60020,1453053229927, region=741a6380c4d039d50dd29da62ef45751, current_state={741a6380c4d039d50dd29da62ef45751 state=PENDING_CLOSE, ts=1453058316372, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:18:37,678 DEBUG [AM.ZK.Worker-pool2-t53] handler.ClosedRegionHandler: Handling CLOSED event for 741a6380c4d039d50dd29da62ef45751
2016-01-17 19:18:37,678 DEBUG [AM.ZK.Worker-pool2-t53] master.AssignmentManager: Table being disabled so deleting ZK node and removing from regions in transition, skipping assignment of region app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.
2016-01-17 19:18:37,699 DEBUG [AM.ZK.Worker-pool2-t53] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 741a6380c4d039d50dd29da62ef45751 in expected state RS_ZK_REGION_CLOSED
2016-01-17 19:18:37,699 DEBUG [AM.ZK.Worker-pool2-t53] master.AssignmentManager: Removing region from replicasToClose {ENCODED => 741a6380c4d039d50dd29da62ef45751, NAME => 'app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.', STARTKEY => '', ENDKEY => ''}
2016-01-17 19:18:37,699 INFO  [AM.ZK.Worker-pool2-t53] master.RegionStates: Transitioned {741a6380c4d039d50dd29da62ef45751 state=PENDING_CLOSE, ts=1453058316372, server=sandbox.hortonworks.com,60020,1453053229927} to {741a6380c4d039d50dd29da62ef45751 state=OFFLINE, ts=1453058317699, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:18:37,699 INFO  [AM.ZK.Worker-pool2-t53] master.RegionStates: Offlined 741a6380c4d039d50dd29da62ef45751 from sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:18:38,339 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disable waiting until done; 298997 ms remaining; []
2016-01-17 19:18:38,360 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DisableTableHandler: Disabled table, app_stock, is done=true
2016-01-17 19:18:38,376 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/app_stock/write-master:600000000000001
2016-01-17 19:18:47,477 INFO  [FifoRpcScheduler.handler1-thread-20] master.HMaster: Client=thenson//10.0.0.4 delete app_stock
2016-01-17 19:18:47,506 DEBUG [FifoRpcScheduler.handler1-thread-20] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/app_stock/write-master:600000000000002
2016-01-17 19:18:47,523 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.TableEventHandler: Handling table operation C_M_DELETE_TABLE on table app_stock
2016-01-17 19:18:47,533 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Deleting regions from META
2016-01-17 19:18:47,548 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Deleted [{ENCODED => 741a6380c4d039d50dd29da62ef45751, NAME => 'app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751.', STARTKEY => '', ENDKEY => ''}]
2016-01-17 19:18:47,584 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Archiving region app_stock,,1453057814222.741a6380c4d039d50dd29da62ef45751. from FS
2016-01-17 19:18:47,585 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: ARCHIVING hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751
2016-01-17 19:18:47,598 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Archiving [class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/info, class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/recovered.edits]
2016-01-17 19:18:47,723 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/info/bb8b4cf4f5844b9fa641d28f80bf853b, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/info/bb8b4cf4f5844b9fa641d28f80bf853b
2016-01-17 19:18:47,786 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Finished archiving from class org.apache.hadoop.hbase.backup.HFileArchiver$FileablePath, file:hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/recovered.edits/12_seqid, to hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/archive/data/default/app_stock/741a6380c4d039d50dd29da62ef45751/recovered.edits/12_seqid
2016-01-17 19:18:47,805 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] backup.HFileArchiver: Deleted all region files in: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/741a6380c4d039d50dd29da62ef45751
2016-01-17 19:18:47,835 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Removing 'app_stock' from region states.
2016-01-17 19:18:47,835 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.DeleteTableHandler: Marking 'app_stock' as deleted.
2016-01-17 19:18:47,879 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/app_stock/write-master:600000000000002
2016-01-17 19:18:50,417 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35349; # active connections: 3
2016-01-17 19:18:50,422 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35349 because read count=-1. Number of active connections: 3
2016-01-17 19:18:50,541 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35274 because read count=-1. Number of active connections: 2
2016-01-17 19:19:14,415 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.006 minutes: inLogs=4, outLogs=4, dropped=0, currentQueueSize=0
2016-01-17 19:19:14,416 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=25, outLogs=25, dropped=0
2016-01-17 19:19:15,031 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:19:20,319 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35474; # active connections: 2
2016-01-17 19:19:20,321 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35474 because read count=-1. Number of active connections: 2
2016-01-17 19:19:50,299 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35628; # active connections: 2
2016-01-17 19:19:50,300 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35628 because read count=-1. Number of active connections: 2
2016-01-17 19:20:20,500 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35768; # active connections: 2
2016-01-17 19:20:20,500 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35768 because read count=-1. Number of active connections: 2
2016-01-17 19:20:32,353 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 02:00.001 minutes: inLogs=4, outLogs=4, dropped=0, currentQueueSize=0
2016-01-17 19:20:32,353 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=25, outLogs=25, dropped=0
2016-01-17 19:20:50,308 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:35908; # active connections: 2
2016-01-17 19:20:50,308 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:35908 because read count=-1. Number of active connections: 2
2016-01-17 19:21:20,474 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36059; # active connections: 2
2016-01-17 19:21:20,475 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36059 because read count=-1. Number of active connections: 2
2016-01-17 19:21:50,393 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36201; # active connections: 2
2016-01-17 19:21:50,401 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36201 because read count=-1. Number of active connections: 2
2016-01-17 19:22:20,417 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36336; # active connections: 2
2016-01-17 19:22:20,426 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36336 because read count=-1. Number of active connections: 2
2016-01-17 19:22:50,360 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36482; # active connections: 2
2016-01-17 19:22:50,361 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36482 because read count=-1. Number of active connections: 2
2016-01-17 19:23:00,387 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36525; # active connections: 2
2016-01-17 19:23:00,438 INFO  [FifoRpcScheduler.handler1-thread-51] master.HMaster: Client=thenson//10.0.0.4 create 'app_stock', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
2016-01-17 19:23:00,582 DEBUG [FifoRpcScheduler.handler1-thread-51] lock.ZKInterProcessLockBase: Acquired a lock for /hbase-unsecure/table-lock/app_stock/write-master:600000000000000
2016-01-17 19:23:00,584 DEBUG [htable-pool55-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:23:00,584 DEBUG [htable-pool55-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:23:00,643 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Create table app_stock
2016-01-17 19:23:01,222 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] util.FSTableDescriptors: Wrote descriptor into: hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp/data/default/app_stock/.tabledesc/.tableinfo.0000000001
2016-01-17 19:23:01,226 INFO  [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: creating HRegion app_stock HTD == 'app_stock', {NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = hdfs://sandbox.hortonworks.com:8020/apps/hbase/data/.tmp Table name == app_stock
2016-01-17 19:23:01,847 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Instantiated app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c.
2016-01-17 19:23:01,847 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Closing app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c.: disabling compactions & flushes
2016-01-17 19:23:01,848 DEBUG [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Updates disabled for region app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c.
2016-01-17 19:23:01,848 INFO  [RegionOpenAndInitThread-app_stock-1] regionserver.HRegion: Closed app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c.
2016-01-17 19:23:01,897 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] catalog.MetaEditor: Added 1
2016-01-17 19:23:01,924 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Assigning 1 region(s) to sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:23:01,924 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Async create of unassigned node 0ae015b86de00d918823cca8ade0195c with OFFLINE state
2016-01-17 19:23:01,940 DEBUG [main-EventThread] master.OfflineCallback: rs={0ae015b86de00d918823cca8ade0195c state=OFFLINE, ts=1453058581898, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:23:01,942 DEBUG [main-EventThread] master.OfflineCallback$ExistCallback: rs={0ae015b86de00d918823cca8ade0195c state=OFFLINE, ts=1453058581898, server=null}, server=sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:23:01,944 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: sandbox.hortonworks.com,60020,1453053229927 unassigned znodes=1 of total=1
2016-01-17 19:23:01,944 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.RegionStates: Transitioned {0ae015b86de00d918823cca8ade0195c state=OFFLINE, ts=1453058581924, server=null} to {0ae015b86de00d918823cca8ade0195c state=PENDING_OPEN, ts=1453058581944, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:01,944 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Use SIMPLE authentication for service AdminService, sasl=false
2016-01-17 19:23:01,944 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:23:01,975 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] master.AssignmentManager: Bulk assigning done for sandbox.hortonworks.com,60020,1453053229927
2016-01-17 19:23:02,037 DEBUG [MASTER_TABLE_OPERATIONS-sandbox:60000-0] lock.ZKInterProcessLockBase: Released /hbase-unsecure/table-lock/app_stock/write-master:600000000000000
2016-01-17 19:23:02,038 INFO  [MASTER_TABLE_OPERATIONS-sandbox:60000-0] handler.CreateTableHandler: Table, app_stock, creation successful
2016-01-17 19:23:02,038 DEBUG [AM.ZK.Worker-pool2-t57] master.AssignmentManager: Handling RS_ZK_REGION_OPENING, server=sandbox.hortonworks.com,60020,1453053229927, region=0ae015b86de00d918823cca8ade0195c, current_state={0ae015b86de00d918823cca8ade0195c state=PENDING_OPEN, ts=1453058581944, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:02,038 INFO  [AM.ZK.Worker-pool2-t57] master.RegionStates: Transitioned {0ae015b86de00d918823cca8ade0195c state=PENDING_OPEN, ts=1453058581944, server=sandbox.hortonworks.com,60020,1453053229927} to {0ae015b86de00d918823cca8ade0195c state=OPENING, ts=1453058582038, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:02,255 DEBUG [AM.ZK.Worker-pool2-t58] master.AssignmentManager: Handling RS_ZK_REGION_OPENED, server=sandbox.hortonworks.com,60020,1453053229927, region=0ae015b86de00d918823cca8ade0195c, current_state={0ae015b86de00d918823cca8ade0195c state=OPENING, ts=1453058582038, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:02,256 INFO  [AM.ZK.Worker-pool2-t58] master.RegionStates: Transitioned {0ae015b86de00d918823cca8ade0195c state=OPENING, ts=1453058582038, server=sandbox.hortonworks.com,60020,1453053229927} to {0ae015b86de00d918823cca8ade0195c state=OPEN, ts=1453058582256, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:02,256 DEBUG [AM.ZK.Worker-pool2-t58] handler.OpenedRegionHandler: Handling OPENED of 0ae015b86de00d918823cca8ade0195c from sandbox.hortonworks.com,60020,1453053229927; deleting unassigned node
2016-01-17 19:23:02,288 DEBUG [AM.ZK.Worker-pool2-t58] zookeeper.ZKAssign: master:60000-0x15250a3fca40006, quorum=sandbox.hortonworks.com:2181, baseZNode=/hbase-unsecure Deleted unassigned node 0ae015b86de00d918823cca8ade0195c in expected state RS_ZK_REGION_OPENED
2016-01-17 19:23:02,289 DEBUG [AM.ZK.Worker-pool2-t60] master.AssignmentManager: Znode app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c. deleted, state: {0ae015b86de00d918823cca8ade0195c state=OPEN, ts=1453058582256, server=sandbox.hortonworks.com,60020,1453053229927}
2016-01-17 19:23:02,290 INFO  [AM.ZK.Worker-pool2-t60] master.RegionStates: Onlined 0ae015b86de00d918823cca8ade0195c on sandbox.hortonworks.com,60020,1453053229927 {ENCODED => 0ae015b86de00d918823cca8ade0195c, NAME => 'app_stock,,1453058580432.0ae015b86de00d918823cca8ade0195c.', STARTKEY => '', ENDKEY => ''}
2016-01-17 19:23:14,423 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: past 01:00.001 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 19:23:14,424 INFO  [AsyncAuditProvider1] provider.AsyncAuditProvider: AsyncAuditProvider-stats:DbAuditProvider: process lifetime: inLogs=26, outLogs=26, dropped=0
2016-01-17 19:23:19,098 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36525 because read count=-1. Number of active connections: 2
2016-01-17 19:23:20,415 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36617; # active connections: 2
2016-01-17 19:23:20,420 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36617 because read count=-1. Number of active connections: 2
2016-01-17 19:23:32,363 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: past 01:00.002 minutes: inLogs=1, outLogs=1, dropped=0, currentQueueSize=0
2016-01-17 19:23:32,364 INFO  [AsyncAuditProvider2] provider.AsyncAuditProvider: AsyncAuditProvider-stats:HdfsAuditProvider: process lifetime: inLogs=26, outLogs=26, dropped=0
2016-01-17 19:23:50,196 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36756; # active connections: 2
2016-01-17 19:23:50,204 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36756 because read count=-1. Number of active connections: 2
2016-01-17 19:24:15,033 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:24:20,269 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:36898; # active connections: 2
2016-01-17 19:24:20,269 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:36898 because read count=-1. Number of active connections: 2
2016-01-17 19:24:50,284 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37042; # active connections: 2
2016-01-17 19:24:50,284 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37042 because read count=-1. Number of active connections: 2
2016-01-17 19:25:20,364 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37183; # active connections: 2
2016-01-17 19:25:20,364 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37183 because read count=-1. Number of active connections: 2
2016-01-17 19:25:50,265 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37322; # active connections: 2
2016-01-17 19:25:50,278 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37322 because read count=-1. Number of active connections: 2
2016-01-17 19:26:20,269 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37453; # active connections: 2
2016-01-17 19:26:20,270 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37453 because read count=-1. Number of active connections: 2
2016-01-17 19:26:50,253 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37606; # active connections: 2
2016-01-17 19:26:50,254 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37606 because read count=-1. Number of active connections: 2
2016-01-17 19:27:20,277 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37738; # active connections: 2
2016-01-17 19:27:20,277 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37738 because read count=-1. Number of active connections: 2
2016-01-17 19:27:50,359 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:37872; # active connections: 2
2016-01-17 19:27:50,360 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:37872 because read count=-1. Number of active connections: 2
2016-01-17 19:28:20,222 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38017; # active connections: 2
2016-01-17 19:28:20,223 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38017 because read count=-1. Number of active connections: 2
2016-01-17 19:28:50,217 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38154; # active connections: 2
2016-01-17 19:28:50,217 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38154 because read count=-1. Number of active connections: 2
2016-01-17 19:29:15,044 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:29:15,068 DEBUG [htable-pool58-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:29:15,068 DEBUG [htable-pool58-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:29:20,278 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38284; # active connections: 2
2016-01-17 19:29:20,284 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38284 because read count=-1. Number of active connections: 2
2016-01-17 19:29:50,236 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38434; # active connections: 2
2016-01-17 19:29:50,237 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38434 because read count=-1. Number of active connections: 2
2016-01-17 19:30:20,350 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38577; # active connections: 2
2016-01-17 19:30:20,350 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38577 because read count=-1. Number of active connections: 2
2016-01-17 19:30:50,253 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38715; # active connections: 2
2016-01-17 19:30:50,253 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38715 because read count=-1. Number of active connections: 2
2016-01-17 19:31:20,425 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:38858; # active connections: 2
2016-01-17 19:31:20,434 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:38858 because read count=-1. Number of active connections: 2
2016-01-17 19:31:50,514 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39045; # active connections: 2
2016-01-17 19:31:50,515 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39045 because read count=-1. Number of active connections: 2
2016-01-17 19:32:20,477 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39191; # active connections: 2
2016-01-17 19:32:20,478 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39191 because read count=-1. Number of active connections: 2
2016-01-17 19:32:50,202 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39347; # active connections: 2
2016-01-17 19:32:50,207 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39347 because read count=-1. Number of active connections: 2
2016-01-17 19:33:20,516 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39490; # active connections: 2
2016-01-17 19:33:20,522 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39490 because read count=-1. Number of active connections: 2
2016-01-17 19:33:50,237 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39636; # active connections: 2
2016-01-17 19:33:50,238 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39636 because read count=-1. Number of active connections: 2
2016-01-17 19:34:15,035 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:34:15,055 DEBUG [htable-pool59-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:34:15,055 DEBUG [htable-pool59-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:34:20,198 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39762; # active connections: 2
2016-01-17 19:34:20,198 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39762 because read count=-1. Number of active connections: 2
2016-01-17 19:34:50,223 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:39909; # active connections: 2
2016-01-17 19:34:50,224 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:39909 because read count=-1. Number of active connections: 2
2016-01-17 19:35:20,282 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40055; # active connections: 2
2016-01-17 19:35:20,282 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40055 because read count=-1. Number of active connections: 2
2016-01-17 19:35:50,313 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40200; # active connections: 2
2016-01-17 19:35:50,314 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40200 because read count=-1. Number of active connections: 2
2016-01-17 19:36:20,342 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40346; # active connections: 2
2016-01-17 19:36:20,342 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40346 because read count=-1. Number of active connections: 2
2016-01-17 19:36:50,358 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40523; # active connections: 2
2016-01-17 19:36:50,359 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40523 because read count=-1. Number of active connections: 2
2016-01-17 19:37:20,593 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40668; # active connections: 2
2016-01-17 19:37:20,602 DEBUG [RpcServer.reader=8,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40668 because read count=-1. Number of active connections: 2
2016-01-17 19:37:50,228 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40827; # active connections: 2
2016-01-17 19:37:50,231 DEBUG [RpcServer.reader=9,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40827 because read count=-1. Number of active connections: 2
2016-01-17 19:38:20,305 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:40971; # active connections: 2
2016-01-17 19:38:20,305 DEBUG [RpcServer.reader=0,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:40971 because read count=-1. Number of active connections: 2
2016-01-17 19:38:50,309 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41116; # active connections: 2
2016-01-17 19:38:50,309 DEBUG [RpcServer.reader=1,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41116 because read count=-1. Number of active connections: 2
2016-01-17 19:39:15,071 DEBUG [htable-pool60-t1] ipc.RpcClient: Use SIMPLE authentication for service ClientService, sasl=false
2016-01-17 19:39:15,071 DEBUG [htable-pool60-t1] ipc.RpcClient: Connecting to sandbox.hortonworks.com/10.0.0.4:60020
2016-01-17 19:39:15,141 DEBUG [sandbox.hortonworks.com,60000,1453053198477-BalancerChore] balancer.BaseLoadBalancer: Not running balancer because only 1 active regionserver(s)
2016-01-17 19:39:20,508 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41249; # active connections: 2
2016-01-17 19:39:20,510 DEBUG [RpcServer.reader=2,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41249 because read count=-1. Number of active connections: 2
2016-01-17 19:39:50,325 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41395; # active connections: 2
2016-01-17 19:39:50,330 DEBUG [RpcServer.reader=3,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41395 because read count=-1. Number of active connections: 2
2016-01-17 19:40:20,448 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41534; # active connections: 2
2016-01-17 19:40:20,449 DEBUG [RpcServer.reader=4,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41534 because read count=-1. Number of active connections: 2
2016-01-17 19:40:50,326 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41678; # active connections: 2
2016-01-17 19:40:50,327 DEBUG [RpcServer.reader=5,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41678 because read count=-1. Number of active connections: 2
2016-01-17 19:41:20,388 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41812; # active connections: 2
2016-01-17 19:41:20,388 DEBUG [RpcServer.reader=6,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41812 because read count=-1. Number of active connections: 2
2016-01-17 19:41:50,275 DEBUG [RpcServer.listener,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: connection from 10.0.0.4:41907; # active connections: 2
2016-01-17 19:41:50,276 DEBUG [RpcServer.reader=7,port=60000] ipc.RpcServer: RpcServer.listener,port=60000: DISCONNECTING client 10.0.0.4:41907 because read count=-1. Number of active connections: 2
2016-01-17 19:41:56,776 INFO  [XaSecureConfigURLWatcher] config.ConfigWatcher: Policy Manager not available, using the last stored Policy File/etc/ranger/sandbox_hbase/policycache/hbase_sandbox_hbase_json
2016-01-17 19:41:57,879 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception, retry in 2635ms
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2016-01-17 19:42:00,517 ERROR [ganglia] impl.MetricsSinkAdapter: Got sink exception and over retry limit, suppressing further error messages
org.apache.hadoop.metrics2.MetricsException: Failed to putMetrics
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:193)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:175)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
	at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:129)
	at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:88)
Caused by: java.io.IOException: Network is unreachable
	at java.net.PlainDatagramSocketImpl.send(Native Method)
	at java.net.DatagramSocket.send(DatagramSocket.java:697)
	at org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.emitToGangliaHosts(AbstractGangliaSink.java:259)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink31.emitMetric(GangliaSink31.java:87)
	at org.apache.hadoop.metrics2.sink.ganglia.GangliaSink30.putMetrics(GangliaSink30.java:184)
	... 5 more
2016-01-17 19:42:05,179 INFO  [Thread-20] provider.DbAuditProvider: DbAuditProvider.waitToComplete()
